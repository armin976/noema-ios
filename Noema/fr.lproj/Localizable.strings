/* Auto-generated localization file. */
"%@" = "%@";
"%@ %" = "%1$@ %2$";
"%@ %@" = "%1$@ %2$@";
"%@ models" = "Modèles %@";
"%@ of %@ budget" = "%1$@ du budget %2$@";
"%@ tokens" = "Jetons %@";
"%@ – %@" = "%1$@ – %2$@";
"%@ • %@" = "%1$@ • %2$@";
"%@%" = "%1$@%2$";
"%@% · %@" = "%1$@%2$ · %3$@";
"%@." = "%@.";
"%@:" = "%@ :";
"(+ mmproj %@%)" = "(+ mmproj %1$@%2$)";
"... and %@ more" = "... et %@ plus";
"320 MB • One-time download" = "320 Mo • Téléchargement unique";
"320 MB • One‑time download used for local dataset search" = "320 Mo • Téléchargement unique utilisé pour la recherche d'ensembles de données locaux";
"A larger context keeps more conversation history, but also uses more memory. Adjust it here." = "Un contexte plus large conserve davantage d’historique de conversation, mais utilise également plus de mémoire. Ajustez-le ici.";
"Active" = "Actif";
"Active Model" = "Modèle actif";
"Active connection via %@" = "Connexion active via %@";
"Active experts per token: %@ of %@" = "Experts actifs par jeton : %1$@ sur %2$@";
"Add a remote backend to configure remote startup fallbacks." = "Ajoutez un backend distant pour configurer les solutions de secours de démarrage à distance.";
"Add one or two datasets (like open textbooks) to keep responses accurate and help the AI cite sources." = "Ajoutez un ou deux ensembles de données (comme des manuels ouverts) pour garantir l'exactitude des réponses et aider l'IA à citer les sources.";
"Add remote endpoint" = "Ajouter un point de terminaison distant";
"Adjust appearance, privacy options, and network preferences here." = "Ajustez ici l’apparence, les options de confidentialité et les préférences réseau.";
"Advanced" = "Avancé";
"Advanced Controls" = "Contrôles avancés";
"Allows models to use a privacy-preserving web search API when you tap the globe in chat. Default is ON. In Offline Only mode, the button is disabled." = "Permet aux modèles d'utiliser une API de recherche Web préservant la confidentialité lorsque vous appuyez sur le globe dans le chat. La valeur par défaut est ON. En mode Hors ligne uniquement, le bouton est désactivé.";
"Analyzing context..." = "Analyse du contexte...";
"App Memory Usage (estimated)" = "Utilisation de la mémoire de l'application (estimée)";
"App memory usage budget: %@ (conservative)" = "Budget d'utilisation de la mémoire de l'application : %@ (conservateur)";
"Approx. Tokens" = "Env. Jetons";
"Arm web search when you truly need outside info. It has a small daily limit and most chats don’t require it." = "Activez la recherche sur le Web lorsque vous avez vraiment besoin d’informations extérieures. Il a une petite limite quotidienne et la plupart des chats ne l’exigent pas.";
"Ask Noema anything" = "Demandez n'importe quoi à Noema";
"Ask…" = "Demander…";
"Attach Photos" = "Joindre des photos";
"Backend not found" = "Backend introuvable";
"Benchmark running…" = "Benchmark en cours…";
"Benchmarking is not available for this model format." = "L'analyse comparative n'est pas disponible pour ce format de modèle.";
"Blocks all network traffic, model downloads, and cloud connections so everything stays on‑device." = "Bloque tout le trafic réseau, les téléchargements de modèles et les connexions cloud afin que tout reste sur l'appareil.";
"Bluetooth Pairing" = "Couplage Bluetooth";
"Browse community models and curated datasets to expand what Noema can do." = "Parcourez les modèles communautaires et les ensembles de données sélectionnés pour étendre ce que Noema peut faire.";
"Browse curated datasets for retrieval" = "Parcourez les ensembles de données sélectionnés pour la récupération";
"CFBundleShortVersionString1.0" = "CFBundleShortVersionString1.0";
"Cancel" = "Annuler";
"Cancel Benchmark" = "Annuler l'évaluation";
"Discover Intelligence" = "Découvrez l’intelligence";
"Catalog" = "Catalogue";
"Chat" = "Chat";
"Chat privately with your local models, sync datasets, and manage the relay server in one place." = "Discutez en privé avec vos modèles locaux, synchronisez les ensembles de données et gérez le serveur relais en un seul endroit.";
"Chats" = "Discussions";
"Checking…" = "Vérification…";
"Citation %@" = "Citation %@";
"Cloud Relay Container" = "Conteneur de relais cloud";
"Cloud Relay via CloudKit (auto-discovery and Bluetooth pairing)" = "Cloud Relay via CloudKit (découverte automatique et couplage Bluetooth)";
"CloudKit" = "Kit Cloud";
"CloudKit bridge active. Local replies are generated on this Mac." = "Pont CloudKit actif. Les réponses locales sont générées sur ce Mac.";
"Compiling Metal kernels for GGUF models can take up to a minute on first load." = "La compilation des noyaux Metal pour les modèles GGUF peut prendre jusqu'à une minute lors du premier chargement.";
"Complete the streaming response in the active chat before sending again." = "Complétez la réponse en streaming dans le chat actif avant de renvoyer.";
"Confirm and Start Embedding" = "Confirmer et commencer l'intégration";
"Connected" = "Connecté";
"Connection Modes" = "Modes de connexion";
"Connection Status: %@" = "État de la connexion : %@";
"Container" = "Récipient";
"Context Length" = "Longueur du contexte";
"Context Length: 4096 tokens" = "Longueur du contexte : 4096 jetons";
"Context length is under 5000 tokens. With images and multi-sequence decoding (n_seq_max=16), per-sequence memory can be too small, leading to a crash. Increase context to at least 8192 in Model Settings." = "La longueur du contexte est inférieure à 5 000 jetons. Avec les images et le décodage multi-séquences (n_seq_max=16), la mémoire par séquence peut être trop petite, entraînant un crash. Augmentez le contexte à au moins 8 192 dans les paramètres du modèle.";
"Controls how many high‑scoring passages (chunks) can be injected into the prompt. Higher values increase recall but consume more context window and can slow responses. Typical range 3–6." = "Contrôle le nombre de passages (morceaux) ayant obtenu un score élevé qui peuvent être injectés dans l'invite. Des valeurs plus élevées augmentent le rappel mais consomment plus de fenêtre contextuelle et peuvent ralentir les réponses. Plage typique 3–6.";
"Couldn't load the recommended model." = "Impossible de charger le modèle recommandé.";
"Couldn’t load the recommended model right now." = "Impossible de charger le modèle recommandé pour le moment.";
"Creativity: %@. Low values focus responses; high values add variety." = "Créativité : %@. Les valeurs faibles concentrent les réponses ; des valeurs élevées ajoutent de la variété.";
"Dark" = "Sombre";
"Dataset" = "Ensemble de données";
"Dataset indexing in progress..." = "Indexation du jeu de données en cours...";
"Dataset ready to use" = "Ensemble de données prêt à l'emploi";
"Datasets" = "Ensembles de données";
"Datasets enrich the model with focused knowledge. Toggle one on to use it in chat." = "Les ensembles de données enrichissent le modèle avec des connaissances ciblées. Activez-en un pour l'utiliser dans le chat.";
"Default selection (~%@) balances RAM usage against model quality." = "La sélection par défaut (~%@) équilibre l'utilisation de la RAM par rapport à la qualité du modèle.";
"Delete" = "Supprimer";
"Delete Dataset" = "Supprimer l'ensemble de données";
"Deletes all chats, downloaded models, and datasets, and restores settings to defaults. The embedding model stays installed." = "Supprime toutes les discussions, modèles téléchargés et ensembles de données, et restaure les paramètres par défaut. Le modèle d'intégration reste installé.";
"Device" = "Appareil";
"Digest:" = "Digérer:";
"Done" = "Fait";
"Done!" = "Fait!";
"Download Now" = "Télécharger maintenant";
"Download a model from Explore or add a remote endpoint to get started." = "Téléchargez un modèle depuis Explore ou ajoutez un point de terminaison distant pour commencer.";
"Download a small embedding model so Noema can index and search your datasets" = "Téléchargez un petit modèle d'intégration pour que Noema puisse indexer et rechercher vos ensembles de données";
"Downloaded datasets need on-device embedding. Give it a few minutes after download finishes." = "Les ensembles de données téléchargés doivent être intégrés sur l'appareil. Attendez quelques minutes après la fin du téléchargement.";
"Downloaded models and datasets live here so you can manage them offline." = "Les modèles et ensembles de données téléchargés sont disponibles ici afin que vous puissiez les gérer hors ligne.";
"Downloading…" = "Téléchargement…";
"Draft tokens: %@" = "Jetons de draft : %@";
"Draft window: %@" = "Fenêtre de brouillon : %@";
"EPUB viewing not supported on this platform" = "Affichage EPUB non pris en charge sur cette plateforme";
"Embedding" = "Intégration";
"Embedding Model Ready" = "Modèle d'intégration prêt";
"Embedding is resource intensive. For best performance, plug in your phone. Do you want to proceed on battery?" = "L’intégration nécessite beaucoup de ressources. Pour de meilleures performances, branchez votre téléphone. Voulez-vous continuer sur batterie ?";
"Enabling Bluetooth…" = "Activation du Bluetooth…";
"Enhance with Datasets" = "Améliorer avec des ensembles de données";
"Error" = "Erreur";
"Estimated working set: %@ · Budget: %@" = "Ensemble de travail estimé : %1$@ · Budget : %2$@";
"Experts Per Token" = "Experts par jeton";
"Explore Datasets" = "Explorer les ensembles de données";
"Expose any downloaded models or connected remote endpoints from the Stored tab to your paired devices. Select which one should answer conversations when the relay is running." = "Exposez tous les modèles téléchargés ou les points de terminaison distants connectés depuis l'onglet Stocké à vos appareils couplés. Sélectionnez celui qui doit répondre aux conversations lorsque le relais est en cours d'exécution.";
"Expose to iOS" = "Exposer à iOS";
"Explore the latest open-source models optimized for your Mac." = "Explorez les derniers modèles open source optimisés pour votre Mac.";
"Failed to load README" = "Échec du chargement du fichier README";
"Failed: %@" = "Échec : %@";
"Fastest option on this device: SLM (Leap) models." = "Option la plus rapide sur cet appareil : modèles SLM (Leap).";
"Field requirements will depend on your specific backend deployment." = "Les exigences sur le terrain dépendront de votre déploiement backend spécifique.";
"Files" = "Fichiers";
"First, enable fast dataset search" = "Tout d’abord, activez la recherche rapide d’ensembles de données";
"First-time GGUF load takes longer" = "Le premier chargement de GGUF prend plus de temps";
"First-time download from HuggingFace" = "Premier téléchargement depuis HuggingFace";
"First‑time setup: download the Qwen‑1.7B model and embeddings.\nWi‑Fi recommended." = "Première configuration : téléchargez le modèle Qwen‑1.7B et les intégrations.\nWi-Fi recommandé.";
"For best performance, please plug in your phone until this completes." = "Pour de meilleures performances, veuillez brancher votre téléphone jusqu'à ce que cette opération soit terminée.";
"Force Local Network" = "Forcer le réseau local";
"Forces chat traffic through the last LAN host even if Wi‑Fi names don't match yet." = "Force le trafic de discussion via le dernier hôte LAN même si les noms Wi-Fi ne correspondent pas encore.";
"Formatted view unavailable" = "Vue formatée indisponible";
"Found unsupported: %@ …" = "Trouvé non pris en charge : %@ …";
"Frequency penalty: %@" = "Pénalité de fréquence : %@";
"GGUF models are the most compatible option. Use the format switch to explore the other builds when you need them." = "Les modèles GGUF sont l’option la plus compatible. Utilisez le commutateur de format pour explorer les autres versions lorsque vous en avez besoin.";
"GGUF works everywhere. MLX targets Apple Silicon speed. SLM focuses on responsiveness on any device." = "GGUF fonctionne partout. MLX cible la vitesse d’Apple Silicon. SLM se concentre sur la réactivité sur n’importe quel appareil.";
"GPU Offload Layers" = "Couches de déchargement GPU";
"GPU off-load is not supported for this model." = "Le déchargement du GPU n'est pas pris en charge pour ce modèle.";
"Get Started" = "Commencer";
"Help shape Noema by trying upcoming features and sharing feedback." = "Aidez à façonner Noema en essayant les fonctionnalités à venir et en partageant vos commentaires.";
"High context lengths use more memory" = "Les longueurs de contexte élevées utilisent plus de mémoire";
"High-quality embedding model for local RAG" = "Modèle d'intégration de haute qualité pour le RAG local";
"Host ID: %@" = "ID d'hôte : %@";
"How it works" = "Comment ça marche";
"I'm New to Local LLMs, Guide Me" = "Je suis nouveau dans les LLM locaux, guidez-moi";
"If enabled, the app will attempt to load models even when they likely exceed your device's memory budget. This can cause the app to terminate." = "Si cette option est activée, l'application tentera de charger les modèles même s'ils dépassent probablement le budget mémoire de votre appareil. Cela peut entraîner la fermeture de l'application.";
"Import Dataset" = "Importer un ensemble de données";
"Import PDFs, EPUBs, or text files to build local knowledge bases." = "Importez des fichiers PDF, EPUB ou texte pour créer des bases de connaissances locales.";
"Import your own PDFs, EPUBs, or TXT files and keep them local." = "Importez vos propres fichiers PDF, EPUB ou TXT et conservez-les localement.";
"Importing & Scanning..." = "Importation et numérisation...";
"In progress..." = "En cours...";
"Indexing %@" = "Indexation %@";
"Indexing dataset…" = "Ensemble de données d'indexation…";
"Indexing: %@% · %@" = "Indexation : %1$@%2$ · %3$@";
"Install a local model to make it available at launch." = "Installez un modèle local pour le rendre disponible au lancement.";
"Install another model with the same architecture and equal or smaller size to enable speculative decoding." = "Installez un autre modèle avec la même architecture et une taille égale ou inférieure pour permettre le décodage spéculatif.";
"K Cache Quant" = "K Cache Quant";
"Keep this iPhone or iPad within a few feet of the Mac that is advertising Noema Relay. We'll pull the relay details automatically once connected." = "Gardez cet iPhone ou iPad à quelques mètres du Mac qui fait la publicité de Noema Relay. Nous extrairons automatiquement les détails du relais une fois connectés.";
"LAN URL: %@" = "URL du réseau local : %@";
"Large Model Downloads" = "Téléchargements de grands modèles";
"Last Sync" = "Dernière synchronisation";
"Last refreshed %@" = "Dernière actualisation %@";
"Latest benchmark" = "Dernier benchmark";
"Latest integrated release: %@" = "Dernière version intégrée : %@";
"Library" = "Bibliothèque";
"Light" = "Lumière";
"Llama.cpp" = "Appeler.cpp";
"Load" = "Charger";
"Load a local model before chatting. You can download one from the Explore tab or load a model you've already installed." = "Chargez un modèle local avant de discuter. Vous pouvez en télécharger un depuis l'onglet Explorer ou charger un modèle que vous avez déjà installé.";
"Loading recommendation…" = "Chargement de la recommandation…";
"Loading…" = "Chargement…";
"Local Network HTTP server for LAN clients (OpenAI-compatible)" = "Serveur HTTP de réseau local pour les clients LAN (compatible OpenAI)";
"Low = focused. High = varied." = "Faible = concentré. Élevé = varié.";
"Lower = more results (more noise). Higher = stricter matches." = "Plus bas = plus de résultats (plus de bruit). Plus élevé = correspondances plus strictes.";
"MLX currently manages expert routing automatically; manual selection is not supported." = "MLX gère actuellement automatiquement le routage expert ; la sélection manuelle n’est pas prise en charge.";
"Many models are several gigabytes in size and require a stable connection and sufficient storage. Downloads can fail or take a long time on slow networks or devices with limited space." = "De nombreux modèles font plusieurs gigaoctets et nécessitent une connexion stable et un stockage suffisant. Les téléchargements peuvent échouer ou prendre beaucoup de temps sur des réseaux lents ou des appareils avec un espace limité.";
"Max Chunks: %@" = "Nombre maximum de morceaux : %@";
"Max recommended context on this device: ~%@ tokens" = "Contexte maximum recommandé sur cet appareil : ~%@ jetons";
"Measure real-world generation speed for this configuration. A short scripted prompt will run locally and report timing and memory usage." = "Mesurez la vitesse de génération réelle pour cette configuration. Une courte invite scriptée s'exécutera localement et signalera la synchronisation et l'utilisation de la mémoire.";
"Min-p" = "Min-p";
"Min-p: %@" = "Min-p : %@";
"Minimum cosine similarity a passage must have to be considered relevant. Lower = more passages (higher recall, more noise). Higher = fewer, more precise passages. Try 0.2–0.4 for broad questions; 0.5–0.7 for precise lookups." = "Similitude minimale en cosinus qu'un passage doit avoir pour être considéré comme pertinent. Plus bas = plus de passages (rappel plus élevé, plus de bruit). Plus haut = moins de passages plus précis. Essayez 0,2 à 0,4 pour les questions générales ; 0,5 à 0,7 pour des recherches précises.";
"MoE layers: %@ / %@" = "Couches MoE : %1$@ / %2$@";
"Model Detection Limitations" = "Limites de la détection du modèle";
"Model Formats" = "Formats de modèles";
"Models" = "Modèles";
"Models shown here are exposed by the Mac relay. Manage sources in the Relay tab on macOS to share more models." = "Les modèles présentés ici sont exposés par le relais Mac. Gérez les sources dans l'onglet Relais sur macOS pour partager plus de modèles.";
"Move your device closer to the Mac running the relay if it doesn't appear right away. Bluetooth discovery usually completes within a few seconds." = "Rapprochez votre appareil du Mac exécutant le relais s'il n'apparaît pas immédiatement. La découverte Bluetooth se termine généralement en quelques secondes.";
"Name your dataset" = "Nommez votre ensemble de données";
"Nearby Relays" = "Relais à proximité";
"Nearby iPhone and iPad devices discover your Mac relay instantly and sync pairing codes over the air." = "Les appareils iPhone et iPad à proximité découvrent instantanément le relais de votre Mac et synchronisent les codes de couplage par liaison radio.";
"Need a fresh thread? Tap the plus button for a brand-new conversation." = "Besoin d'un nouveau fil ? Appuyez sur le bouton plus pour une toute nouvelle conversation.";
"Nice! You already have the recommended GGUF starter model ready to use." = "Bon! Vous disposez déjà du modèle de démarrage GGUF recommandé, prêt à l’emploi.";
"No compatible files found for retrieval. Supported: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV" = "Aucun fichier compatible trouvé pour la récupération. Pris en charge : PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV";
"No connection responses recorded yet." = "Aucune réponse de connexion enregistrée pour le moment.";
"No datasets available yet. Import or download datasets to build your personal library." = "Aucun ensemble de données n'est encore disponible. Importez ou téléchargez des ensembles de données pour créer votre bibliothèque personnelle.";
"No datasets found. Try different keywords." = "Aucun ensemble de données trouvé. Essayez différents mots-clés.";
"No datasets imported yet." = "Aucun ensemble de données n'a encore été importé.";
"No datasets yet" = "Aucun ensemble de données pour l'instant";
"No files listed for this dataset." = "Aucun fichier répertorié pour cet ensemble de données.";
"No model >" = "Aucun modèle >";
"No model loaded" = "Aucun modèle chargé";
"No models available. Add downloads or remote connections in Stored to configure the relay." = "Aucun modèle disponible. Ajoutez des téléchargements ou des connexions à distance dans Stored pour configurer le relais.";
"No models cached yet. Open the backend to refresh its catalog." = "Aucun modèle mis en cache pour l'instant. Ouvrez le backend pour actualiser son catalogue.";
"No models found for '%@'" = "Aucun modèle trouvé pour '%@'";
"No models loaded right now. We'll spin one up when a request arrives." = "Aucun modèle chargé pour le moment. Nous en lancerons un lorsqu'une demande arrivera.";
"No models match your search." = "Aucun modèle ne correspond à votre recherche.";
"No models yet" = "Aucun modèle pour l'instant";
"No parameters" = "Aucun paramètre";
"No quant files available" = "Aucun fichier quantitatif disponible";
"No recent devices. We'll list clients the next time they talk to this relay." = "Aucun appareil récent. Nous listerons les clients la prochaine fois qu'ils parleront à ce relais.";
"No remote endpoints configured yet." = "Aucun point de terminaison distant configuré pour le moment.";
"No remote endpoints configured." = "Aucun point de terminaison distant configuré.";
"No ≥Q3 quants are available for this model." = "Aucun quants ≥Q3 n’est disponible pour ce modèle.";
"Noema" = "Novembre";
"Noema REST API — /api/v0/* for model catalog & operations" = "API REST Noema — /api/v0/* pour le catalogue de modèles et les opérations";
"Noema Relay" = "Relais Noéma";
"Noema Server" = "Serveur Noéma";
"Noema attempts to gauge available memory to prevent models from exceeding device limits. These checks may occasionally miss risky situations and allow a model to crash your app, or they may be overly conservative and block a model that could have run fine." = "Noema tente d'évaluer la mémoire disponible pour empêcher les modèles de dépasser les limites de l'appareil. Ces vérifications peuvent parfois manquer des situations à risque et permettre à un modèle de faire planter votre application, ou elles peuvent être trop conservatrices et bloquer un modèle qui aurait pu fonctionner correctement.";
"Noema could not find a projector in the repository. If the model advertises vision, ensure the mmproj file is present in the same folder as the weights." = "Noema n'a pas trouvé de projecteur dans le référentiel. Si le modèle annonce une vision, assurez-vous que le fichier mmproj est présent dans le même dossier que les poids.";
"Noema has been reset. The embedding model remains installed." = "Noema a été réinitialisée. Le modèle d'intégration reste installé.";
"Nomic Embed Text v1.5 (Q4_K_M)" = "Texte intégré Nomic v1.5 (Q4_K_M)";
"None" = "Aucun";
"Not found" = "Pas trouvé";
"Not provided" = "Non fourni";
"OK" = "D'ACCORD";
"Off-Grid" = "Hors réseau";
"Off-grid mode blocks every network call so the app stays self-contained. Good luck exploring Noema!" = "Le mode hors réseau bloque tous les appels réseau afin que l'application reste autonome. Bonne chance pour explorer Noema !";
"Only one expert is available for this model; the active expert count is fixed." = "Un seul expert est disponible pour ce modèle ; le nombre d’experts actifs est fixe.";
"Open Stored to choose a model to run locally or connect to a remote endpoint." = "Ouvrez Stored pour choisir un modèle à exécuter localement ou à connecter à un point de terminaison distant.";
"Open the sidebar to revisit any previous session without losing your spot." = "Ouvrez la barre latérale pour revoir n'importe quelle session précédente sans perdre votre place.";
"OpenAI-style API — /v1/chat/completions, /v1/completions, /v1/models" = "API de style OpenAI — /v1/chat/completions, /v1/completions, /v1/models";
"Optimizations in use" = "Optimisations utilisées";
"PDF viewing not supported on this platform" = "Affichage PDF non pris en charge sur cette plateforme";
"Pick a model and add a dataset" = "Choisissez un modèle et ajoutez un ensemble de données";
"Pick the SLM format when you want ultra-responsive models that run well anywhere." = "Choisissez le format SLM lorsque vous souhaitez des modèles ultra-réactifs qui fonctionnent partout.";
"Pinned answer" = "Réponse épinglée";
"Pinned answer unavailable" = "Réponse épinglée indisponible";
"Preparation" = "Préparation";
"Preparing Embedding Model" = "Préparation du modèle d'intégration";
"Preparing benchmark…" = "Préparation du benchmark…";
"Preparing…" = "Préparation…";
"Presence penalty: %@" = "Pénalité de présence : %@";
"Projector (mmproj)" = "Projecteur (mmproj)";
"Projector downloaded automatically from Hugging Face. Keep this file alongside the weights so vision remains available." = "Projecteur téléchargé automatiquement depuis Hugging Face. Conservez ce fichier à côté des poids afin que la vision reste disponible.";
"Quantize the runtime key cache to save memory. Experimental." = "Quantifiez le cache des clés d'exécution pour économiser de la mémoire. Expérimental.";
"Quantize the runtime value cache to save memory when Flash Attention is enabled. Experimental." = "Quantifiez le cache des valeurs d'exécution pour économiser de la mémoire lorsque Flash Attention est activé. Expérimental.";
"Qwen 3 1.7B GGUF (Q3_K_M) gives you a dependable starting point. Delete it anytime if you need space." = "Qwen 3 1.7B GGUF (Q3_K_M) vous offre un point de départ fiable. Supprimez-le à tout moment si vous avez besoin d'espace.";
"RAG embeds normalized paragraphs from your PDFs and EPUBs. On each question, the most relevant chunks are retrieved and added to the prompt. Images are ignored." = "RAG intègre des paragraphes normalisés de vos PDF et EPUB. Pour chaque question, les éléments les plus pertinents sont récupérés et ajoutés à l'invite. Les images sont ignorées.";
"RAM Safety Checks" = "Contrôles de sécurité de la RAM";
"RAM information for this device will be added in a future update." = "Les informations sur la RAM de cet appareil seront ajoutées dans une future mise à jour.";
"REST Endpoints" = "Points de terminaison REST";
"Reachable at" = "Joignable à";
"Ready for Use" = "Prêt à l'emploi";
"Recent Chats" = "Discussions récentes";
"Recommended" = "Recommandé";
"Recommended Starter Model" = "Modèle de démarrage recommandé";
"Relay ID" = "ID du relais";
"Relay Server Running" = "Serveur relais en cours d'exécution";
"Relay Sources" = "Sources relais";
"Remaining: %@" = "Restant : %@";
"Remember:" = "Souviens-toi:";
"Remote Backends" = "Backends distants";
"Remote endpoint is offline. This model can't be found at this time." = "Le point de terminaison distant est hors ligne. Ce modèle est introuvable pour le moment.";
"Remote timeout: %@s" = "Délai d'expiration à distance : %@s";
"Repeat last N tokens: %@" = "Répétez les N derniers jetons : %@";
"Repetition penalty: %@" = "Pénalité de répétition : %@";
"Request Parameters" = "Paramètres de la demande";
"Responses are generated by the macOS relay server. Configure the provider (LM Studio or Ollama) on the Mac app." = "Les réponses sont générées par le serveur relais macOS. Configurez le fournisseur (LM Studio ou Ollama) sur l'application Mac.";
"Result" = "Résultat";
"Results" = "Résultats";
"Save" = "Sauvegarder";
"Saving…" = "Économie…";
"Score: %@" = "Note : %@";
"SearXNG web search is available without limits. There's nothing to purchase—just enable the globe button in chat whenever you need online results." = "La recherche Web SearXNG est disponible sans limites. Il n'y a rien à acheter : activez simplement le bouton Globe dans le chat chaque fois que vous avez besoin de résultats en ligne.";
"SearXNG web search is enabled for this device." = "La recherche Web SearXNG est activée pour cet appareil.";
"Search" = "Recherche";
"Search for any subject you're interested in." = "Recherchez n’importe quel sujet qui vous intéresse.";
"Search requests are proxied through https://search.noemaai.com and are available without quotas." = "Les demandes de recherche sont transmises via https://search.noemaai.com et sont disponibles sans quotas.";
"Seed" = "Graine";
"Selecting more experts keeps additional expert weights resident in RAM and increases memory usage." = "La sélection de davantage d'experts permet de conserver des pondérations d'experts supplémentaires dans la RAM et d'augmenter l'utilisation de la mémoire.";
"Server Settings" = "Paramètres du serveur";
"Share Logs" = "Partager les journaux";
"Sharing relay payload with nearby devices…" = "Partager la charge utile du relais avec les appareils à proximité…";
"Shows the last server response." = "Affiche la dernière réponse du serveur.";
"Signal" = "Signal";
"Similarity Threshold" = "Seuil de similarité";
"Simple" = "Simple";
"Smooth loops and phrase echo by balancing repetition controls." = "Boucles fluides et écho de phrases en équilibrant les commandes de répétition.";
"Smooth loops and repeated phrases by tuning repetition controls." = "Boucles fluides et phrases répétées en réglant les commandes de répétition.";
"Some models do not provide the system prompts needed for Noema to detect and configure them properly. These models may be unusable until they include appropriate metadata or support." = "Certains modèles ne fournissent pas les invites système nécessaires à Noema pour les détecter et les configurer correctement. Ces modèles peuvent être inutilisables jusqu'à ce qu'ils incluent des métadonnées ou une prise en charge appropriée.";
"Source unavailable. Check storage or network settings." = "Source indisponible. Vérifiez les paramètres de stockage ou de réseau.";
"Source: %@" = "Source : %@";
"Specify identifiers for models that are not listed by the server. Leave blank to rely on the server's catalog." = "Spécifiez les identifiants des modèles qui ne sont pas répertoriés par le serveur. Laissez vide pour vous fier au catalogue du serveur.";
"Specify your model identifiers, or reload your custom models later." = "Spécifiez vos identifiants de modèle ou rechargez vos modèles personnalisés ultérieurement.";
"Speed up with a smaller helper model." = "Accélérez avec un modèle d’assistance plus petit.";
"Start by installing one model. Then add a dataset (like an open textbook) so the AI can answer with grounded knowledge." = "Commencez par installer un modèle. Ajoutez ensuite un ensemble de données (comme un manuel ouvert) afin que l'IA puisse répondre avec des connaissances fondées.";
"Start the relay to automatically share the latest payload with nearby devices." = "Démarrez le relais pour partager automatiquement la dernière charge utile avec les appareils à proximité.";
"Start with a reliable Qwen 3 1.7B build. It balances capability with small download size." = "Commencez avec une version fiable de Qwen 3 1.7B. Il équilibre la capacité avec une petite taille de téléchargement.";
"Startup defaults now live in Settings → Startup. Favorite models here to keep them handy." = "Les paramètres de démarrage par défaut se trouvent désormais dans Paramètres → Démarrage. Modèles préférés ici pour les garder à portée de main.";
"Status" = "Statut";
"Stay close to your Mac" = "Restez proche de votre Mac";
"Stop Using Dataset" = "Arrêter d'utiliser l'ensemble de données";
"Streaming" = "Streaming";
"Streaming response…" = "Réponse en streaming…";
"Supported Endpoints" = "Points de terminaison pris en charge";
"Supported formats: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV" = "Formats pris en charge : PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV";
"Swap between the new stacked chat panel and the classic tab bar layout." = "Basculez entre le nouveau panneau de discussion empilé et la disposition classique de la barre d'onglets.";
"Swipe left to remove the embedding model from this device." = "Faites glisser votre doigt vers la gauche pour supprimer le modèle d'intégration de cet appareil.";
"Switch the selector to MLX for Apple Silicon‑optimized builds that excel at speed." = "Basculez le sélecteur sur MLX pour les versions optimisées pour Apple Silicon qui excellent en vitesse.";
"Switch to Raw to inspect the original response." = "Passez à Raw pour inspecter la réponse d’origine.";
"System" = "Système";
"Tap to load" = "Appuyez pour charger";
"Temperature" = "Température";
"Testing" = "Essai";
"The app memory usage budget is an estimate based on your device's total RAM and typical iOS memory management. The actual available memory may vary depending on system load, other running apps, and iOS memory pressure. Models that exceed this budget may cause the app to be terminated by iOS." = "Le budget d'utilisation de la mémoire de l'application est une estimation basée sur la RAM totale de votre appareil et la gestion typique de la mémoire iOS. La mémoire disponible réelle peut varier en fonction de la charge du système, des autres applications en cours d'exécution et de la pression de la mémoire iOS. Les modèles qui dépassent ce budget peuvent entraîner la fermeture de l'application par iOS.";
"The embedding model is installed. Delete it to free ~320 MB." = "Le modèle d'intégration est installé. Supprimez-le pour libérer environ 320 Mo.";
"The relay listens to the %@ container for new conversations and responds with your selected provider." = "Le relais écoute le conteneur %@ pour les nouvelles conversations et répond avec votre fournisseur sélectionné.";
"The tool returned data that can't be formatted. Switch to Raw to inspect the original response." = "L'outil a renvoyé des données qui ne peuvent pas être formatées. Passez à Raw pour inspecter la réponse d’origine.";
"These options stay in simple mode for clarity. Let’s cover the essentials." = "Ces options restent en mode simple pour plus de clarté. Voyons l'essentiel.";
"Think of Noema as a simple way to run AI on your device. To get useful answers, you pair a local model with datasets (like open textbooks). We’ll guide you through the first setup." = "Considérez Noema comme un moyen simple d'exécuter l'IA sur votre appareil. Pour obtenir des réponses utiles, vous associez un modèle local à des ensembles de données (comme des manuels ouverts). Nous vous guiderons tout au long de la première configuration.";
"This app bundles llama.cpp; we keep this in sync with upstream b‑releases." = "Cette application regroupe lama.cpp ; nous gardons cela en synchronisation avec les versions B en amont.";
"This backend is unavailable. Remove it or pick another option." = "Ce back-end n'est pas disponible. Supprimez-le ou choisissez une autre option.";
"This chat stays private—responses are generated on your device after you load a model." = "Cette discussion reste privée : les réponses sont générées sur votre appareil après le chargement d'un modèle.";
"This configuration exceeds the current RAM safety guard, so benchmarking is disabled." = "Cette configuration dépasse la protection de sécurité actuelle de la RAM, l'analyse comparative est donc désactivée.";
"This dataset is taking a while to load, still working…" = "Cet ensemble de données prend un certain temps à charger, mais fonctionne toujours…";
"This dataset's files are not currently supported for document retrieval." = "Les fichiers de cet ensemble de données ne sont actuellement pas pris en charge pour la récupération de documents.";
"This device doesn't support GPU offload." = "Cet appareil ne prend pas en charge le déchargement GPU.";
"This device doesn't support GPU offload; GGUF models will run on the CPU and generation speed will be significantly slower." = "Cet appareil ne prend pas en charge le déchargement GPU ; Les modèles GGUF fonctionneront sur le processeur et la vitesse de génération sera nettement plus lente.";
"This model doesn't support GPU offload and generation speed will be significantly slower. Consider switching to an MLX model." = "Ce modèle ne prend pas en charge le déchargement GPU et la vitesse de génération sera nettement plus lente. Pensez à passer à un modèle MLX.";
"This model doesn't support GPU offload and generation speed will be significantly slower. Fastest option on this device: use an SLM (Leap) model." = "Ce modèle ne prend pas en charge le déchargement GPU et la vitesse de génération sera nettement plus lente. Option la plus rapide sur cet appareil : utilisez un modèle SLM (Leap).";
"This model doesn't support GPU offload and may run slowly. Consider an MLX model." = "Ce modèle ne prend pas en charge le déchargement GPU et peut fonctionner lentement. Considérons un modèle MLX.";
"This model doesn't support GPU offload and may run slowly. Fastest option: use an SLM model." = "Ce modèle ne prend pas en charge le déchargement GPU et peut fonctionner lentement. Option la plus rapide : utilisez un modèle SLM.";
"This permanently removes every chat conversation. This action cannot be undone." = "Cela supprime définitivement toutes les conversations de chat. Cette action ne peut pas être annulée.";
"This textbook appears to be available only as a web page. Noema can't import it as a dataset." = "Ce manuel semble être disponible uniquement sous forme de page Web. Noema ne peut pas l'importer sous forme d'ensemble de données.";
"Tool calling isn't perfect. Although Noema implements many methods of detecting and instructing models to use tools, not all LLMs will follow instructions and some might not call them correctly or at all. Tool calling heavily depends on model pre-training and will get better as time passes." = "L'appel d'outils n'est pas parfait. Bien que Noema implémente de nombreuses méthodes pour détecter et demander aux modèles d'utiliser des outils, tous les LLM ne suivront pas les instructions et certains pourraient ne pas les appeler correctement ou pas du tout. L'appel d'outils dépend fortement de la pré-formation du modèle et s'améliorera avec le temps.";
"Tools" = "Outils";
"Top-k: %@" = "Haut-k : %@";
"Top-p" = "Haut-p";
"Top-p: %@" = "Haut-p : %@";
"Try again" = "Essayer à nouveau";
"Try another dataset if these formats aren't available." = "Essayez un autre ensemble de données si ces formats ne sont pas disponibles.";
"Try the Qwen 3 1.7B GGUF (Q3_K_M) build below. It's a good starting point and you can delete it anytime." = "Essayez la version Qwen 3 1.7B GGUF (Q3_K_M) ci-dessous. C'est un bon point de départ et vous pouvez le supprimer à tout moment.";
"Unable to load image" = "Impossible de charger l'image";
"Unknown error" = "Erreur inconnue";
"Updates every second" = "Mises à jour toutes les secondes";
"Use" = "Utiliser";
"Use Dataset" = "Utiliser l'ensemble de données";
"Use this switch to flip between finding models or datasets." = "Utilisez ce commutateur pour basculer entre la recherche de modèles ou d'ensembles de données.";
"Using %@" = "Utiliser %@";
"Using %@ of %@ budget" = "Utiliser %1$@ du budget %2$@";
"Using more than %@ significantly increases RAM usage." = "L’utilisation de plus de %@ augmente considérablement l’utilisation de la RAM.";
"Using server catalog" = "Utilisation du catalogue de serveur";
"V Cache Quant" = "V Cache Quant";
"Vendor recommendation: %@" = "Recommandation du fournisseur : %@";
"Version" = "Version";
"Version %@" = "Version %@";
"Version 1.4" = "Version 1.4";
"Vision models require a companion projector (.mmproj). Noema will fetch it automatically the next time you download this model." = "Les modèles Vision nécessitent un projecteur compagnon (.mmproj). Noema le récupérera automatiquement la prochaine fois que vous téléchargerez ce modèle.";
"Wait for the response in your other chat to finish before sending a new message." = "Attendez la fin de la réponse dans votre autre chat avant d'envoyer un nouveau message.";
"Waiting for tool response…" = "En attente de la réponse de l'outil…";
"We'll extract text and prepare embeddings. You can also start later from the dataset details." = "Nous extrairons le texte et préparerons les intégrations. Vous pouvez également commencer plus tard à partir des détails de l'ensemble de données.";
"We'll route new conversations through %@ even if Wi‑Fi names differ. You can switch back by reloading the backend." = "Nous acheminerons les nouvelles conversations via %@ même si les noms Wi-Fi diffèrent. Vous pouvez revenir en arrière en rechargeant le backend.";
"We'll try remote models in priority order for this long before moving to the next option." = "Nous essaierons les modèles distants par ordre de priorité avant de passer à l'option suivante.";
"We'll try this saved identifier even though it's not in the latest catalog." = "Nous allons essayer cet identifiant enregistré même s'il ne figure pas dans le dernier catalogue.";
"Web Search Tool Calls" = "Appels aux outils de recherche sur le Web";
"Web Search button" = "Bouton de recherche sur le Web";
"Web search is included" = "La recherche sur le Web est incluse";
"Weights" = "Poids";
"Welcome to Noema" = "Bienvenue à Noéma";
"Welcome to Noema for Mac" = "Bienvenue sur Noema pour Mac";
"What is Noema?" = "Qu’est-ce que Noéma ?";
"When connecting from another device, point the base URL to your computer (for example http://192.168.0.10:11434) and start Ollama with `OLLAMA_HOST=0.0.0.0` so it accepts remote clients." = "Lors de la connexion depuis un autre appareil, pointez l'URL de base vers votre ordinateur (par exemple http://192.168.0.10:11434) et démarrez Ollama avec `OLLAMA_HOST=0.0.0.0` afin qu'il accepte les clients distants.";
"When enabled, pressing eject on iOS tells this Mac to unload the active relay model." = "Lorsqu'il est activé, appuyer sur Éjecter sur iOS indique à ce Mac de décharger le modèle de relais actif.";
"When enabled, you will be asked to choose parameters every time a model loads." = "Lorsqu'il est activé, il vous sera demandé de choisir des paramètres à chaque chargement d'un modèle.";
"Wi-Fi: %@" = "Wi-Fi : %@";
"Working set estimate (%@): %@ @ %@ tokens" = "Estimation de l'ensemble de travail (%1$@) : %2$@ @ %3$@ jetons";
"Write prompts, instructions, or notes here. Press return to add new lines." = "Écrivez des invites, des instructions ou des notes ici. Appuyez sur Entrée pour ajouter de nouvelles lignes.";
"You can keep chatting while indexing finishes" = "Vous pouvez continuer à discuter pendant la fin de l'indexation";
"You can only favorite up to three models." = "Vous ne pouvez mettre en favori que trois modèles maximum.";
"You can restart this process in the dataset settings any time." = "Vous pouvez redémarrer ce processus dans les paramètres de l'ensemble de données à tout moment.";
"You're in Off-Grid mode. The Explore tab is hidden and all network features are disabled. You can only use downloaded models and datasets." = "Vous êtes en mode hors réseau. L'onglet Explorer est masqué et toutes les fonctionnalités réseau sont désactivées. Vous ne pouvez utiliser que des modèles et des ensembles de données téléchargés.";
"Your Datasets" = "Vos ensembles de données";
"Your Models" = "Vos modèles";
"Your private AI workspace" = "Votre espace de travail IA privé";
"You’re ready to explore. Download models, add datasets, and start chatting." = "Vous êtes prêt à explorer. Téléchargez des modèles, ajoutez des ensembles de données et commencez à discuter.";
"minutes" = "minutes";
"•" = "";
"• Close other applications to free up RAM" = "• Fermez les autres applications pour libérer de la RAM";
"• Embedding happens locally on your device" = "• L'intégration s'effectue localement sur votre appareil";
"• Larger datasets take exponentially more time" = "• Les ensembles de données plus volumineux prennent exponentiellement plus de temps";
"• You can pause and resume downloads if needed" = "• Vous pouvez suspendre et reprendre les téléchargements si nécessaire";
"…and %@ more parameter%@" = "…et %1$@ plus de paramètre%2$@";
"⚠️ " = "";
"General" = "Général";

"Privacy" = "Confidentialité";

"About" = "À propos";

"About & Support" = "À propos et support";

"Network" = "Réseau";

"Embedding Model" = "Modèle d'intégration";

"Retrieval" = "Récupération";

"Early Testers" = "Testeurs précoces";

"Build Info" = "Informations de build";

"Settings" = "Réglages";

"Language" = "Langue";
"Startup" = "Démarrage";
"Search models" = "Rechercher des modèles";
"SLM Models - Liquid AI" = "SLM Models - Liquid AI";
"Import" = "Importer";
"Import GGUF" = "Importer GGUF";
"Import MLX" = "Importer MLX";
"Import Failed" = "Échec de l’import";
"Switching between GGUF/MLX modes" = "Basculer entre les modes GGUF/MLX";
"Switching between GGUF/SLM modes" = "Basculer entre les modes GGUF/SLM";
"Vision-capable model" = "Modèle compatible vision";
"All" = "Tout";
"Text" = "Texte";
"Vision" = "Vision";
"Continue" = "Continuer";
"Try bullet" = "Essayez :\n• D’autres mots-clés (ex. « gemma-3 » au lieu de « gemma 3 »)\n• %@\n• Ajuster le filtre texte/vision\n• Vérifier vos filtres de recherche";
"Select one or more .gguf files. For vision models, also select the projector .gguf (files containing ‘mmproj’ or ‘projector’). Files will be copied into your local model library." = "Select one or more .gguf files. For vision models, also select the projector .gguf (files containing ‘mmproj’ or ‘projector’). Files will be copied into your local model library.";
"Select the model folder that contains config.json and the weights (safetensors/npz). The entire folder will be imported into your local model library." = "Select the model folder that contains config.json and the weights (safetensors/npz). The entire folder will be imported into your local model library.";
"K Cache Quantization" = "Quantification du cache K";
"V Cache Quantization" = "Quantification du cache V";
"Favorite Limit Reached" = "Limite de favoris atteinte";
"Overview" = "Aperçu";
"Sampling" = "Échantillonnage";
"Speculative Decoding" = "Décodage spéculatif";
"Benchmark" = "Benchmark";
"Maintenance" = "Maintenance";
"MLX" = "MLX";
"Tokenizer Path (tokenizer.json)" = "Chemin du tokenizer (tokenizer.json)";
"Back" = "Retour";
"Favorite Model" = "Modèle favori";
"Reset to Default Settings" = "Réinitialiser aux réglages par défaut";
"Delete Model" = "Supprimer le modèle";
"Delete %@?" = "Supprimer %@ ?";
"Not provided by repository" = "Non fourni par le dépôt";
"Unknown (not checked yet)" = "Inconnu (pas encore vérifié)";
"Keep Model In Memory" = "Garder le modèle en mémoire";
"GPU Offload Layers: %@/%@" = "Couches GPU déchargées : %1$@/%2$@";
"CPU Threads: %@" = "Threads CPU : %@";
"Offload KV Cache to GPU" = "Décharger le cache KV vers le GPU";
"Use mmap()" = "Utiliser mmap()";
"Random" = "Aléatoire";
"Flash Attention" = "Flash Attention";
"1 expert" = "1 expert";
"%@ experts" = "%@ experts";
"Helper Model" = "Modèle assistant";
"Draft strategy" = "Stratégie de brouillon";
"Run Benchmark" = "Lancer le benchmark";
"Benchmarking…" = "Benchmark en cours…";
"Leap SLM models manage runtime optimizations automatically." = "Les modèles Leap SLM gèrent automatiquement les optimisations d'exécution.";
"This format doesn't expose tunable runtime optimizations." = "Ce format n'expose pas d'optimisations runtime réglables.";
"Token processing" = "Traitement des tokens";
"Token generation" = "Génération de tokens";
"Total time" = "Temps total";
"First token" = "Premier token";
"Peak memory" = "Mémoire maximale";
"Output tokens" = "Tokens générés";
"End Guide" = "Terminer le guide";
"Streaming benchmark output…" = "Diffusion des résultats du benchmark…";
"Streaming… %@ chunks (~%@ tok est.)" = "Streaming… %1$@ blocs (~%2$@ jetons estim.)";
"Streaming… %d chunks (~%d tok est.)" = "Streaming… %d blocs (~%d jetons estim.)";
"The selected model's weights could not be located." = "Les poids du modèle sélectionné sont introuvables.";
"Failed to load model for benchmark: %@" = "Échec du chargement du modèle pour le benchmark : %@";
"Benchmark generation failed: %@" = "Échec de la génération du benchmark : %@";
"K Cache" = "Cache K";
"V Cache" = "Cache V";
"KV Offload" = "Offload KV";
"On" = "Activé";
"Off" = "Désactivé";
"GPU" = "GPU";
"CPU" = "CPU";
"%.1f tok/s" = "%.1f tok/s";
"%.1fs" = "%.1fs";
"%.2fs" = "%.2fs";
"Move Up" = "Déplacer vers le haut";
"Move Down" = "Déplacer vers le bas";
"Remove" = "Supprimer";
"Startup remote options" = "Options de démarrage distant";
"No models cached yet. Open the backend to refresh its catalog." = "Aucun modèle mis en cache. Ouvrez le backend pour actualiser son catalogue.";
"We'll try this saved identifier even though it's not in the latest catalog." = "Nous essaierons cet identifiant enregistré même s'il n'apparaît pas dans le dernier catalogue.";
"This backend is unavailable. Remove it or pick another option." = "Ce backend est indisponible. Supprimez-le ou choisissez une autre option.";
"Backend removed" = "Backend supprimé";
"What is Max Chunks?" = "Qu'est-ce que le nombre maximal de blocs ?";
"What is Similarity Threshold?" = "Qu'est-ce que le seuil de similarité ?";
"Approx. %@" = "Env. %@";
"Advanced mode shows developer options and diagnostics." = "Le mode avancé affiche les options développeur et les diagnostics.";
"Simple mode hides advanced settings for a cleaner interface." = "Le mode simple masque les réglages avancés pour une interface plus épurée.";
"Hide advanced controls" = "Masquer les contrôles avancés";
"Show advanced controls" = "Afficher les contrôles avancés";
"Adjust model settings" = "Ajuster les réglages du modèle";
"Model Settings" = "Réglages du modèle";
"SLM models are not supported on this platform." = "Les modèles SLM ne sont pas pris en charge sur cette plateforme.";
"Model likely exceeds memory budget. Lower context or choose a smaller quant." = "Le modèle dépasse probablement le budget mémoire. Réduisez le contexte ou choisissez un quant plus petit.";
"Apple bundle models aren't supported on macOS yet." = "Les modèles Apple bundle ne sont pas encore pris en charge sur macOS.";
"Estimate: %@\nBudget: %@\nContext length: %@ tokens\n\nThis is an estimate based on your device’s memory budget, context length (KV cache), and typical runtime overheads. Actual usage may vary." = "Estimation : %@\nBudget : %@\nLongueur de contexte : %@ tokens\n\nIl s'agit d'une estimation basée sur le budget mémoire de votre appareil, la longueur de contexte (cache KV) et les surcharges d'exécution typiques. Les valeurs réelles peuvent varier.";
"Model likely fits in RAM" = "Le modèle tient probablement en mémoire";
"Model may not fit in RAM" = "Le modèle pourrait ne pas tenir en mémoire";
"Fits in RAM (estimated)" = "Tient en mémoire (estimé)";
"May not fit (estimated)" = "Pourrait ne pas tenir (estimé)";
"Please provide a backend name." = "Veuillez fournir un nom de backend.";
"A backend with this name already exists." = "Un backend portant ce nom existe déjà.";
"Backend not found." = "Backend introuvable.";
"This Noema Relay device is already configured." = "Cet appareil Noema Relay est déjà configuré.";
"OpenAI API" = "OpenAI API";
"LM Studio" = "LM Studio";
"Ollama" = "Ollama";
"Cloud Relay" = "Cloud Relay";
"Noema Relay" = "Noema Relay";
"Compatible with OpenAI-style /v1 endpoints" = "Compatible avec les endpoints /v1 de type OpenAI";
"Connect to LM Studio's REST server" = "Connectez-vous au serveur REST de LM Studio";
"Target an Ollama host for chat and pulls" = "Cibler un hôte Ollama pour le chat et les téléchargements";
"Use Noema's Cloud Relay on macOS" = "Utiliser le Cloud Relay de Noema sur macOS";
"Pair with your Mac over CloudKit" = "Appairer avec votre Mac via CloudKit";
"Please provide the CloudKit container identifier." = "Veuillez saisir l’identifiant du conteneur CloudKit.";
"Please provide the host device ID from the Mac relay." = "Veuillez saisir l’identifiant de l’appareil hôte du relais Mac.";
"Missing host device ID for Noema Relay." = "Identifiant de l’appareil hôte manquant pour Noema Relay.";
"Missing CloudKit container identifier." = "Identifiant du conteneur CloudKit manquant.";
"Relay catalog unavailable." = "Catalogue du relais indisponible.";
"Relay catalog is still syncing. Open the Mac relay, ensure it is signed into iCloud, then try again in a moment." = "Le catalogue du relais est encore en cours de synchronisation. Ouvrez le relais sur le Mac, vérifiez la connexion iCloud, puis réessayez.";
"Terms of Use" = "Conditions d’utilisation";
"Privacy Policy" = "Politique de confidentialité";
"Contact Support" = "Contacter le support";
"Write a Review" = "Rédiger un avis";
"Notes & Issues" = "Notes et problèmes";
"Qwen3-1.7B is a compact and efficient model from the Qwen3 family, suitable for on-device usage with strong general capabilities." = "Qwen3-1.7B est un modèle compact et efficace de la famille Qwen3, adapté à l’usage embarqué avec de solides capacités générales.";
"Gemma 3n E2B is a lightweight instruction-tuned model from Google's Gemma family, optimized for efficient on-device conversations." = "Gemma 3n E2B est un modèle léger, affiné pour les instructions, issu de la famille Gemma de Google, optimisé pour des conversations locales efficaces.";
"Gemma 3n E2B is an instruction-tuned variant of Google's Gemma family built for efficient reasoning on low-resource devices.\nAvailable in GGUF quants (Q3_K_M, Q4_K_M, Q6_K) and an MLX 4-bit build for Apple Silicon.\n" = "Gemma 3n E2B est une variante orientée instructions de la famille Gemma, conçue pour un raisonnement efficace sur des appareils à ressources limitées.\nDisponible en quants GGUF (Q3_K_M, Q4_K_M, Q6_K) et en build MLX 4 bits pour Apple Silicon.\n";
"Phi-4 Mini Reasoning is a lightweight model from the Phi-4 family, tuned for strong reasoning and efficiency across tasks." = "Phi-4 Mini Reasoning est un modèle léger de la famille Phi-4, optimisé pour le raisonnement et l’efficacité sur diverses tâches.";
"Phi-4 Mini Reasoning — a compact model in Microsoft’s Phi-4 line designed for logical reasoning, problem solving, and instruction-following. \nDistributed in efficient GGUF quants (Q3_K_L, Q4_K_M, Q6_K) and an MLX 4-bit variant for Apple Silicon devices.\n" = "Phi-4 Mini Reasoning — un modèle compact de la gamme Phi-4 de Microsoft, conçu pour le raisonnement logique, la résolution de problèmes et le suivi d'instructions.\nDistribué en quants GGUF efficaces (Q3_K_L, Q4_K_M, Q6_K) et en variante MLX 4 bits pour les appareils Apple Silicon.\n";
"Runtime Safety" = "Sécurité à l'exécution";
"Bypass RAM safety check (may cause crashes)" = "Ignorer le contrôle de sécurité RAM (peut provoquer des plantages)";
"Estimate for" = "Estimation pour";
"Off-grid Mode" = "Mode hors ligne total";
"Delete All Chats" = "Supprimer toutes les conversations";
"Reset App Data" = "Réinitialiser les données de l'app";
"Max Chunks" = "Nombre maximal de blocs";
"Delete Embedding Model" = "Supprimer le modèle d'embedding";
"Override the app language. Defaults to the device language on first launch." = "Remplacer la langue de l’app. Par défaut, celle de l’appareil est utilisée au premier lancement.";
"Swap between the new stacked chat panel and the classic tab bar layout." = "Basculer entre le nouveau panneau de chat empilé et l’ancienne barre d’onglets.";
"Available Quantizations" = "Quantifications disponibles";
"Sort quantizations" = "Trier les quantifications";
"Quant" = "Quant";
"Size ↑" = "Taille ↑";
"Size ↓" = "Taille ↓";
"Model Library" = "Bibliothèque de modèles";
"Type to filter models…" = "Saisissez pour filtrer les modèles…";
"No models match your search." = "Aucun modèle ne correspond à votre recherche.";
"Browse Explore tab" = "Ouvrir l’onglet Explorer";
"Manually choose parameters" = "Choisir les paramètres manuellement";
"The base URL looks invalid. Please include the host (e.g. http://127.0.0.1:1234)." = "L’URL de base semble invalide. Incluez l’hôte (ex. http://127.0.0.1:1234).";
"Could not build the remote endpoint URL." = "Impossible de construire l’URL du point de terminaison distant.";
"The server returned an unexpected response." = "Le serveur a renvoyé une réponse inattendue.";
"Server responded with status code %d." = "Le serveur a répondu avec le code d’état %d.";
"Server responded with status code %d: %@" = "Le serveur a répondu avec le code %1$d : %2$@";
"Failed to decode server response." = "Échec du décodage de la réponse du serveur.";

"Model doesn't support GPU offload" = "Le modèle ne prend pas en charge le déchargement GPU";
"Loading model…" = "Chargement du modèle…";
"Select a model to load" = "Sélectionnez un modèle à charger";
"Please wait" = "Veuillez patienter";
"Models Library" = "Bibliothèque de modèles";
"Sort" = "Trier";
"Recency" = "Récence";
"Size" = "Taille";
"Name" = "Nom";
"Load Failed" = "Échec du chargement";
"Don't show again" = "Ne plus afficher";

"Explore" = "Explorer";
"Search datasets" = "Rechercher des jeux de données";
"Download" = "Télécharger";
"Offline" = "Hors ligne";
"Tap to load" = "Touchez pour charger";
"%d models" = "%d modèles";
"Updated %@" = "Mis à jour %@";
"No models fetched yet" = "Aucun modèle récupéré pour le moment";
"Auth" = "Auth";
"Local Network" = "Réseau local";
"Direct" = "Direct";
"LAN" = "LAN";
"LAN · %@" = "LAN · %@";

/* Noema Relay – pairing & dataset helpers */
"Model file missing (.gguf)" = "Fichier de modèle manquant (.gguf)";
"Model path missing" = "Chemin du modèle manquant";
"Imported Dataset" = "Jeu de données importé";
"Dataset name" = "Nom du jeu de données";
"Keep this device near the Mac that's running Noema Relay to import its settings." = "Gardez cet appareil à proximité du Mac qui exécute Noema Relay pour en importer les réglages.";
"Scanning for your Mac relay…" = "Recherche de votre relais Mac…";
"Ready to scan nearby relays" = "Prêt à rechercher les relais à proximité";
"Bluetooth access is required to pair with the Mac relay." = "L’accès Bluetooth est requis pour jumeler avec le relais Mac.";
"Stop Scanning" = "Arrêter la recherche";
"Start Scan" = "Lancer la recherche";
"Connection verified. Relay details imported from this Mac." = "Connexion vérifiée. Détails du relais importés depuis ce Mac.";
"Signal strength unavailable" = "Intensité du signal indisponible";
"Very close" = "Très proche";
"Nearby" = "À proximité";
"Within one room" = "Dans la même pièce";
"Move closer for a stronger signal" = "Rapprochez-vous pour obtenir un signal plus puissant.";
"This Mac" = "Ce Mac";

/* Accessibility announcements */
"Model loaded." = "Modèle chargé.";
"Prompt submitted." = "Prompt envoyé.";
"Generating response…" = "Génération de la réponse…";
"Response generated." = "Réponse générée.";

/* Tabs & accessibility labels */
"Stored" = "Stocké";
"Web Search" = "Recherche Web";
"Open Stored" = "Ouvrir Stocké";
"Message input" = "Saisie du message";
"What is Web Search button?" = "Qu’est-ce que le bouton Recherche Web ?";
"Backend" = "Backend";
"Base URL" = "URL de base";
"Chat Path" = "Chemin du chat";
"Models Path" = "Chemin des modèles";
"Endpoint Type" = "Type d’endpoint";
"Endpoints" = "Endpoints";
"Authentication" = "Authentification";
"Model Identifiers" = "Identifiants de modèles";
"Name" = "Nom";
"Host device ID" = "ID de l’appareil hôte";
"Host Device ID" = "ID de l’appareil hôte";
"CloudKit container identifier" = "Identifiant du conteneur CloudKit";
"Field requirements will depend on your specific backend deployment." = "Les champs requis dépendent de votre déploiement backend.";
"Uses Noema Relay configuration" = "Utilise la configuration Noema Relay";
"Chat: %@\nModels: %@" = "Chat : %@\nModèles : %@";
"Download Dataset" = "Télécharger le jeu de données";
"No files listed for this dataset." = "Aucun fichier répertorié pour ce jeu de données.";
"This dataset's files are not currently supported for document retrieval." = "Les fichiers de ce jeu de données ne sont actuellement pas pris en charge pour la recherche de documents.";
"Supported formats: %@" = "Formats pris en charge : %@";
"Try another dataset if these formats aren't available." = "Essayez un autre jeu de données si ces formats ne sont pas disponibles.";
"Found unsupported: %@ …" = "Formats non pris en charge trouvés : %@ …";
"This textbook appears to be available only as a web page. Noema can't import it as a dataset." = "Ce manuel semble uniquement disponible sous forme de page Web. Noema ne peut pas l’importer en tant que jeu de données.";
"Download complete" = "Téléchargement terminé";
"Downloading…" = "Téléchargement…";
"No compatible files found for retrieval. Supported formats: %@" = "Aucun fichier compatible trouvé pour la recherche. Formats pris en charge : %@";
"No internet connection." = "Pas de connexion Internet.";
"Request timed out. Please try again." = "Délai d’attente dépassé. Veuillez réessayer.";
"Connection was lost. Please try again." = "La connexion a été perdue. Veuillez réessayer.";
"Unexpected error: %@" = "Erreur inattendue : %@";

"Downloaded" = "Téléchargé";
"Compressed Text" = "Texte compressé";
"Small" = "Petit";
"Medium" = "Moyen";
"Large" = "Grand";
"Very Large" = "Très grand";
"Extreme" = "Extrême";
"Under 10 MB" = "Moins de 10 Mo";
"10–50 MB" = "10–50 Mo";
"50–200 MB" = "50–200 Mo";
"200–500 MB" = "200–500 Mo";
"Over 500 MB" = "Plus de 500 Mo";
"Estimated Embedding Time" = "Temps d'intégration estimé";
"Peak RAM Usage" = "Pic d'utilisation de la RAM";
"Dataset Size" = "Taille du jeu de données";
"Performance Note" = "Note de performance";
"Recommendation" = "Recommandation";
"Remember:" = "À retenir :";
"• Close other applications to free up RAM" = "• Fermez les autres applications pour libérer de la RAM";
"• Embedding happens locally on your device" = "• L'intégration se fait localement sur votre appareil";
"• Larger datasets take exponentially more time" = "• Les jeux de données plus grands prennent beaucoup plus de temps";
"• You can pause and resume downloads if needed" = "• Vous pouvez mettre les téléchargements en pause et les reprendre si besoin";
"Dataset Requirements" = "Exigences du jeu de données";
"Got it" = "Compris";
"Check Requirements" = "Vérifier les exigences";
"< 1 minute" = "< 1 minute";
"%d minutes" = "%d minutes";
"This dataset should embed quickly with minimal resource usage. Perfect for testing and quick experiments." = "Ce jeu de données devrait s'intégrer rapidement avec un minimum de ressources. Parfait pour les tests et expériences rapides.";
"This dataset is a reasonable size for most systems. Embedding should complete in a few minutes." = "Ce jeu de données a une taille raisonnable pour la plupart des systèmes. L'intégration devrait se terminer en quelques minutes.";
"This is a substantial dataset. Ensure you have adequate RAM and expect embedding to take 10–30 minutes." = "C'est un jeu de données conséquent. Assurez-vous d'avoir suffisamment de RAM et prévoyez 10 à 30 minutes d'intégration.";
"This is a very large dataset. Embedding may take 30–60 minutes and requires significant RAM." = "C'est un très grand jeu de données. L'intégration peut durer 30 à 60 minutes et requiert beaucoup de RAM.";
"This is an extremely large dataset. Consider splitting it into smaller parts for better performance." = "C'est un jeu de données extrêmement volumineux. Envisagez de le découper en parties plus petites pour de meilleures performances.";
"Go ahead and download! This size works well on all systems." = "Allez-y et téléchargez ! Cette taille fonctionne bien sur tous les systèmes.";
"Recommended for most users. Make sure you have at least 4GB of free RAM." = "Recommandé pour la plupart des utilisateurs. Assurez-vous de disposer d'au moins 4 Go de RAM libre.";
"Recommended only if you have 8GB+ RAM available. Close other applications before embedding." = "Recommandé uniquement si vous avez plus de 8 Go de RAM disponible. Fermez les autres applications avant l'intégration.";
"Recommended only for systems with 16GB+ RAM. Consider processing during off-hours." = "Recommandé seulement pour les systèmes avec au moins 16 Go de RAM. Envisagez de traiter en dehors des heures de travail.";
"Not recommended for typical systems. Consider finding a smaller version or subset of this dataset." = "Non recommandé pour les systèmes classiques. Cherchez une version plus petite ou un sous-ensemble de ce jeu de données.";
"Sample dataset" = "Jeu de données d'exemple";
"Ready" = "Prêt";
"Open" = "Ouvrir";

/* Mac chat quick-load menu */
"Open Model Library" = "Bibliothèque de modèles";
"Favorites" = "Favoris";
"Recent" = "Récents";
