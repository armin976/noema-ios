/* Auto-generated localization file. */
"%@" = "%@";
"%@ %" = "%1$@ %2$";
"%@ %@" = "%1$@ %2$@";
"%@ models" = "%@ मॉडल";
"%@ of %@ budget" = "%2$@ बजट का %1$@";
"%@ tokens" = "%@ टोकन";
"%@ – %@" = "%1$@ – %2$@";
"%@ • %@" = "%1$@ • %2$@";
"%@%" = "%1$@%2$";
"%@% · %@" = "%1$@%2$ · %3$@";
"%@." = "%@.";
"%@:" = "%@:";
"(+ mmproj %@%)" = "(+ mmproj %1$@%2$)";
"... and %@ more" = "... और %@ अधिक";
"320 MB • One-time download" = "320 एमबी • एक बार डाउनलोड";
"320 MB • One‑time download used for local dataset search" = "320 एमबी • स्थानीय डेटासेट खोज के लिए एक बार डाउनलोड का उपयोग किया जाता है";
"A larger context keeps more conversation history, but also uses more memory. Adjust it here." = "एक बड़ा संदर्भ अधिक वार्तालाप इतिहास रखता है, लेकिन अधिक मेमोरी का भी उपयोग करता है। इसे यहां समायोजित करें.";
"Active" = "सक्रिय";
"Active Model" = "सक्रिय मॉडल";
"Active connection via %@" = "%@ के माध्यम से सक्रिय कनेक्शन";
"Active experts per token: %@ of %@" = "प्रति टोकन सक्रिय विशेषज्ञ: %1$@ में से %2$@";
"Add a remote backend to configure remote startup fallbacks." = "दूरस्थ स्टार्टअप फ़ॉलबैक को कॉन्फ़िगर करने के लिए एक दूरस्थ बैकएंड जोड़ें।";
"Add one or two datasets (like open textbooks) to keep responses accurate and help the AI cite sources." = "प्रतिक्रियाओं को सटीक रखने और एआई को स्रोतों का हवाला देने में मदद करने के लिए एक या दो डेटासेट (जैसे खुली पाठ्यपुस्तकें) जोड़ें।";
"Add remote endpoint" = "दूरस्थ समापनबिंदु जोड़ें";
"Adjust appearance, privacy options, and network preferences here." = "यहां उपस्थिति, गोपनीयता विकल्प और नेटवर्क प्राथमिकताएं समायोजित करें।";
"Advanced" = "विकसित";
"Advanced Controls" = "उन्नत नियंत्रण";
"Allows models to use a privacy-preserving web search API when you tap the globe in chat. Default is ON. In Offline Only mode, the button is disabled." = "जब आप चैट में ग्लोब पर टैप करते हैं तो मॉडलों को गोपनीयता-संरक्षित वेब खोज एपीआई का उपयोग करने की अनुमति मिलती है। डिफ़ॉल्ट चालू है. केवल ऑफ़लाइन मोड में, बटन अक्षम है।";
"Analyzing context..." = "संदर्भ का विश्लेषण किया जा रहा है...";
"App Memory Usage (estimated)" = "ऐप मेमोरी उपयोग (अनुमानित)";
"App memory usage budget: %@ (conservative)" = "ऐप मेमोरी उपयोग बजट: %@ (रूढ़िवादी)";
"Approx. Tokens" = "लगभग। टोकन";
"Arm web search when you truly need outside info. It has a small daily limit and most chats don’t require it." = "जब आपको वास्तव में बाहरी जानकारी की आवश्यकता हो तो वेब सर्च करें। इसकी एक छोटी दैनिक सीमा है और अधिकांश चैट के लिए इसकी आवश्यकता नहीं होती है।";
"Ask Noema anything" = "नोएमा से कुछ भी पूछें";
"Ask…" = "पूछना…";
"Attach Photos" = "फ़ोटो संलग्न करें";
"Backend not found" = "बैकएंड नहीं मिला";
"Benchmark running…" = "बेंचमार्क चल रहा है...";
"Benchmarking is not available for this model format." = "इस मॉडल प्रारूप के लिए बेंचमार्किंग उपलब्ध नहीं है।";
"Blocks all network traffic, model downloads, and cloud connections so everything stays on‑device." = "सभी नेटवर्क ट्रैफ़िक, मॉडल डाउनलोड और क्लाउड कनेक्शन को ब्लॉक कर देता है ताकि सब कुछ डिवाइस पर बना रहे।";
"Bluetooth Pairing" = "ब्लूटूथ पेयरिंग";
"Browse community models and curated datasets to expand what Noema can do." = "नोएमा क्या कर सकता है इसका विस्तार करने के लिए सामुदायिक मॉडल और क्यूरेटेड डेटासेट ब्राउज़ करें।";
"Browse curated datasets for retrieval" = "पुनर्प्राप्ति के लिए क्यूरेटेड डेटासेट ब्राउज़ करें";
"CFBundleShortVersionString1.0" = "CFBundleShortVersionString1.0";
"Cancel" = "रद्द करना";
"Cancel Benchmark" = "बेंचमार्क रद्द करें";
"Discover Intelligence" = "बुद्धिमत्ता खोजें";
"Catalog" = "सूची";
"Chat" = "बात करना";
"Chat privately with your local models, sync datasets, and manage the relay server in one place." = "अपने स्थानीय मॉडलों के साथ निजी तौर पर चैट करें, डेटासेट सिंक करें और रिले सर्वर को एक ही स्थान पर प्रबंधित करें।";
"Chats" = "चैट";
"Checking…" = "जाँच हो रही है...";
"Citation %@" = "उद्धरण %@";
"Cloud Relay Container" = "क्लाउड रिले कंटेनर";
"Cloud Relay via CloudKit (auto-discovery and Bluetooth pairing)" = "CloudKit के माध्यम से क्लाउड रिले (ऑटो-डिस्कवरी और ब्लूटूथ पेयरिंग)";
"CloudKit" = "क्लाउडकिट";
"CloudKit bridge active. Local replies are generated on this Mac." = "क्लाउडकिट ब्रिज सक्रिय। इस मैक पर स्थानीय उत्तर उत्पन्न होते हैं।";
"Compiling Metal kernels for GGUF models can take up to a minute on first load." = "जीजीयूएफ मॉडल के लिए मेटल कर्नेल को संकलित करने में पहले लोड पर एक मिनट तक का समय लग सकता है।";
"Complete the streaming response in the active chat before sending again." = "दोबारा भेजने से पहले सक्रिय चैट में स्ट्रीमिंग प्रतिक्रिया पूरी करें।";
"Confirm and Start Embedding" = "पुष्टि करें और एम्बेड करना प्रारंभ करें";
"Connected" = "जुड़े हुए";
"Connection Modes" = "कनेक्शन मोड";
"Connection Status: %@" = "कनेक्शन स्थिति: %@";
"Container" = "पात्र";
"Context Length" = "प्रसंग लंबाई";
"Context Length: 4096 tokens" = "प्रसंग लंबाई: 4096 टोकन";
"Context length is under 5000 tokens. With images and multi-sequence decoding (n_seq_max=16), per-sequence memory can be too small, leading to a crash. Increase context to at least 8192 in Model Settings." = "प्रसंग की लंबाई 5000 टोकन से कम है। छवियों और बहु-अनुक्रम डिकोडिंग (n_seq_max=16) के साथ, प्रति-अनुक्रम मेमोरी बहुत छोटी हो सकती है, जिससे दुर्घटना हो सकती है। मॉडल सेटिंग्स में संदर्भ को कम से कम 8192 तक बढ़ाएं।";
"Controls how many high‑scoring passages (chunks) can be injected into the prompt. Higher values increase recall but consume more context window and can slow responses. Typical range 3–6." = "यह नियंत्रित करता है कि प्रॉम्प्ट में कितने उच्च स्कोरिंग अंश (खंड) डाले जा सकते हैं। उच्च मान स्मरण को बढ़ाते हैं लेकिन अधिक संदर्भ विंडो का उपभोग करते हैं और प्रतिक्रियाओं को धीमा कर सकते हैं। विशिष्ट श्रेणी 3-6।";
"Couldn't load the recommended model." = "अनुशंसित मॉडल लोड नहीं किया जा सका.";
"Couldn’t load the recommended model right now." = "अभी अनुशंसित मॉडल लोड नहीं किया जा सका.";
"Creativity: %@. Low values focus responses; high values add variety." = "रचनात्मकता: %@. निम्न मान फ़ोकस प्रतिक्रियाएँ; उच्च मूल्य विविधता जोड़ते हैं।";
"Dark" = "अँधेरा";
"Dataset" = "डेटासेट";
"Dataset indexing in progress..." = "डेटासेट अनुक्रमण प्रगति पर है...";
"Dataset ready to use" = "डेटासेट उपयोग के लिए तैयार है";
"Datasets" = "डेटासेट";
"Datasets enrich the model with focused knowledge. Toggle one on to use it in chat." = "डेटासेट मॉडल को केंद्रित ज्ञान से समृद्ध करते हैं। चैट में इसका उपयोग करने के लिए एक को टॉगल करें।";
"Default selection (~%@) balances RAM usage against model quality." = "डिफ़ॉल्ट चयन (~%@) मॉडल गुणवत्ता के विरुद्ध RAM उपयोग को संतुलित करता है।";
"Delete" = "मिटाना";
"Delete Dataset" = "डेटासेट हटाएं";
"Deletes all chats, downloaded models, and datasets, and restores settings to defaults. The embedding model stays installed." = "सभी चैट, डाउनलोड किए गए मॉडल और डेटासेट हटा देता है, और सेटिंग्स को डिफ़ॉल्ट पर पुनर्स्थापित करता है। एम्बेडिंग मॉडल स्थापित रहता है।";
"Device" = "उपकरण";
"Digest:" = "पाचन:";
"Done" = "हो गया";
"Done!" = "हो गया!";
"Download Now" = "अब डाउनलोड करो";
"Download a model from Explore or add a remote endpoint to get started." = "आरंभ करने के लिए एक्सप्लोर से एक मॉडल डाउनलोड करें या एक रिमोट एंडपॉइंट जोड़ें।";
"Download a small embedding model so Noema can index and search your datasets" = "एक छोटा एम्बेडिंग मॉडल डाउनलोड करें ताकि नोएमा आपके डेटासेट को अनुक्रमित और खोज सके";
"Downloaded datasets need on-device embedding. Give it a few minutes after download finishes." = "डाउनलोड किए गए डेटासेट को ऑन-डिवाइस एम्बेडिंग की आवश्यकता होती है। डाउनलोड समाप्त होने के बाद इसे कुछ मिनट दें।";
"Downloaded models and datasets live here so you can manage them offline." = "डाउनलोड किए गए मॉडल और डेटासेट यहां रहते हैं ताकि आप उन्हें ऑफ़लाइन प्रबंधित कर सकें।";
"Downloading…" = "डाउनलोड हो रहा है...";
"Draft tokens: %@" = "ड्राफ्ट टोकन: %@";
"Draft window: %@" = "ड्राफ्ट विंडो: %@";
"EPUB viewing not supported on this platform" = "इस प्लेटफ़ॉर्म पर EPUB देखना समर्थित नहीं है";
"Embedding" = "एम्बेडिंग";
"Embedding Model Ready" = "एंबेडिंग मॉडल तैयार";
"Embedding is resource intensive. For best performance, plug in your phone. Do you want to proceed on battery?" = "एंबेडिंग संसाधन गहन है। सर्वोत्तम प्रदर्शन के लिए, अपने फ़ोन को प्लग इन करें। क्या आप बैटरी पर आगे बढ़ना चाहते हैं?";
"Enabling Bluetooth…" = "ब्लूटूथ सक्षम किया जा रहा है...";
"Enhance with Datasets" = "डेटासेट के साथ सुधार करें";
"Error" = "गलती";
"Estimated working set: %@ · Budget: %@" = "अनुमानित कार्य सेट: %1$@ · बजट: %2$@";
"Experts Per Token" = "प्रति टोकन विशेषज्ञ";
"Explore Datasets" = "डेटासेट का अन्वेषण करें";
"Expose any downloaded models or connected remote endpoints from the Stored tab to your paired devices. Select which one should answer conversations when the relay is running." = "संग्रहीत टैब से किसी भी डाउनलोड किए गए मॉडल या कनेक्टेड रिमोट एंडपॉइंट को अपने युग्मित डिवाइस पर प्रदर्शित करें। चुनें कि रिले चलने पर किसे बातचीत का उत्तर देना चाहिए।";
"Expose to iOS" = "आईओएस को उजागर करें";
"Explore the latest open-source models optimized for your Mac." = "अपने Mac के लिए अनुकूलित नवीनतम मुक्त स्रोत मॉडलों का अन्वेषण करें।";
"Failed to load README" = "README लोड करने में विफल";
"Failed: %@" = "विफल: %@";
"Fastest option on this device: SLM (Leap) models." = "इस डिवाइस पर सबसे तेज़ विकल्प: एसएलएम (लीप) मॉडल।";
"Field requirements will depend on your specific backend deployment." = "फ़ील्ड आवश्यकताएँ आपके विशिष्ट बैकएंड परिनियोजन पर निर्भर करेंगी।";
"Files" = "फ़ाइलें";
"First, enable fast dataset search" = "सबसे पहले, तेज़ डेटासेट खोज सक्षम करें";
"First-time GGUF load takes longer" = "पहली बार GGUF लोड होने में अधिक समय लगता है";
"First-time download from HuggingFace" = "हगिंगफेस से पहली बार डाउनलोड करें";
"First‑time setup: download the Qwen‑1.7B model and embeddings.\nWi‑Fi recommended." = "पहली बार सेटअप: Qwen‑1.7B मॉडल और एम्बेडिंग डाउनलोड करें।\nवाई-फ़ाई अनुशंसित.";
"For best performance, please plug in your phone until this completes." = "सर्वोत्तम प्रदर्शन के लिए, कृपया यह पूरा होने तक अपने फ़ोन को प्लग इन करें।";
"Force Local Network" = "स्थानीय नेटवर्क को बाध्य करें";
"Forces chat traffic through the last LAN host even if Wi‑Fi names don't match yet." = "भले ही वाई-फ़ाई नाम अभी तक मेल न खाते हों, अंतिम LAN होस्ट के माध्यम से चैट ट्रैफ़िक को बाध्य करता है।";
"Formatted view unavailable" = "स्वरूपित दृश्य अनुपलब्ध है";
"Found unsupported: %@ …" = "असमर्थित पाया गया: %@ …";
"Frequency penalty: %@" = "फ़्रिक्वेंसी जुर्माना: %@";
"GGUF models are the most compatible option. Use the format switch to explore the other builds when you need them." = "जीजीयूएफ मॉडल सबसे अनुकूल विकल्प हैं। जब आपको आवश्यकता हो तो अन्य बिल्डों का पता लगाने के लिए प्रारूप स्विच का उपयोग करें।";
"GGUF works everywhere. MLX targets Apple Silicon speed. SLM focuses on responsiveness on any device." = "जीजीयूएफ हर जगह काम करता है। MLX Apple सिलिकॉन स्पीड को लक्षित करता है। एसएलएम किसी भी डिवाइस पर प्रतिक्रिया पर ध्यान केंद्रित करता है।";
"GPU Offload Layers" = "जीपीयू ऑफलोड परतें";
"GPU off-load is not supported for this model." = "इस मॉडल के लिए GPU ऑफ-लोड समर्थित नहीं है।";
"Get Started" = "शुरू हो जाओ";
"Help shape Noema by trying upcoming features and sharing feedback." = "आगामी सुविधाओं को आज़माकर और फीडबैक साझा करके नोएमा को आकार देने में मदद करें।";
"High context lengths use more memory" = "उच्च संदर्भ लंबाई अधिक मेमोरी का उपयोग करती है";
"High-quality embedding model for local RAG" = "स्थानीय आरएजी के लिए उच्च गुणवत्ता वाला एम्बेडिंग मॉडल";
"Host ID: %@" = "होस्ट आईडी: %@";
"How it works" = "यह काम किस प्रकार करता है";
"I'm New to Local LLMs, Guide Me" = "मैं स्थानीय एलएलएम में नया हूं, मेरा मार्गदर्शन करें";
"If enabled, the app will attempt to load models even when they likely exceed your device's memory budget. This can cause the app to terminate." = "यदि सक्षम किया गया है, तो ऐप तब भी मॉडल लोड करने का प्रयास करेगा जब वे आपके डिवाइस के मेमोरी बजट से अधिक हो जाएं। इससे ऐप बंद हो सकता है.";
"Import Dataset" = "डेटासेट आयात करें";
"Import PDFs, EPUBs, or text files to build local knowledge bases." = "स्थानीय ज्ञानकोष बनाने के लिए पीडीएफ, ईपीयूबी या टेक्स्ट फ़ाइलें आयात करें।";
"Import your own PDFs, EPUBs, or TXT files and keep them local." = "अपनी स्वयं की PDF, EPUB, या TXT फ़ाइलें आयात करें और उन्हें स्थानीय रखें।";
"Importing & Scanning..." = "आयात एवं स्कैनिंग...";
"In progress..." = "प्रगति पर है...";
"Indexing %@" = "अनुक्रमण %@";
"Indexing dataset…" = "डेटासेट को अनुक्रमित किया जा रहा है...";
"Indexing: %@% · %@" = "अनुक्रमण: %1$@%2$ · %3$@";
"Install a local model to make it available at launch." = "इसे लॉन्च के समय उपलब्ध कराने के लिए एक स्थानीय मॉडल स्थापित करें।";
"Install another model with the same architecture and equal or smaller size to enable speculative decoding." = "सट्टा डिकोडिंग को सक्षम करने के लिए समान आर्किटेक्चर और समान या छोटे आकार के साथ एक और मॉडल स्थापित करें।";
"K Cache Quant" = "के कैश क्वांट";
"Keep this iPhone or iPad within a few feet of the Mac that is advertising Noema Relay. We'll pull the relay details automatically once connected." = "इस iPhone या iPad को उस Mac से कुछ फीट की दूरी पर रखें जो Noema Relay का विज्ञापन कर रहा है। एक बार कनेक्ट होने पर हम रिले विवरण स्वचालित रूप से खींच लेंगे।";
"LAN URL: %@" = "लैन यूआरएल: %@";
"Large Model Downloads" = "बड़े मॉडल डाउनलोड";
"Last Sync" = "अंतिम सिंक";
"Last refreshed %@" = "अंतिम बार ताज़ा किया गया %@";
"Latest benchmark" = "नवीनतम बेंचमार्क";
"Latest integrated release: %@" = "नवीनतम एकीकृत रिलीज़: %@";
"Library" = "पुस्तकालय";
"Light" = "रोशनी";
"Llama.cpp" = "कॉल.सीपीपी";
"Load" = "भार";
"Load a local model before chatting. You can download one from the Explore tab or load a model you've already installed." = "चैट करने से पहले एक स्थानीय मॉडल लोड करें. आप एक्सप्लोर टैब से एक डाउनलोड कर सकते हैं या पहले से इंस्टॉल किए गए मॉडल को लोड कर सकते हैं।";
"Loading recommendation…" = "सिफ़ारिश लोड हो रही है...";
"Loading…" = "लोड हो रहा है...";
"Local Network HTTP server for LAN clients (OpenAI-compatible)" = "LAN क्लाइंट के लिए स्थानीय नेटवर्क HTTP सर्वर (OpenAI-संगत)";
"Low = focused. High = varied." = "निम्न = केंद्रित. उच्च = विविध।";
"Lower = more results (more noise). Higher = stricter matches." = "कम = अधिक परिणाम (अधिक शोर)। उच्चतर = सख्त मिलान।";
"MLX currently manages expert routing automatically; manual selection is not supported." = "एमएलएक्स वर्तमान में विशेषज्ञ रूटिंग को स्वचालित रूप से प्रबंधित करता है; मैन्युअल चयन समर्थित नहीं है.";
"Many models are several gigabytes in size and require a stable connection and sufficient storage. Downloads can fail or take a long time on slow networks or devices with limited space." = "कई मॉडल कई गीगाबाइट आकार के होते हैं और उन्हें स्थिर कनेक्शन और पर्याप्त भंडारण की आवश्यकता होती है। धीमे नेटवर्क या सीमित स्थान वाले उपकरणों पर डाउनलोड विफल हो सकते हैं या इसमें लंबा समय लग सकता है।";
"Max Chunks: %@" = "अधिकतम टुकड़े: %@";
"Max recommended context on this device: ~%@ tokens" = "इस डिवाइस पर अधिकतम अनुशंसित संदर्भ: ~%@ टोकन";
"Measure real-world generation speed for this configuration. A short scripted prompt will run locally and report timing and memory usage." = "इस कॉन्फ़िगरेशन के लिए वास्तविक दुनिया की पीढ़ी की गति को मापें। एक लघु स्क्रिप्टेड प्रॉम्प्ट स्थानीय रूप से चलेगा और समय और मेमोरी उपयोग की रिपोर्ट करेगा।";
"Min-p" = "मिन-पी";
"Min-p: %@" = "न्यूनतम-पी: %@";
"Minimum cosine similarity a passage must have to be considered relevant. Lower = more passages (higher recall, more noise). Higher = fewer, more precise passages. Try 0.2–0.4 for broad questions; 0.5–0.7 for precise lookups." = "किसी परिच्छेद को न्यूनतम कोसाइन समानता के आधार पर प्रासंगिक माना जाना चाहिए। निचला = अधिक मार्ग (उच्च स्मरण, अधिक शोर)। उच्चतर = कम, अधिक सटीक मार्ग। व्यापक प्रश्नों के लिए 0.2-0.4 आज़माएँ; सटीक लुकअप के लिए 0.5–0.7।";
"MoE layers: %@ / %@" = "MoE परतें: %1$@ / %2$@";
"Model Detection Limitations" = "मॉडल का पता लगाने की सीमाएँ";
"Model Formats" = "मॉडल प्रारूप";
"Models" = "मॉडल";
"Models shown here are exposed by the Mac relay. Manage sources in the Relay tab on macOS to share more models." = "यहां दिखाए गए मॉडल मैक रिले द्वारा प्रदर्शित किए गए हैं। अधिक मॉडल साझा करने के लिए macOS पर रिले टैब में स्रोत प्रबंधित करें।";
"Move your device closer to the Mac running the relay if it doesn't appear right away. Bluetooth discovery usually completes within a few seconds." = "यदि रिले तुरंत दिखाई नहीं देता है तो अपने डिवाइस को रिले चलाने वाले मैक के करीब ले जाएं। ब्लूटूथ खोज आमतौर पर कुछ ही सेकंड में पूरी हो जाती है।";
"Name your dataset" = "अपने डेटासेट को नाम दें";
"Nearby Relays" = "निकटवर्ती रिले";
"Nearby iPhone and iPad devices discover your Mac relay instantly and sync pairing codes over the air." = "आस-पास के iPhone और iPad डिवाइस आपके Mac रिले को तुरंत खोज लेते हैं और पेयरिंग कोड को हवा में सिंक कर देते हैं।";
"Need a fresh thread? Tap the plus button for a brand-new conversation." = "ताज़ा धागे की आवश्यकता है? एकदम नई बातचीत के लिए प्लस बटन पर टैप करें।";
"Nice! You already have the recommended GGUF starter model ready to use." = "अच्छा! आपके पास पहले से ही अनुशंसित GGUF स्टार्टर मॉडल उपयोग के लिए तैयार है।";
"No compatible files found for retrieval. Supported: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV" = "पुनर्प्राप्ति के लिए कोई संगत फ़ाइल नहीं मिली. समर्थित: पीडीएफ, ईपीयूबी, टीएक्सटी, एमडी, जेएसओएन, जेएसओएनएल, सीएसवी, टीएसवी";
"No connection responses recorded yet." = "अभी तक कोई कनेक्शन प्रतिक्रिया दर्ज नहीं की गई है.";
"No datasets available yet. Import or download datasets to build your personal library." = "अभी तक कोई डेटासेट उपलब्ध नहीं है. अपनी निजी लाइब्रेरी बनाने के लिए डेटासेट आयात या डाउनलोड करें।";
"No datasets found. Try different keywords." = "कोई डेटासेट नहीं मिला. अलग-अलग कीवर्ड आज़माएं.";
"No datasets imported yet." = "अभी तक कोई डेटासेट आयात नहीं किया गया.";
"No datasets yet" = "अभी तक कोई डेटासेट नहीं";
"No files listed for this dataset." = "इस डेटासेट के लिए कोई फ़ाइल सूचीबद्ध नहीं है।";
"No model >" = "कोई मॉडल नहीं >";
"No model loaded" = "कोई मॉडल लोड नहीं किया गया";
"No models available. Add downloads or remote connections in Stored to configure the relay." = "कोई मॉडल उपलब्ध नहीं. रिले को कॉन्फ़िगर करने के लिए स्टोर्ड में डाउनलोड या रिमोट कनेक्शन जोड़ें।";
"No models cached yet. Open the backend to refresh its catalog." = "अभी तक कोई मॉडल कैश नहीं किया गया. इसके कैटलॉग को ताज़ा करने के लिए बैकएंड खोलें।";
"No models found for '%@'" = "'%@' के लिए कोई मॉडल नहीं मिला";
"No models loaded right now. We'll spin one up when a request arrives." = "अभी कोई मॉडल लोड नहीं किया गया. अनुरोध आने पर हम एक को खोल देंगे।";
"No models match your search." = "कोई भी मॉडल आपकी खोज से मेल नहीं खाता.";
"No models yet" = "अभी तक कोई मॉडल नहीं";
"No parameters" = "कोई पैरामीटर नहीं";
"No quant files available" = "कोई मात्रा फ़ाइल उपलब्ध नहीं है";
"No recent devices. We'll list clients the next time they talk to this relay." = "कोई नवीनतम उपकरण नहीं. अगली बार जब ग्राहक इस रिले से बात करेंगे तो हम उनकी सूची बनाएंगे।";
"No remote endpoints configured yet." = "अभी तक कोई दूरस्थ समापन बिंदु कॉन्फ़िगर नहीं किया गया है.";
"No remote endpoints configured." = "कोई दूरस्थ समापन बिंदु कॉन्फ़िगर नहीं किया गया.";
"No ≥Q3 quants are available for this model." = "इस मॉडल के लिए कोई ≥Q3 मात्रा उपलब्ध नहीं है।";
"Noema" = "नवंबर";
"Noema REST API — /api/v0/* for model catalog & operations" = "मॉडल कैटलॉग और संचालन के लिए नोएमा रेस्ट एपीआई - /api/v0/*";
"Noema Relay" = "नोएमा रिले";
"Noema Server" = "नोएमा सर्वर";
"Noema attempts to gauge available memory to prevent models from exceeding device limits. These checks may occasionally miss risky situations and allow a model to crash your app, or they may be overly conservative and block a model that could have run fine." = "नोएमा मॉडलों को डिवाइस की सीमा से अधिक होने से रोकने के लिए उपलब्ध मेमोरी को मापने का प्रयास करता है। ये जाँचें कभी-कभी जोखिम भरी स्थितियों में चूक सकती हैं और एक मॉडल को आपके ऐप को क्रैश करने की अनुमति दे सकती हैं, या वे अत्यधिक रूढ़िवादी हो सकते हैं और एक ऐसे मॉडल को ब्लॉक कर सकते हैं जो ठीक से चल सकता था।";
"Noema could not find a projector in the repository. If the model advertises vision, ensure the mmproj file is present in the same folder as the weights." = "नोएमा को भंडार में प्रोजेक्टर नहीं मिला। यदि मॉडल विज़न का विज्ञापन करता है, तो सुनिश्चित करें कि mmproj फ़ाइल वेट के समान फ़ोल्डर में मौजूद है।";
"Noema has been reset. The embedding model remains installed." = "नोएमा को रीसेट कर दिया गया है. एम्बेडिंग मॉडल स्थापित रहता है.";
"Nomic Embed Text v1.5 (Q4_K_M)" = "नॉमिक एंबेड टेक्स्ट v1.5 (Q4_K_M)";
"None" = "कोई नहीं";
"Not found" = "नहीं मिला";
"Not provided" = "उपलब्ध नहीं कराया";
"OK" = "ठीक है";
"Off-Grid" = "ग्रिड बंद करें";
"Off-grid mode blocks every network call so the app stays self-contained. Good luck exploring Noema!" = "ऑफ-ग्रिड मोड प्रत्येक नेटवर्क कॉल को ब्लॉक कर देता है ताकि ऐप स्व-निहित रहे। नोएमा की खोज में शुभकामनाएँ!";
"Only one expert is available for this model; the active expert count is fixed." = "इस मॉडल के लिए केवल एक विशेषज्ञ उपलब्ध है; सक्रिय विशेषज्ञ संख्या निश्चित है.";
"Open Stored to choose a model to run locally or connect to a remote endpoint." = "स्थानीय रूप से चलाने या रिमोट एंडपॉइंट से कनेक्ट करने के लिए एक मॉडल चुनने के लिए स्टोर्ड खोलें।";
"Open the sidebar to revisit any previous session without losing your spot." = "अपना स्थान खोए बिना किसी भी पिछले सत्र को दोबारा देखने के लिए साइडबार खोलें।";
"OpenAI-style API — /v1/chat/completions, /v1/completions, /v1/models" = "ओपनएआई-शैली एपीआई - /v1/चैट/पूर्णता, /v1/पूर्णता, /v1/मॉडल";
"Optimizations in use" = "उपयोग में अनुकूलन";
"PDF viewing not supported on this platform" = "इस प्लेटफ़ॉर्म पर पीडीएफ देखना समर्थित नहीं है";
"Pick a model and add a dataset" = "एक मॉडल चुनें और एक डेटासेट जोड़ें";
"Pick the SLM format when you want ultra-responsive models that run well anywhere." = "जब आप अल्ट्रा-रिस्पॉन्सिव मॉडल चाहते हैं जो कहीं भी अच्छा चलता हो तो एसएलएम प्रारूप चुनें।";
"Pinned answer" = "पिन किया गया उत्तर";
"Pinned answer unavailable" = "पिन किया गया उत्तर अनुपलब्ध है";
"Preparation" = "तैयारी";
"Preparing Embedding Model" = "एंबेडिंग मॉडल तैयार किया जा रहा है";
"Preparing benchmark…" = "बेंचमार्क तैयार किया जा रहा है...";
"Preparing…" = "तैयारी हो रही है...";
"Presence penalty: %@" = "उपस्थिति दंड: %@";
"Projector (mmproj)" = "प्रोजेक्टर (एमएमप्रोज)";
"Projector downloaded automatically from Hugging Face. Keep this file alongside the weights so vision remains available." = "प्रोजेक्टर हगिंग फेस से स्वचालित रूप से डाउनलोड हो गया। इस फ़ाइल को वज़न के साथ रखें ताकि दृष्टि उपलब्ध रहे।";
"Quantize the runtime key cache to save memory. Experimental." = "मेमोरी को बचाने के लिए रनटाइम कुंजी कैश को परिमाणित करें। प्रायोगिक.";
"Quantize the runtime value cache to save memory when Flash Attention is enabled. Experimental." = "फ्लैश अटेंशन सक्षम होने पर मेमोरी को बचाने के लिए रनटाइम वैल्यू कैश को परिमाणित करें। प्रायोगिक.";
"Qwen 3 1.7B GGUF (Q3_K_M) gives you a dependable starting point. Delete it anytime if you need space." = "Qwen 3 1.7B GGUF (Q3_K_M) आपको एक भरोसेमंद शुरुआती बिंदु देता है। यदि आपको स्थान की आवश्यकता हो तो इसे कभी भी हटा दें।";
"RAG embeds normalized paragraphs from your PDFs and EPUBs. On each question, the most relevant chunks are retrieved and added to the prompt. Images are ignored." = "RAG आपके PDF और EPUB से सामान्यीकृत पैराग्राफ एम्बेड करता है। प्रत्येक प्रश्न पर, सबसे प्रासंगिक भाग पुनर्प्राप्त किए जाते हैं और प्रॉम्प्ट में जोड़े जाते हैं। छवियों को नजरअंदाज कर दिया जाता है.";
"RAM Safety Checks" = "रैम सुरक्षा जांच";
"RAM information for this device will be added in a future update." = "इस डिवाइस की रैम जानकारी भविष्य के अपडेट में जोड़ी जाएगी।";
"REST Endpoints" = "बाकी समापनबिंदु";
"Reachable at" = "पर पहुंच योग्य";
"Ready for Use" = "उपयोग के लिए तैयार";
"Recent Chats" = "हाल की चैट";
"Recommended" = "अनुशंसित";
"Recommended Starter Model" = "अनुशंसित स्टार्टर मॉडल";
"Relay ID" = "रिले आईडी";
"Relay Server Running" = "रिले सर्वर चल रहा है";
"Relay Sources" = "रिले स्रोत";
"Remaining: %@" = "शेष: %@";
"Remember:" = "याद करना:";
"Remote Backends" = "रिमोट बैकएंड";
"Remote endpoint is offline. This model can't be found at this time." = "दूरस्थ समापन बिंदु ऑफ़लाइन है. यह मॉडल इस समय नहीं मिल सकता.";
"Remote timeout: %@s" = "रिमोट टाइमआउट: %@s";
"Repeat last N tokens: %@" = "अंतिम N टोकन दोहराएं: %@";
"Repetition penalty: %@" = "पुनरावृत्ति दंड: %@";
"Request Parameters" = "पैरामीटर्स का अनुरोध करें";
"Responses are generated by the macOS relay server. Configure the provider (LM Studio or Ollama) on the Mac app." = "प्रतिक्रियाएँ macOS रिले सर्वर द्वारा उत्पन्न होती हैं। मैक ऐप पर प्रदाता (एलएम स्टूडियो या ओलामा) को कॉन्फ़िगर करें।";
"Result" = "परिणाम";
"Results" = "परिणाम";
"Save" = "बचाना";
"Saving…" = "सहेजा जा रहा है...";
"Score: %@" = "स्कोर: %@";
"SearXNG web search is available without limits. There's nothing to purchase—just enable the globe button in chat whenever you need online results." = "SearXNG वेब खोज बिना किसी सीमा के उपलब्ध है। खरीदने के लिए कुछ भी नहीं है—जब भी आपको ऑनलाइन परिणामों की आवश्यकता हो तो चैट में ग्लोब बटन सक्षम करें।";
"SearXNG web search is enabled for this device." = "इस डिवाइस के लिए SearXNG वेब खोज सक्षम है।";
"Search" = "खोज";
"Search for any subject you're interested in." = "जिस भी विषय में आपकी रुचि हो उसे खोजें।";
"Search requests are proxied through https://search.noemaai.com and are available without quotas." = "खोज अनुरोध https://search.noemaai.com के माध्यम से प्रॉक्सी किए जाते हैं और बिना कोटा के उपलब्ध होते हैं।";
"Seed" = "बीज";
"Selecting more experts keeps additional expert weights resident in RAM and increases memory usage." = "अधिक विशेषज्ञों का चयन करने से रैम में अतिरिक्त विशेषज्ञ भार रहता है और मेमोरी का उपयोग बढ़ता है।";
"Server Settings" = "सर्वर सेटिंग्स";
"Share Logs" = "लॉग साझा करें";
"Sharing relay payload with nearby devices…" = "आस-पास के उपकरणों के साथ रिले पेलोड साझा करना…";
"Shows the last server response." = "अंतिम सर्वर प्रतिक्रिया दिखाता है.";
"Signal" = "संकेत";
"Similarity Threshold" = "समानता दहलीज";
"Simple" = "सरल";
"Smooth loops and phrase echo by balancing repetition controls." = "दोहराव नियंत्रण को संतुलित करके चिकने लूप और वाक्यांश प्रतिध्वनि।";
"Smooth loops and repeated phrases by tuning repetition controls." = "दोहराव नियंत्रण को ट्यून करके चिकने लूप और दोहराए गए वाक्यांश।";
"Some models do not provide the system prompts needed for Noema to detect and configure them properly. These models may be unusable until they include appropriate metadata or support." = "कुछ मॉडल नोएमा को उन्हें ठीक से पहचानने और कॉन्फ़िगर करने के लिए आवश्यक सिस्टम संकेत प्रदान नहीं करते हैं। ये मॉडल तब तक अनुपयोगी हो सकते हैं जब तक उनमें उचित मेटाडेटा या समर्थन शामिल न हो।";
"Source unavailable. Check storage or network settings." = "स्रोत अनुपलब्ध. भंडारण या नेटवर्क सेटिंग जांचें.";
"Source: %@" = "स्रोत: %@";
"Specify identifiers for models that are not listed by the server. Leave blank to rely on the server's catalog." = "उन मॉडलों के लिए पहचानकर्ता निर्दिष्ट करें जो सर्वर द्वारा सूचीबद्ध नहीं हैं। सर्वर के कैटलॉग पर भरोसा करने के लिए खाली छोड़ दें।";
"Specify your model identifiers, or reload your custom models later." = "अपने मॉडल पहचानकर्ता निर्दिष्ट करें, या बाद में अपने कस्टम मॉडल पुनः लोड करें।";
"Speed up with a smaller helper model." = "एक छोटे सहायक मॉडल के साथ गति बढ़ाएं।";
"Start by installing one model. Then add a dataset (like an open textbook) so the AI can answer with grounded knowledge." = "एक मॉडल स्थापित करके प्रारंभ करें. फिर एक डेटासेट जोड़ें (एक खुली पाठ्यपुस्तक की तरह) ताकि एआई जमीनी ज्ञान के साथ उत्तर दे सके।";
"Start the relay to automatically share the latest payload with nearby devices." = "नवीनतम पेलोड को आस-पास के उपकरणों के साथ स्वचालित रूप से साझा करने के लिए रिले प्रारंभ करें।";
"Start with a reliable Qwen 3 1.7B build. It balances capability with small download size." = "एक विश्वसनीय क्वेन 3 1.7बी बिल्ड के साथ शुरुआत करें। यह छोटे डाउनलोड आकार के साथ क्षमता को संतुलित करता है।";
"Startup defaults now live in Settings → Startup. Favorite models here to keep them handy." = "स्टार्टअप डिफॉल्ट अब सेटिंग्स → स्टार्टअप में रहते हैं। उन्हें संभालकर रखने के लिए यहां पसंदीदा मॉडल हैं।";
"Status" = "स्थिति";
"Stay close to your Mac" = "अपने मैक के करीब रहें";
"Stop Using Dataset" = "डेटासेट का उपयोग बंद करें";
"Streaming" = "स्ट्रीमिंग";
"Streaming response…" = "स्ट्रीमिंग प्रतिक्रिया...";
"Supported Endpoints" = "समर्थित समापनबिंदु";
"Supported formats: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV" = "समर्थित प्रारूप: पीडीएफ, ईपीयूबी, टीएक्सटी, एमडी, जेएसओएन, जेएसओएनएल, सीएसवी, टीएसवी";
"Swap between the new stacked chat panel and the classic tab bar layout." = "नए स्टैक्ड चैट पैनल और क्लासिक टैब बार लेआउट के बीच स्वैप करें।";
"Swipe left to remove the embedding model from this device." = "इस डिवाइस से एम्बेडिंग मॉडल को हटाने के लिए बाएं स्वाइप करें।";
"Switch the selector to MLX for Apple Silicon‑optimized builds that excel at speed." = "Apple सिलिकॉन-अनुकूलित बिल्ड के लिए चयनकर्ता को MLX पर स्विच करें जो गति में उत्कृष्टता प्रदान करता है।";
"Switch to Raw to inspect the original response." = "मूल प्रतिक्रिया का निरीक्षण करने के लिए रॉ पर स्विच करें।";
"System" = "प्रणाली";
"Tap to load" = "लोड करने के लिए टैप करें";
"Temperature" = "तापमान";
"Testing" = "परीक्षण";
"The app memory usage budget is an estimate based on your device's total RAM and typical iOS memory management. The actual available memory may vary depending on system load, other running apps, and iOS memory pressure. Models that exceed this budget may cause the app to be terminated by iOS." = "ऐप मेमोरी उपयोग बजट आपके डिवाइस की कुल रैम और विशिष्ट iOS मेमोरी प्रबंधन पर आधारित एक अनुमान है। वास्तविक उपलब्ध मेमोरी सिस्टम लोड, अन्य चल रहे ऐप्स और iOS मेमोरी दबाव के आधार पर भिन्न हो सकती है। जो मॉडल इस बजट से अधिक हैं, उनके कारण iOS द्वारा ऐप को समाप्त किया जा सकता है।";
"The embedding model is installed. Delete it to free ~320 MB." = "एम्बेडिंग मॉडल स्थापित है. ~320 एमबी खाली करने के लिए इसे हटा दें।";
"The relay listens to the %@ container for new conversations and responds with your selected provider." = "रिले नई बातचीत के लिए %@ कंटेनर को सुनता है और आपके चयनित प्रदाता के साथ प्रतिक्रिया करता है।";
"The tool returned data that can't be formatted. Switch to Raw to inspect the original response." = "टूल ने वह डेटा लौटाया जिसे फ़ॉर्मेट नहीं किया जा सकता. मूल प्रतिक्रिया का निरीक्षण करने के लिए रॉ पर स्विच करें।";
"These options stay in simple mode for clarity. Let’s cover the essentials." = "स्पष्टता के लिए ये विकल्प सरल मोड में रहते हैं। आइए आवश्यक बातों को कवर करें।";
"Think of Noema as a simple way to run AI on your device. To get useful answers, you pair a local model with datasets (like open textbooks). We’ll guide you through the first setup." = "नोएमा को अपने डिवाइस पर एआई चलाने का एक सरल तरीका समझें। उपयोगी उत्तर पाने के लिए, आप एक स्थानीय मॉडल को डेटासेट (जैसे खुली पाठ्यपुस्तकें) के साथ जोड़ते हैं। हम आपको पहले सेटअप में मार्गदर्शन करेंगे.";
"This app bundles llama.cpp; we keep this in sync with upstream b‑releases." = "यह ऐप llama.cpp को बंडल करता है; हम इसे अपस्ट्रीम बी-रिलीज़ के साथ समन्वयित रखते हैं।";
"This backend is unavailable. Remove it or pick another option." = "यह बैकएंड अनुपलब्ध है. इसे हटाएं या कोई अन्य विकल्प चुनें.";
"This chat stays private—responses are generated on your device after you load a model." = "यह चैट निजी रहती है—आपके द्वारा मॉडल लोड करने के बाद आपके डिवाइस पर प्रतिक्रियाएं उत्पन्न होती हैं।";
"This configuration exceeds the current RAM safety guard, so benchmarking is disabled." = "यह कॉन्फ़िगरेशन वर्तमान रैम सुरक्षा गार्ड से अधिक है, इसलिए बेंचमार्किंग अक्षम है।";
"This dataset is taking a while to load, still working…" = "इस डेटासेट को लोड होने में थोड़ा समय लग रहा है, फिर भी यह काम कर रहा है...";
"This dataset's files are not currently supported for document retrieval." = "इस डेटासेट की फ़ाइलें वर्तमान में दस्तावेज़ पुनर्प्राप्ति के लिए समर्थित नहीं हैं।";
"This device doesn't support GPU offload." = "यह डिवाइस GPU ऑफलोड का समर्थन नहीं करता है.";
"This device doesn't support GPU offload; GGUF models will run on the CPU and generation speed will be significantly slower." = "यह डिवाइस GPU ऑफलोड का समर्थन नहीं करता है; जीजीयूएफ मॉडल सीपीयू पर चलेंगे और पीढ़ी की गति काफी धीमी होगी।";
"This model doesn't support GPU offload and generation speed will be significantly slower. Consider switching to an MLX model." = "यह मॉडल GPU ऑफलोड का समर्थन नहीं करता है और पीढ़ी की गति काफी धीमी होगी। एमएलएक्स मॉडल पर स्विच करने पर विचार करें।";
"This model doesn't support GPU offload and generation speed will be significantly slower. Fastest option on this device: use an SLM (Leap) model." = "यह मॉडल GPU ऑफलोड का समर्थन नहीं करता है और पीढ़ी की गति काफी धीमी होगी। इस डिवाइस पर सबसे तेज़ विकल्प: SLM (लीप) मॉडल का उपयोग करें।";
"This model doesn't support GPU offload and may run slowly. Consider an MLX model." = "यह मॉडल GPU ऑफलोड का समर्थन नहीं करता है और धीरे-धीरे चल सकता है। एक एमएलएक्स मॉडल पर विचार करें।";
"This model doesn't support GPU offload and may run slowly. Fastest option: use an SLM model." = "यह मॉडल GPU ऑफलोड का समर्थन नहीं करता है और धीरे-धीरे चल सकता है। सबसे तेज़ विकल्प: एसएलएम मॉडल का उपयोग करें।";
"This permanently removes every chat conversation. This action cannot be undone." = "यह प्रत्येक चैट वार्तालाप को स्थायी रूप से हटा देता है। इस एक्शन को वापस नहीं किया जा सकता।";
"This textbook appears to be available only as a web page. Noema can't import it as a dataset." = "ऐसा प्रतीत होता है कि यह पाठ्यपुस्तक केवल एक वेब पेज के रूप में उपलब्ध है। नोएमा इसे डेटासेट के रूप में आयात नहीं कर सकता।";
"Tool calling isn't perfect. Although Noema implements many methods of detecting and instructing models to use tools, not all LLMs will follow instructions and some might not call them correctly or at all. Tool calling heavily depends on model pre-training and will get better as time passes." = "टूल कॉलिंग सही नहीं है. हालाँकि नोएमा मॉडलों का पता लगाने और उन्हें टूल का उपयोग करने का निर्देश देने के कई तरीकों को लागू करता है, लेकिन सभी एलएलएम निर्देशों का पालन नहीं करेंगे और कुछ उन्हें सही ढंग से या बिल्कुल भी कॉल नहीं कर सकते हैं। टूल कॉलिंग काफी हद तक मॉडल प्री-ट्रेनिंग पर निर्भर करती है और समय बीतने के साथ बेहतर होती जाएगी।";
"Tools" = "औजार";
"Top-k: %@" = "टॉप-के: %@";
"Top-p" = "टॉप-पी";
"Top-p: %@" = "टॉप-पी: %@";
"Try again" = "पुनः प्रयास करें";
"Try another dataset if these formats aren't available." = "यदि ये प्रारूप उपलब्ध नहीं हैं तो कोई अन्य डेटासेट आज़माएँ।";
"Try the Qwen 3 1.7B GGUF (Q3_K_M) build below. It's a good starting point and you can delete it anytime." = "नीचे दिए गए Qwen 3 1.7B GGUF (Q3_K_M) बिल्ड को आज़माएं। यह एक अच्छा आरंभिक बिंदु है और आप इसे किसी भी समय हटा सकते हैं.";
"Unable to load image" = "छवि लोड करने में असमर्थ";
"Unknown error" = "अज्ञात त्रुटि";
"Updates every second" = "हर सेकंड अपडेट होता है";
"Use" = "उपयोग";
"Use Dataset" = "डेटासेट का उपयोग करें";
"Use this switch to flip between finding models or datasets." = "मॉडल या डेटासेट खोजने के बीच फ़्लिप करने के लिए इस स्विच का उपयोग करें।";
"Using %@" = "%@ का उपयोग करना";
"Using %@ of %@ budget" = "%2$@ बजट में से %1$@ का उपयोग करना";
"Using more than %@ significantly increases RAM usage." = "%@ से अधिक का उपयोग करने से RAM का उपयोग काफी बढ़ जाता है।";
"Using server catalog" = "सर्वर कैटलॉग का उपयोग करना";
"V Cache Quant" = "वी कैश क्वांट";
"Vendor recommendation: %@" = "विक्रेता अनुशंसा: %@";
"Version" = "संस्करण";
"Version %@" = "संस्करण %@";
"Version 1.4" = "संस्करण 1.4";
"Vision models require a companion projector (.mmproj). Noema will fetch it automatically the next time you download this model." = "विज़न मॉडल के लिए एक सहयोगी प्रोजेक्टर (.mmproj) की आवश्यकता होती है। अगली बार जब आप इस मॉडल को डाउनलोड करेंगे तो नोएमा इसे स्वचालित रूप से प्राप्त कर लेगा।";
"Wait for the response in your other chat to finish before sending a new message." = "नया संदेश भेजने से पहले अपनी अन्य चैट में प्रतिक्रिया समाप्त होने तक प्रतीक्षा करें।";
"Waiting for tool response…" = "टूल प्रतिक्रिया की प्रतीक्षा में...";
"We'll extract text and prepare embeddings. You can also start later from the dataset details." = "हम टेक्स्ट निकालेंगे और एम्बेडिंग तैयार करेंगे। आप बाद में डेटासेट विवरण से भी शुरुआत कर सकते हैं।";
"We'll route new conversations through %@ even if Wi‑Fi names differ. You can switch back by reloading the backend." = "हम नई बातचीत को %@ के माध्यम से रूट करेंगे, भले ही वाई-फ़ाई नाम भिन्न हों। आप बैकएंड को पुनः लोड करके वापस स्विच कर सकते हैं।";
"We'll try remote models in priority order for this long before moving to the next option." = "अगले विकल्प पर जाने से पहले हम इतने समय तक दूरस्थ मॉडलों को प्राथमिकता क्रम में आज़माएँगे।";
"We'll try this saved identifier even though it's not in the latest catalog." = "हम इस सहेजे गए पहचानकर्ता को आज़माएँगे भले ही यह नवीनतम कैटलॉग में न हो।";
"Web Search Tool Calls" = "वेब खोज उपकरण कॉल";
"Web Search button" = "वेब खोज बटन";
"Web search is included" = "वेब खोज शामिल है";
"Weights" = "तौल";
"Welcome to Noema" = "नोएमा में आपका स्वागत है";
"Welcome to Noema for Mac" = "मैक के लिए नोएमा में आपका स्वागत है";
"What is Noema?" = "नोएमा क्या है?";
"When connecting from another device, point the base URL to your computer (for example http://192.168.0.10:11434) and start Ollama with `OLLAMA_HOST=0.0.0.0` so it accepts remote clients." = "किसी अन्य डिवाइस से कनेक्ट करते समय, बेस यूआरएल को अपने कंप्यूटर पर इंगित करें (उदाहरण के लिए http://192.168.0.10:11434) और ओलामा को `OLLAMA_HOST=0.0.0.0` से प्रारंभ करें ताकि यह दूरस्थ क्लाइंट स्वीकार कर सके।";
"When enabled, pressing eject on iOS tells this Mac to unload the active relay model." = "सक्षम होने पर, iOS पर इजेक्ट दबाने पर यह मैक सक्रिय रिले मॉडल को अनलोड करने के लिए कहता है।";
"When enabled, you will be asked to choose parameters every time a model loads." = "सक्षम होने पर, आपको हर बार मॉडल लोड होने पर पैरामीटर चुनने के लिए कहा जाएगा।";
"Wi-Fi: %@" = "वाईफ़ाई: %@";
"Working set estimate (%@): %@ @ %@ tokens" = "कार्यशील सेट अनुमान (%1$@): %2$@ @ %3$@ टोकन";
"Write prompts, instructions, or notes here. Press return to add new lines." = "यहां संकेत, निर्देश या नोट्स लिखें। नई पंक्तियाँ जोड़ने के लिए रिटर्न दबाएँ।";
"You can keep chatting while indexing finishes" = "अनुक्रमणिका समाप्त होने तक आप चैट करना जारी रख सकते हैं";
"You can only favorite up to three models." = "आप केवल तीन मॉडलों को ही पसंदीदा बना सकते हैं।";
"You can restart this process in the dataset settings any time." = "आप किसी भी समय डेटासेट सेटिंग में इस प्रक्रिया को पुनः आरंभ कर सकते हैं।";
"You're in Off-Grid mode. The Explore tab is hidden and all network features are disabled. You can only use downloaded models and datasets." = "आप ऑफ-ग्रिड मोड में हैं. एक्सप्लोर टैब छिपा हुआ है और सभी नेटवर्क सुविधाएँ अक्षम हैं। आप केवल डाउनलोड किए गए मॉडल और डेटासेट का उपयोग कर सकते हैं।";
"Your Datasets" = "आपके डेटासेट";
"Your Models" = "आपके मॉडल";
"Your private AI workspace" = "आपका निजी AI कार्यक्षेत्र";
"You’re ready to explore. Download models, add datasets, and start chatting." = "आप अन्वेषण के लिए तैयार हैं मॉडल डाउनलोड करें, डेटासेट जोड़ें और चैट करना शुरू करें।";
"minutes" = "मिनट";
"•" = "";
"• Close other applications to free up RAM" = "• रैम खाली करने के लिए अन्य एप्लिकेशन बंद करें";
"• Embedding happens locally on your device" = "• एम्बेडिंग आपके डिवाइस पर स्थानीय रूप से होती है";
"• Larger datasets take exponentially more time" = "• बड़े डेटासेट में तेजी से अधिक समय लगता है";
"• You can pause and resume downloads if needed" = "• यदि आवश्यक हो तो आप डाउनलोड रोक सकते हैं और फिर से शुरू कर सकते हैं";
"…and %@ more parameter%@" = "…और %1$@ अधिक पैरामीटर%2$@";
"⚠️ " = "";
"General" = "सामान्य";

"Privacy" = "गोपनीयता";

"About" = "परिचय";

"About & Support" = "परिचय और समर्थन";

"Network" = "नेटवर्क";

"Embedding Model" = "एम्बेडिंग मॉडल";

"Retrieval" = "पुनर्प्राप्ति";

"Early Testers" = "प्रारंभिक परीक्षक";

"Build Info" = "बिल्ड जानकारी";

"Settings" = "सेटिंग्स";

"Language" = "भाषा";
"Startup" = "स्टार्टअप";
"Search models" = "मॉडल खोजें";
"SLM Models - Liquid AI" = "SLM Models - Liquid AI";
"Import" = "आयात करें";
"Import GGUF" = "GGUF आयात करें";
"Import MLX" = "MLX आयात करें";
"Import Failed" = "आयात विफल";
"Switching between GGUF/MLX modes" = "GGUF/MLX मोड के बीच स्विच करें";
"Switching between GGUF/SLM modes" = "GGUF/SLM मोड के बीच स्विच करें";
"Vision-capable model" = "विज़न समर्थ मॉडल";
"All" = "सभी";
"Text" = "पाठ";
"Vision" = "विज़न";
"Continue" = "जारी रखें";
"Try bullet" = "इनको आज़माएँ:\n• अलग कीवर्ड (जैसे 'gemma 3' की जगह 'gemma-3')\n• %@\n• टेक्स्ट/विज़न फ़िल्टर समायोजित करें\n• अपने खोज फ़िल्टर जाँचें";
"Select one or more .gguf files. For vision models, also select the projector .gguf (files containing ‘mmproj’ or ‘projector’). Files will be copied into your local model library." = "Select one or more .gguf files. For vision models, also select the projector .gguf (files containing ‘mmproj’ or ‘projector’). Files will be copied into your local model library.";
"Select the model folder that contains config.json and the weights (safetensors/npz). The entire folder will be imported into your local model library." = "Select the model folder that contains config.json and the weights (safetensors/npz). The entire folder will be imported into your local model library.";
"K Cache Quantization" = "K कैश क्वांटाइज़ेशन";
"V Cache Quantization" = "V कैश क्वांटाइज़ेशन";
"Favorite Limit Reached" = "पसंदीदा सीमा पूरी हुई";
"Overview" = "संक्षिप्त विवरण";
"Sampling" = "सैंपलिंग";
"Speculative Decoding" = "स्पेक्युलेटिव डिकोडिंग";
"Benchmark" = "बेंचमार्क";
"Maintenance" = "रखरखाव";
"MLX" = "MLX";
"Tokenizer Path (tokenizer.json)" = "टोकनाइज़र पथ (tokenizer.json)";
"Back" = "वापस";
"Favorite Model" = "पसंदीदा मॉडल";
"Reset to Default Settings" = "डिफ़ॉल्ट सेटिंग्स पर रीसेट करें";
"Delete Model" = "मॉडल हटाएँ";
"Delete %@?" = "%@ हटाएँ?";
"Not provided by repository" = "रिपॉज़िटरी द्वारा उपलब्ध नहीं";
"Unknown (not checked yet)" = "अज्ञात (अभी जांचा नहीं)";
"Keep Model In Memory" = "मॉडल को मेमोरी में रखें";
"GPU Offload Layers: %@/%@" = "GPU ऑफ़लोड लेयर: %1$@/%2$@";
"CPU Threads: %@" = "CPU थ्रेड्स: %@";
"Offload KV Cache to GPU" = "KV कैश को GPU पर ऑफ़लोड करें";
"Use mmap()" = "mmap() का उपयोग करें";
"Random" = "यादृच्छिक";
"Flash Attention" = "फ़्लैश अटेंशन";
"1 expert" = "1 विशेषज्ञ";
"%@ experts" = "%@ विशेषज्ञ";
"Helper Model" = "सहायक मॉडल";
"Draft strategy" = "ड्राफ्ट रणनीति";
"Run Benchmark" = "बेंचमार्क चलाएँ";
"Benchmarking…" = "बेंचमार्किंग…";
"Leap SLM models manage runtime optimizations automatically." = "Leap SLM मॉडल रनटाइम अनुकूलन स्वचालित रूप से संभालते हैं।";
"This format doesn't expose tunable runtime optimizations." = "यह फ़ॉर्मेट समायोज्य रनटाइम अनुकूलन प्रदान नहीं करता।";
"Token processing" = "टोकन प्रसंस्करण";
"Token generation" = "टोकन जनरेशन";
"Total time" = "कुल समय";
"First token" = "पहला टोकन";
"Peak memory" = "पीक मेमोरी";
"Output tokens" = "आउटपुट टोकन";
"End Guide" = "मार्गदर्शिका समाप्त करें";
"Streaming benchmark output…" = "बेंचमार्क आउटपुट स्ट्रीम किया जा रहा है…";
"Streaming… %@ chunks (~%@ tok est.)" = "स्ट्रीमिंग… %1$@ खंड (~%2$@ अनुमानित टोकन)";
"Streaming… %d chunks (~%d tok est.)" = "स्ट्रीमिंग… %d खंड (~%d अनुमानित टोकन)";
"The selected model's weights could not be located." = "चयनित मॉडल के वज़न नहीं मिले।";
"Failed to load model for benchmark: %@" = "बेंचमार्क के लिए मॉडल लोड करने में विफल: %@";
"Benchmark generation failed: %@" = "बेंचमार्क जनरेशन विफल: %@";
"K Cache" = "K कैश";
"V Cache" = "V कैश";
"KV Offload" = "KV ऑफ़लोड";
"On" = "चालू";
"Off" = "बंद";
"GPU" = "GPU";
"CPU" = "CPU";
"%.1f tok/s" = "%.1f tok/s";
"%.1fs" = "%.1fs";
"%.2fs" = "%.2fs";
"Move Up" = "ऊपर ले जाएँ";
"Move Down" = "नीचे ले जाएँ";
"Remove" = "हटाएँ";
"Startup remote options" = "रिमोट स्टार्ट विकल्प";
"No models cached yet. Open the backend to refresh its catalog." = "अभी तक कोई मॉडल कैश नहीं है। कैटलॉग ताज़ा करने के लिए बैकएंड खोलें।";
"We'll try this saved identifier even though it's not in the latest catalog." = "हम इस सहेजे गए पहचानकर्ता को आज़माएँगे, भले ही यह नवीनतम कैटलॉग में न हो।";
"This backend is unavailable. Remove it or pick another option." = "यह बैकएंड उपलब्ध नहीं है। इसे हटाएँ या कोई और विकल्प चुनें।";
"Backend removed" = "बैकएंड हटा दिया गया";
"What is Max Chunks?" = "Max Chunks क्या है?";
"What is Similarity Threshold?" = "Similarity Threshold क्या है?";
"Approx. %@" = "लगभग %@";
"Advanced mode shows developer options and diagnostics." = "उन्नत मोड डेवलपर विकल्प और डायग्नॉस्टिक्स दिखाता है।";
"Simple mode hides advanced settings for a cleaner interface." = "सादा मोड साफ़ इंटरफ़ेस के लिए उन्नत सेटिंग्स छुपाता है।";
"Hide advanced controls" = "उन्नत नियंत्रण छुपाएँ";
"Show advanced controls" = "उन्नत नियंत्रण दिखाएँ";
"Adjust model settings" = "मॉडल सेटिंग्स समायोजित करें";
"Model Settings" = "मॉडल सेटिंग्स";
"SLM models are not supported on this platform." = "SLM मॉडल इस प्लेटफ़ॉर्म पर समर्थित नहीं हैं।";
"Model likely exceeds memory budget. Lower context or choose a smaller quant." = "मॉडल संभवतः मेमोरी बजट से अधिक है। संदर्भ घटाएँ या छोटा क्वांट चुनें।";
"Apple bundle models aren't supported on macOS yet." = "Apple बंडल मॉडल अभी macOS पर समर्थित नहीं हैं।";
"Estimate: %@\nBudget: %@\nContext length: %@ tokens\n\nThis is an estimate based on your device’s memory budget, context length (KV cache), and typical runtime overheads. Actual usage may vary." = "अनुमान: %@\nबजट: %@\nसंदर्भ लंबाई: %@ टोकन\n\nयह आपके डिवाइस के मेमोरी बजट, संदर्भ लंबाई (KV कैश) और सामान्य रनटाइम ओवरहेड पर आधारित एक अनुमान है। वास्तविक उपयोग अलग हो सकता है।";
"Model likely fits in RAM" = "मॉडल सम्भवतः RAM में फिट होगा";
"Model may not fit in RAM" = "मॉडल RAM में फिट नहीं भी हो सकता";
"Fits in RAM (estimated)" = "RAM में फिट (अनुमानित)";
"May not fit (estimated)" = "शायद फिट न हो (अनुमानित)";
"Please provide a backend name." = "कृपया बैकएंड का नाम दें।";
"A backend with this name already exists." = "इस नाम का बैकएंड पहले से मौजूद है।";
"Backend not found." = "बैकएंड नहीं मिला।";
"This Noema Relay device is already configured." = "यह Noema Relay डिवाइस पहले से कॉन्फ़िगर है।";
"OpenAI API" = "OpenAI API";
"LM Studio" = "LM Studio";
"Ollama" = "Ollama";
"Cloud Relay" = "Cloud Relay";
"Noema Relay" = "Noema Relay";
"Compatible with OpenAI-style /v1 endpoints" = "OpenAI शैली /v1 एंडपॉइंट्स के साथ संगत";
"Connect to LM Studio's REST server" = "LM Studio के REST सर्वर से कनेक्ट करें";
"Target an Ollama host for chat and pulls" = "चैट और पुल्स के लिए एक Ollama होस्ट लक्ष्य करें";
"Use Noema's Cloud Relay on macOS" = "macOS पर Noema का Cloud Relay उपयोग करें";
"Pair with your Mac over CloudKit" = "CloudKit के माध्यम से अपने Mac से पेयर करें";
"Please provide the CloudKit container identifier." = "कृपया CloudKit कंटेनर पहचानकर्ता दें।";
"Please provide the host device ID from the Mac relay." = "कृपया Mac रिले से होस्ट डिवाइस ID दें।";
"Missing host device ID for Noema Relay." = "Noema Relay के लिए होस्ट डिवाइस ID गायब है।";
"Missing CloudKit container identifier." = "CloudKit कंटेनर पहचानकर्ता गायब है।";
"Relay catalog unavailable." = "रिले कैटलॉग उपलब्ध नहीं है।";
"Relay catalog is still syncing. Open the Mac relay, ensure it is signed into iCloud, then try again in a moment." = "रिले कैटलॉग अभी भी सिंक हो रहा है। Mac पर रिले खोलें, iCloud लॉगिन सुनिश्चित करें, फिर पुनः प्रयास करें।";
"Terms of Use" = "उपयोग की शर्तें";
"Privacy Policy" = "गोपनीयता नीति";
"Contact Support" = "सपोर्ट से संपर्क करें";
"Write a Review" = "समीक्षा लिखें";
"Notes & Issues" = "नोट्स और समस्याएँ";
"Qwen3-1.7B is a compact and efficient model from the Qwen3 family, suitable for on-device usage with strong general capabilities." = "Qwen3-1.7B Qwen3 परिवार का एक कॉम्पैक्ट और कुशल मॉडल है, मजबूत सामान्य क्षमताओं के साथ ऑन-डिवाइस उपयोग के लिए उपयुक्त।";
"Gemma 3n E2B is a lightweight instruction-tuned model from Google's Gemma family, optimized for efficient on-device conversations." = "Gemma 3n E2B, Google के Gemma परिवार का हल्का, निर्देश-ट्यून किया गया मॉडल है, जो कुशल स्थानीय वार्तालापों के लिए अनुकूलित है।";
"Gemma 3n E2B is an instruction-tuned variant of Google's Gemma family built for efficient reasoning on low-resource devices.\nAvailable in GGUF quants (Q3_K_M, Q4_K_M, Q6_K) and an MLX 4-bit build for Apple Silicon.\n" = "Gemma 3n E2B Gemma परिवार का निर्देश-ट्यून किया गया संस्करण है, जो कम संसाधन वाले उपकरणों पर कुशल तर्क के लिए बनाया गया है।\nGGUF क्वांट (Q3_K_M, Q4_K_M, Q6_K) और Apple Silicon के लिए MLX 4-बिट बिल्ड में उपलब्ध है।\n";
"Phi-4 Mini Reasoning is a lightweight model from the Phi-4 family, tuned for strong reasoning and efficiency across tasks." = "Phi-4 Mini Reasoning Phi-4 परिवार का हल्का मॉडल है, जिसे मजबूत तर्क और दक्षता के लिए ट्यून किया गया है।";
"Phi-4 Mini Reasoning — a compact model in Microsoft’s Phi-4 line designed for logical reasoning, problem solving, and instruction-following. \nDistributed in efficient GGUF quants (Q3_K_L, Q4_K_M, Q6_K) and an MLX 4-bit variant for Apple Silicon devices.\n" = "Phi-4 Mini Reasoning — Microsoft की Phi-4 श्रृंखला का एक कॉम्पैक्ट मॉडल, तार्किक तर्क, समस्या समाधान और निर्देशों का पालन करने के लिए डिज़ाइन किया गया।\nप्रभावी GGUF क्वांट (Q3_K_L, Q4_K_M, Q6_K) और Apple Silicon के लिए MLX 4-बिट संस्करण में वितरित।\n";
"Runtime Safety" = "रनटाइम सुरक्षा";
"Bypass RAM safety check (may cause crashes)" = "RAM सुरक्षा जाँच को छोड़ें (क्रैश हो सकता है)";
"Estimate for" = "इसके लिए अनुमान";
"Off-grid Mode" = "ऑफ-ग्रिड मोड";
"Delete All Chats" = "सभी चैट हटाएँ";
"Reset App Data" = "ऐप डेटा रीसेट करें";
"Max Chunks" = "अधिकतम खंड";
"Delete Embedding Model" = "एम्बेडिंग मॉडल हटाएँ";
"Override the app language. Defaults to the device language on first launch." = "ऐप की भाषा बदलें। पहले लॉन्च पर डिफ़ॉल्ट रूप से डिवाइस की भाषा उपयोग होती है।";
"Swap between the new stacked chat panel and the classic tab bar layout." = "नए स्टैक्ड चैट पैनल और क्लासिक टैब बार लेआउट के बीच स्विच करें।";
"Available Quantizations" = "उपलब्ध क्वांटाइजेशन";
"Sort quantizations" = "क्वांटाइजेशन क्रमबद्ध करें";
"Quant" = "क्वांट";
"Size ↑" = "आकार ↑";
"Size ↓" = "आकार ↓";
"Model Library" = "मॉडल लाइब्रेरी";
"Type to filter models…" = "मॉडल फ़िल्टर करने के लिए टाइप करें…";
"No models match your search." = "आपकी खोज से कोई मॉडल मेल नहीं खाता।";
"Browse Explore tab" = "Explore टैब खोलें";
"Manually choose parameters" = "पैरामीटर मैन्युअली चुनें";
"The base URL looks invalid. Please include the host (e.g. http://127.0.0.1:1234)." = "बेस URL अमान्य लगता है। कृपया होस्ट शामिल करें (जैसे http://127.0.0.1:1234)।";
"Could not build the remote endpoint URL." = "रिमोट एंडपॉइंट URL नहीं बना सके।";
"The server returned an unexpected response." = "सर्वर ने अप्रत्याशित प्रतिक्रिया दी।";
"Server responded with status code %d." = "सर्वर ने स्थिति कोड %d के साथ जवाब दिया।";
"Server responded with status code %d: %@" = "सर्वर ने स्थिति कोड %1$d के साथ जवाब दिया: %2$@";
"Failed to decode server response." = "सर्वर प्रतिक्रिया डीकोड करने में विफल।";

"Model doesn't support GPU offload" = "मॉडल GPU ऑफलोड का समर्थन नहीं करता";
"Loading model…" = "मॉडल लोड हो रहा है…";
"Select a model to load" = "लोड करने के लिए एक मॉडल चुनें";
"Please wait" = "कृपया प्रतीक्षा करें";
"Models Library" = "मॉडल लाइब्रेरी";
"Sort" = "क्रमबद्ध करें";
"Recency" = "नवीनतम";
"Size" = "आकार";
"Name" = "नाम";
"Load Failed" = "लोड विफल";
"Don't show again" = "दोबारा न दिखाएं";

"Explore" = "एक्सप्लोर";
"Search datasets" = "डेटासेट खोजें";
"Download" = "डाउनलोड";
"Offline" = "ऑफ़लाइन";
"Tap to load" = "लोड करने के लिए टैप करें";
"%d models" = "%d मॉडल";
"Updated %@" = "%@ पहले अपडेट किया";
"No models fetched yet" = "अभी तक कोई मॉडल नहीं मिला";
"Auth" = "प्रमाणीकरण";
"Local Network" = "लोकल नेटवर्क";
"Direct" = "डायरेक्ट";
"LAN" = "LAN";
"LAN · %@" = "LAN · %@";
"Backend" = "बैकएंड";
"Base URL" = "बेस URL";
"Chat Path" = "चैट पाथ";
"Models Path" = "मॉडल पाथ";
"Endpoint Type" = "एंडपॉइंट प्रकार";
"Endpoints" = "एंडपॉइंट";
"Authentication" = "प्रमाणीकरण";
"Model Identifiers" = "मॉडल पहचानकर्ता";
"Name" = "नाम";
"Host device ID" = "होस्ट डिवाइस आईडी";
"Host Device ID" = "होस्ट डिवाइस आईडी";
"CloudKit container identifier" = "CloudKit कंटेनर पहचानकर्ता";
"Field requirements will depend on your specific backend deployment." = "फ़ील्ड आवश्यकताएँ आपके बैकएंड डिप्लॉयमेंट पर निर्भर करेंगी।";
"Uses Noema Relay configuration" = "Noema Relay कॉन्फ़िगरेशन का उपयोग करता है";
"Chat: %@\nModels: %@" = "चैट: %@\nमॉडल: %@";

"Downloaded" = "डाउनलोड किया गया";
"Compressed Text" = "संपीडित पाठ";
"Small" = "छोटा";
"Medium" = "मध्यम";
"Large" = "बड़ा";
"Very Large" = "बहुत बड़ा";
"Extreme" = "अत्यंत बड़ा";
"Under 10 MB" = "10 एमबी से कम";
"10–50 MB" = "10–50 एमबी";
"50–200 MB" = "50–200 एमबी";
"200–500 MB" = "200–500 एमबी";
"Over 500 MB" = "500 एमबी से अधिक";
"Estimated Embedding Time" = "अनुमानित एम्बेडिंग समय";
"Peak RAM Usage" = "अधिकतम RAM उपयोग";
"Dataset Size" = "डेटासेट का आकार";
"Performance Note" = "प्रदर्शन नोट";
"Recommendation" = "सिफारिश";
"Remember:" = "याद रखें:";
"• Close other applications to free up RAM" = "• RAM खाली करने के लिए अन्य ऐप बंद करें";
"• Embedding happens locally on your device" = "• एम्बेडिंग आपके डिवाइस पर स्थानीय रूप से होती है";
"• Larger datasets take exponentially more time" = "• बड़े डेटासेट को बहुत अधिक समय लगता है";
"• You can pause and resume downloads if needed" = "• ज़रूरत पड़ने पर आप डाउनलोड रोककर फिर शुरू कर सकते हैं";
"Dataset Requirements" = "डेटासेट आवश्यकताएँ";
"Got it" = "समझ गया";
"Check Requirements" = "आवश्यकताएँ देखें";
"< 1 minute" = "1 मिनट से कम";
"%d minutes" = "%d मिनट";
"This dataset should embed quickly with minimal resource usage. Perfect for testing and quick experiments." = "यह डेटासेट कम संसाधनों में जल्दी एम्बेड हो जाना चाहिए। परीक्षण और त्वरित प्रयोगों के लिए बढ़िया।";
"This dataset is a reasonable size for most systems. Embedding should complete in a few minutes." = "यह डेटासेट अधिकांश सिस्टम के लिए उचित आकार का है। एम्बेडिंग कुछ मिनटों में पूरी हो जानी चाहिए।";
"This is a substantial dataset. Ensure you have adequate RAM and expect embedding to take 10–30 minutes." = "यह एक बड़ा डेटासेट है। पर्याप्त RAM सुनिश्चित करें और 10–30 मिनट लगने की अपेक्षा करें।";
"This is a very large dataset. Embedding may take 30–60 minutes and requires significant RAM." = "यह बहुत बड़ा डेटासेट है। एम्बेडिंग में 30–60 मिनट लग सकते हैं और काफी RAM चाहिए।";
"This is an extremely large dataset. Consider splitting it into smaller parts for better performance." = "यह बेहद बड़ा डेटासेट है। बेहतर प्रदर्शन के लिए इसे छोटे भागों में बाँटने पर विचार करें।";
"Go ahead and download! This size works well on all systems." = "डाउनलोड जारी रखें! यह आकार सभी सिस्टम पर अच्छा चलता है।";
"Recommended for most users. Make sure you have at least 4GB of free RAM." = "अधिकांश उपयोगकर्ताओं के लिए अनुशंसित। सुनिश्चित करें कि कम से कम 4GB RAM खाली हो।";
"Recommended only if you have 8GB+ RAM available. Close other applications before embedding." = "केवल तब अनुशंसित जब आपके पास 8GB+ RAM उपलब्ध हो। एम्बेडिंग से पहले अन्य ऐप बंद करें।";
"Recommended only for systems with 16GB+ RAM. Consider processing during off-hours." = "केवल उन सिस्टम के लिए जिनमें 16GB+ RAM हो। संभव हो तो ऑफ-ऑवर्स में प्रोसेस करें।";
"Not recommended for typical systems. Consider finding a smaller version or subset of this dataset." = "सामान्य सिस्टम के लिए अनुशंसित नहीं। इस डेटासेट का छोटा संस्करण या उपसमूह खोजें।";
"Sample dataset" = "नमूना डेटासेट";
"Ready" = "तैयार";
"Open" = "खोलें";
"Download Dataset" = "डेटासेट डाउनलोड करें";
"No files listed for this dataset." = "इस डेटासेट के लिए कोई फ़ाइल सूचीबद्ध नहीं है।";
"This dataset's files are not currently supported for document retrieval." = "इस डेटासेट की फ़ाइलें फिलहाल दस्तावेज़ पुनर्प्राप्ति के लिए समर्थित नहीं हैं।";
"Supported formats: %@" = "समर्थित फ़ॉर्मेट: %@";
"Try another dataset if these formats aren't available." = "यदि ये फ़ॉर्मेट उपलब्ध नहीं हैं, तो कोई दूसरा डेटासेट आज़माएँ।";
"Found unsupported: %@ …" = "असमर्थित पाए गए: %@ …";
"This textbook appears to be available only as a web page. Noema can't import it as a dataset." = "यह पाठ्यपुस्तक केवल वेब पेज के रूप में उपलब्ध लगती है। Noema इसे डेटासेट के रूप में आयात नहीं कर सकता।";
"Download complete" = "डाउनलोड पूरा हुआ";
"Downloading…" = "डाउनलोड हो रहा है…";
"No compatible files found for retrieval. Supported formats: %@" = "पुनर्प्राप्ति के लिए कोई संगत फ़ाइल नहीं मिली। समर्थित फ़ॉर्मेट: %@";
"No internet connection." = "इंटरनेट कनेक्शन नहीं है।";
"Request timed out. Please try again." = "अनुरोध का समय समाप्त हो गया। कृपया पुनः प्रयास करें।";
"Connection was lost. Please try again." = "कनेक्शन टूट गया। कृपया पुनः प्रयास करें।";
"Unexpected error: %@" = "अप्रत्याशित त्रुटि: %@";

/* Noema Relay – pairing & dataset helpers */
"Model file missing (.gguf)" = "मॉडल फ़ाइल गायब है (.gguf)";
"Model path missing" = "मॉडल पथ गायब है";
"Imported Dataset" = "आयातित डेटासेट";
"Dataset name" = "डेटासेट का नाम";
"Keep this device near the Mac that's running Noema Relay to import its settings." = "इस डिवाइस को उस Mac के पास रखें जिस पर Noema Relay चल रहा है ताकि उसकी सेटिंग्स आयात की जा सकें।";
"Scanning for your Mac relay…" = "आपके Mac रिले की स्कैनिंग हो रही है…";
"Ready to scan nearby relays" = "आसपास के रिले स्कैन करने के लिए तैयार";
"Bluetooth access is required to pair with the Mac relay." = "Mac रिले के साथ पेयर करने के लिए ब्लूटूथ एक्सेस आवश्यक है।";
"Stop Scanning" = "स्कैनिंग रोकें";
"Start Scan" = "स्कैन शुरू करें";
"Connection verified. Relay details imported from this Mac." = "कनेक्शन सत्यापित। इस Mac से रिले विवरण आयात किए गए।";
"Signal strength unavailable" = "सिग्नल की शक्ति उपलब्ध नहीं है";
"Very close" = "बहुत पास";
"Nearby" = "पास में";
"Within one room" = "एक ही कमरे के भीतर";
"Move closer for a stronger signal" = "मज़बूत सिग्नल के लिए और पास जाएँ।";
"This Mac" = "यह Mac";

/* Accessibility announcements */
"Model loaded." = "मॉडल लोड हो गया।";
"Prompt submitted." = "प्रॉम्प्ट भेजा गया।";
"Generating response…" = "जवाब बनाया जा रहा है…";
"Response generated." = "जवाब तैयार हो गया।";

/* Tabs & accessibility labels */
"Stored" = "स्टोर्ड";
"Web Search" = "वेब खोज";
"Open Stored" = "स्टोर्ड खोलें";
"Message input" = "संदेश इनपुट";
"What is Web Search button?" = "वेब खोज बटन क्या है?";

/* Mac chat quick-load menu */
"Open Model Library" = "मॉडल लाइब्रेरी खोलें";
"Favorites" = "पसंदीदा";
"Recent" = "हाल ही के";
