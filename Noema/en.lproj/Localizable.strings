/* Auto-generated localization file. */
"%@" = "%@";
"%@ %" = "%1$@ %2$";
"%@ %@" = "%1$@ %2$@";
"%@ models" = "%@ models";
"%@ of %@ budget" = "%1$@ of %2$@ budget";
"%@ tokens" = "%@ tokens";
"%@ – %@" = "%1$@ – %2$@";
"%@ • %@" = "%1$@ • %2$@";
"%@%" = "%1$@%2$";
"%@% · %@" = "%1$@%2$ · %3$@";
"%@." = "%@.";
"%@:" = "%@:";
"(+ mmproj %@%)" = "(+ mmproj %1$@%2$)";
"... and %@ more" = "... and %@ more";
"320 MB • One-time download" = "320 MB • One-time download";
"320 MB • One‑time download used for local dataset search" = "320 MB • One‑time download used for local dataset search";
"A larger context keeps more conversation history, but also uses more memory. Adjust it here." = "A larger context keeps more conversation history, but also uses more memory. Adjust it here.";
"Active" = "Active";
"Active Model" = "Active Model";
"Active connection via %@" = "Active connection via %@";
"Active experts per token: %@ of %@" = "Active experts per token: %1$@ of %2$@";
"Add a remote backend to configure remote startup fallbacks." = "Add a remote backend to configure remote startup fallbacks.";
"Add one or two datasets (like open textbooks) to keep responses accurate and help the AI cite sources." = "Add one or two datasets (like open textbooks) to keep responses accurate and help the AI cite sources.";
"Add remote endpoint" = "Add remote endpoint";
"Adjust appearance, privacy options, and network preferences here." = "Adjust appearance, privacy options, and network preferences here.";
"Advanced" = "Advanced";
"Advanced Controls" = "Advanced Controls";
"Allows models to use a privacy-preserving web search API when you tap the globe in chat. Default is ON. In Offline Only mode, the button is disabled." = "Allows models to use a privacy-preserving web search API when you tap the globe in chat. Default is ON. In Offline Only mode, the button is disabled.";
"Analyzing context..." = "Analyzing context...";
"App Memory Usage (estimated)" = "App Memory Usage (estimated)";
"App memory usage budget: %@ (conservative)" = "App memory usage budget: %@ (conservative)";
"Approx. Tokens" = "Approx. Tokens";
"Arm web search when you truly need outside info. It has a small daily limit and most chats don’t require it." = "Arm web search when you truly need outside info. It has a small daily limit and most chats don’t require it.";
"Ask Noema anything" = "Ask Noema anything";
"Ask…" = "Ask…";
"Attach Photos" = "Attach Photos";
"Backend not found" = "Backend not found";
"Benchmark running…" = "Benchmark running…";
"Benchmarking is not available for this model format." = "Benchmarking is not available for this model format.";
"Blocks all network traffic, model downloads, and cloud connections so everything stays on‑device." = "Blocks all network traffic, model downloads, and cloud connections so everything stays on‑device.";
"Bluetooth Pairing" = "Bluetooth Pairing";
"Browse community models and curated datasets to expand what Noema can do." = "Browse community models and curated datasets to expand what Noema can do.";
"Browse curated datasets for retrieval" = "Browse curated datasets for retrieval";
"CFBundleShortVersionString1.0" = "CFBundleShortVersionString1.0";
"Cancel" = "Cancel";
"Cancel Benchmark" = "Cancel Benchmark";
"Discover Intelligence" = "Discover Intelligence";
"Catalog" = "Catalog";
"Chat" = "Chat";
"Chat privately with your local models, sync datasets, and manage the relay server in one place." = "Chat privately with your local models, sync datasets, and manage the relay server in one place.";
"Chats" = "Chats";
"Checking…" = "Checking…";
"Citation %@" = "Citation %@";
"Cloud Relay Container" = "Cloud Relay Container";
"Cloud Relay via CloudKit (auto-discovery and Bluetooth pairing)" = "Cloud Relay via CloudKit (auto-discovery and Bluetooth pairing)";
"CloudKit" = "CloudKit";
"CloudKit bridge active. Local replies are generated on this Mac." = "CloudKit bridge active. Local replies are generated on this Mac.";
"Compiling Metal kernels for GGUF models can take up to a minute on first load." = "Compiling Metal kernels for GGUF models can take up to a minute on first load.";
"Complete the streaming response in the active chat before sending again." = "Complete the streaming response in the active chat before sending again.";
"Confirm and Start Embedding" = "Confirm and Start Embedding";
"Connected" = "Connected";
"Connection Modes" = "Connection Modes";
"Connection Status: %@" = "Connection Status: %@";
"Container" = "Container";
"Context Length" = "Context Length";
"Context Length: 4096 tokens" = "Context Length: 4096 tokens";
"Context length is under 5000 tokens. With images and multi-sequence decoding (n_seq_max=16), per-sequence memory can be too small, leading to a crash. Increase context to at least 8192 in Model Settings." = "Context length is under 5000 tokens. With images and multi-sequence decoding (n_seq_max=16), per-sequence memory can be too small, leading to a crash. Increase context to at least 8192 in Model Settings.";
"Controls how many high‑scoring passages (chunks) can be injected into the prompt. Higher values increase recall but consume more context window and can slow responses. Typical range 3–6." = "Controls how many high‑scoring passages (chunks) can be injected into the prompt. Higher values increase recall but consume more context window and can slow responses. Typical range 3–6.";
"Couldn't load the recommended model." = "Couldn't load the recommended model.";
"Couldn’t load the recommended model right now." = "Couldn’t load the recommended model right now.";
"Creativity: %@. Low values focus responses; high values add variety." = "Creativity: %@. Low values focus responses; high values add variety.";
"Dark" = "Dark";
"Dataset" = "Dataset";
"Dataset indexing in progress..." = "Dataset indexing in progress...";
"Dataset ready to use" = "Dataset ready to use";
"Datasets" = "Datasets";
"Datasets enrich the model with focused knowledge. Toggle one on to use it in chat." = "Datasets enrich the model with focused knowledge. Toggle one on to use it in chat.";
"Default selection (~%@) balances RAM usage against model quality." = "Default selection (~%@) balances RAM usage against model quality.";
"Delete" = "Delete";
"Delete Dataset" = "Delete Dataset";
"Deletes all chats, downloaded models, and datasets, and restores settings to defaults. The embedding model stays installed." = "Deletes all chats, downloaded models, and datasets, and restores settings to defaults. The embedding model stays installed.";
"Device" = "Device";
"Digest:" = "Digest:";
"Done" = "Done";
"Done!" = "Done!";
"Download Now" = "Download Now";
"Download a model from Explore or add a remote endpoint to get started." = "Download a model from Explore or add a remote endpoint to get started.";
"Download a small embedding model so Noema can index and search your datasets" = "Download a small embedding model so Noema can index and search your datasets";
"Downloaded datasets need on-device embedding. Give it a few minutes after download finishes." = "Downloaded datasets need on-device embedding. Give it a few minutes after download finishes.";
"Downloaded models and datasets live here so you can manage them offline." = "Downloaded models and datasets live here so you can manage them offline.";
"Downloading…" = "Downloading…";
"Draft tokens: %@" = "Draft tokens: %@";
"Draft window: %@" = "Draft window: %@";
"EPUB viewing not supported on this platform" = "EPUB viewing not supported on this platform";
"Embedding" = "Embedding";
"Embedding Model Ready" = "Embedding Model Ready";
"Embedding is resource intensive. For best performance, plug in your phone. Do you want to proceed on battery?" = "Embedding is resource intensive. For best performance, plug in your phone. Do you want to proceed on battery?";
"Enabling Bluetooth…" = "Enabling Bluetooth…";
"Enhance with Datasets" = "Enhance with Datasets";
"Error" = "Error";
"Estimated working set: %@ · Budget: %@" = "Estimated working set: %1$@ · Budget: %2$@";
"Experts Per Token" = "Experts Per Token";
"Explore Datasets" = "Explore Datasets";
"Expose any downloaded models or connected remote endpoints from the Stored tab to your paired devices. Select which one should answer conversations when the relay is running." = "Expose any downloaded models or connected remote endpoints from the Stored tab to your paired devices. Select which one should answer conversations when the relay is running.";
"Expose to iOS" = "Expose to iOS";
"Explore the latest open-source models optimized for your Mac." = "Explore the latest open-source models optimized for your Mac.";
"Failed to load README" = "Failed to load README";
"Failed: %@" = "Failed: %@";
"Fastest option on this device: SLM (Leap) models." = "Fastest option on this device: SLM (Leap) models.";
"Field requirements will depend on your specific backend deployment." = "Field requirements will depend on your specific backend deployment.";
"Files" = "Files";
"First, enable fast dataset search" = "First, enable fast dataset search";
"First-time GGUF load takes longer" = "First-time GGUF load takes longer";
"First-time download from HuggingFace" = "First-time download from HuggingFace";
"First‑time setup: download the Qwen‑1.7B model and embeddings.\nWi‑Fi recommended." = "First‑time setup: download the Qwen‑1.7B model and embeddings.\nWi‑Fi recommended.";
"For best performance, please plug in your phone until this completes." = "For best performance, please plug in your phone until this completes.";
"Force Local Network" = "Force Local Network";
"Forces chat traffic through the last LAN host even if Wi‑Fi names don't match yet." = "Forces chat traffic through the last LAN host even if Wi‑Fi names don't match yet.";
"Formatted view unavailable" = "Formatted view unavailable";
"Found unsupported: %@ …" = "Found unsupported: %@ …";
"Frequency penalty: %@" = "Frequency penalty: %@";
"GGUF models are the most compatible option. Use the format switch to explore the other builds when you need them." = "GGUF models are the most compatible option. Use the format switch to explore the other builds when you need them.";
"GGUF works everywhere. MLX targets Apple Silicon speed. SLM focuses on responsiveness on any device." = "GGUF works everywhere. MLX targets Apple Silicon speed. SLM focuses on responsiveness on any device.";
"GPU Offload Layers" = "GPU Offload Layers";
"GPU off-load is not supported for this model." = "GPU off-load is not supported for this model.";
"Get Started" = "Get Started";
"Help shape Noema by trying upcoming features and sharing feedback." = "Help shape Noema by trying upcoming features and sharing feedback.";
"High context lengths use more memory" = "High context lengths use more memory";
"High-quality embedding model for local RAG" = "High-quality embedding model for local RAG";
"Host ID: %@" = "Host ID: %@";
"How it works" = "How it works";
"I'm New to Local LLMs, Guide Me" = "I'm New to Local LLMs, Guide Me";
"If enabled, the app will attempt to load models even when they likely exceed your device's memory budget. This can cause the app to terminate." = "If enabled, the app will attempt to load models even when they likely exceed your device's memory budget. This can cause the app to terminate.";
"Import Dataset" = "Import Dataset";
"Import PDFs, EPUBs, or text files to build local knowledge bases." = "Import PDFs, EPUBs, or text files to build local knowledge bases.";
"Import your own PDFs, EPUBs, or TXT files and keep them local." = "Import your own PDFs, EPUBs, or TXT files and keep them local.";
"Importing & Scanning..." = "Importing & Scanning...";
"In progress..." = "In progress...";
"Indexing %@" = "Indexing %@";
"Indexing dataset…" = "Indexing dataset…";
"Indexing: %@% · %@" = "Indexing: %1$@%2$ · %3$@";
"Install a local model to make it available at launch." = "Install a local model to make it available at launch.";
"Install another model with the same architecture and equal or smaller size to enable speculative decoding." = "Install another model with the same architecture and equal or smaller size to enable speculative decoding.";
"K Cache Quant" = "K Cache Quant";
"Keep this iPhone or iPad within a few feet of the Mac that is advertising Noema Relay. We'll pull the relay details automatically once connected." = "Keep this iPhone or iPad within a few feet of the Mac that is advertising Noema Relay. We'll pull the relay details automatically once connected.";
"LAN URL: %@" = "LAN URL: %@";
"Large Model Downloads" = "Large Model Downloads";
"Last Sync" = "Last Sync";
"Last refreshed %@" = "Last refreshed %@";
"Latest benchmark" = "Latest benchmark";
"Latest integrated release: %@" = "Latest integrated release: %@";
"Library" = "Library";
"Light" = "Light";
"Llama.cpp" = "Llama.cpp";
"Load" = "Load";
"Load a local model before chatting. You can download one from the Explore tab or load a model you've already installed." = "Load a local model before chatting. You can download one from the Explore tab or load a model you've already installed.";
"Loading recommendation…" = "Loading recommendation…";
"Loading…" = "Loading…";
"Local Network HTTP server for LAN clients (OpenAI-compatible)" = "Local Network HTTP server for LAN clients (OpenAI-compatible)";
"Low = focused. High = varied." = "Low = focused. High = varied.";
"Lower = more results (more noise). Higher = stricter matches." = "Lower = more results (more noise). Higher = stricter matches.";
"MLX currently manages expert routing automatically; manual selection is not supported." = "MLX currently manages expert routing automatically; manual selection is not supported.";
"Many models are several gigabytes in size and require a stable connection and sufficient storage. Downloads can fail or take a long time on slow networks or devices with limited space." = "Many models are several gigabytes in size and require a stable connection and sufficient storage. Downloads can fail or take a long time on slow networks or devices with limited space.";
"Max Chunks: %@" = "Max Chunks: %@";
"Max recommended context on this device: ~%@ tokens" = "Max recommended context on this device: ~%@ tokens";
"Measure real-world generation speed for this configuration. A short scripted prompt will run locally and report timing and memory usage." = "Measure real-world generation speed for this configuration. A short scripted prompt will run locally and report timing and memory usage.";
"Min-p" = "Min-p";
"Min-p: %@" = "Min-p: %@";
"Minimum cosine similarity a passage must have to be considered relevant. Lower = more passages (higher recall, more noise). Higher = fewer, more precise passages. Try 0.2–0.4 for broad questions; 0.5–0.7 for precise lookups." = "Minimum cosine similarity a passage must have to be considered relevant. Lower = more passages (higher recall, more noise). Higher = fewer, more precise passages. Try 0.2–0.4 for broad questions; 0.5–0.7 for precise lookups.";
"MoE layers: %@ / %@" = "MoE layers: %1$@ / %2$@";
"Model Detection Limitations" = "Model Detection Limitations";
"Model Formats" = "Model Formats";
"Models" = "Models";
"Models shown here are exposed by the Mac relay. Manage sources in the Relay tab on macOS to share more models." = "Models shown here are exposed by the Mac relay. Manage sources in the Relay tab on macOS to share more models.";
"Move your device closer to the Mac running the relay if it doesn't appear right away. Bluetooth discovery usually completes within a few seconds." = "Move your device closer to the Mac running the relay if it doesn't appear right away. Bluetooth discovery usually completes within a few seconds.";
"Name your dataset" = "Name your dataset";
"Nearby Relays" = "Nearby Relays";
"Nearby iPhone and iPad devices discover your Mac relay instantly and sync pairing codes over the air." = "Nearby iPhone and iPad devices discover your Mac relay instantly and sync pairing codes over the air.";
"Need a fresh thread? Tap the plus button for a brand-new conversation." = "Need a fresh thread? Tap the plus button for a brand-new conversation.";
"Nice! You already have the recommended GGUF starter model ready to use." = "Nice! You already have the recommended GGUF starter model ready to use.";
"No compatible files found for retrieval. Supported: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV" = "No compatible files found for retrieval. Supported: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV";
"No connection responses recorded yet." = "No connection responses recorded yet.";
"No datasets available yet. Import or download datasets to build your personal library." = "No datasets available yet. Import or download datasets to build your personal library.";
"No datasets found. Try different keywords." = "No datasets found. Try different keywords.";
"No datasets imported yet." = "No datasets imported yet.";
"No datasets yet" = "No datasets yet";
"No files listed for this dataset." = "No files listed for this dataset.";
"No model >" = "No model >";
"No model loaded" = "No model loaded";
"No models available. Add downloads or remote connections in Stored to configure the relay." = "No models available. Add downloads or remote connections in Stored to configure the relay.";
"No models cached yet. Open the backend to refresh its catalog." = "No models cached yet. Open the backend to refresh its catalog.";
"No models found for '%@'" = "No models found for '%@'";
"No models loaded right now. We'll spin one up when a request arrives." = "No models loaded right now. We'll spin one up when a request arrives.";
"No models match your search." = "No models match your search.";
"No models yet" = "No models yet";
"No parameters" = "No parameters";
"No quant files available" = "No quant files available";
"No recent devices. We'll list clients the next time they talk to this relay." = "No recent devices. We'll list clients the next time they talk to this relay.";
"No remote endpoints configured yet." = "No remote endpoints configured yet.";
"No remote endpoints configured." = "No remote endpoints configured.";
"No ≥Q3 quants are available for this model." = "No ≥Q3 quants are available for this model.";
"K Cache Quantization" = "K Cache Quantization";
"V Cache Quantization" = "V Cache Quantization";
"Favorite Limit Reached" = "Favorite Limit Reached";
"Overview" = "Overview";
"Sampling" = "Sampling";
"Speculative Decoding" = "Speculative Decoding";
"Benchmark" = "Benchmark";
"Maintenance" = "Maintenance";
"MLX" = "MLX";
"Tokenizer Path (tokenizer.json)" = "Tokenizer Path (tokenizer.json)";
"Back" = "Back";
"Favorite Model" = "Favorite Model";
"Reset to Default Settings" = "Reset to Default Settings";
"Delete Model" = "Delete Model";
"Delete %@?" = "Delete %@?";
"Not provided by repository" = "Not provided by repository";
"Unknown (not checked yet)" = "Unknown (not checked yet)";
"Keep Model In Memory" = "Keep Model In Memory";
"GPU Offload Layers: %@/%@" = "GPU Offload Layers: %1$@/%2$@";
"CPU Threads: %@" = "CPU Threads: %@";
"Offload KV Cache to GPU" = "Offload KV Cache to GPU";
"Use mmap()" = "Use mmap()";
"Random" = "Random";
"Flash Attention" = "Flash Attention";
"1 expert" = "1 expert";
"%@ experts" = "%@ experts";
"Helper Model" = "Helper Model";
"Draft strategy" = "Draft strategy";
"Run Benchmark" = "Run Benchmark";
"Benchmarking…" = "Benchmarking…";
"Leap SLM models manage runtime optimizations automatically." = "Leap SLM models manage runtime optimizations automatically.";
"This format doesn't expose tunable runtime optimizations." = "This format doesn't expose tunable runtime optimizations.";
"Token processing" = "Token processing";
"Token generation" = "Token generation";
"Total time" = "Total time";
"First token" = "First token";
"Peak memory" = "Peak memory";
"Output tokens" = "Output tokens";
"End Guide" = "End Guide";
"Streaming benchmark output…" = "Streaming benchmark output…";
"Streaming… %@ chunks (~%@ tok est.)" = "Streaming… %1$@ chunks (~%2$@ tok est.)";
"Streaming… %d chunks (~%d tok est.)" = "Streaming… %d chunks (~%d tok est.)";
"The selected model's weights could not be located." = "The selected model's weights could not be located.";
"Failed to load model for benchmark: %@" = "Failed to load model for benchmark: %@";
"Benchmark generation failed: %@" = "Benchmark generation failed: %@";
"K Cache" = "K Cache";
"V Cache" = "V Cache";
"KV Offload" = "KV Offload";
"On" = "On";
"Off" = "Off";
"GPU" = "GPU";
"CPU" = "CPU";
"%.1f tok/s" = "%.1f tok/s";
"%.1fs" = "%.1fs";
"%.2fs" = "%.2fs";
"Noema" = "Noema";
"Noema REST API — /api/v0/* for model catalog & operations" = "Noema REST API — /api/v0/* for model catalog & operations";
"Noema Relay" = "Noema Relay";
"Noema Server" = "Noema Server";
"Noema attempts to gauge available memory to prevent models from exceeding device limits. These checks may occasionally miss risky situations and allow a model to crash your app, or they may be overly conservative and block a model that could have run fine." = "Noema attempts to gauge available memory to prevent models from exceeding device limits. These checks may occasionally miss risky situations and allow a model to crash your app, or they may be overly conservative and block a model that could have run fine.";
"Noema could not find a projector in the repository. If the model advertises vision, ensure the mmproj file is present in the same folder as the weights." = "Noema could not find a projector in the repository. If the model advertises vision, ensure the mmproj file is present in the same folder as the weights.";
"Noema has been reset. The embedding model remains installed." = "Noema has been reset. The embedding model remains installed.";
"Nomic Embed Text v1.5 (Q4_K_M)" = "Nomic Embed Text v1.5 (Q4_K_M)";
"None" = "None";
"Not found" = "Not found";
"Not provided" = "Not provided";
"OK" = "OK";
"Off-Grid" = "Off-Grid";
"Off-grid mode blocks every network call so the app stays self-contained. Good luck exploring Noema!" = "Off-grid mode blocks every network call so the app stays self-contained. Good luck exploring Noema!";
"Only one expert is available for this model; the active expert count is fixed." = "Only one expert is available for this model; the active expert count is fixed.";
"Open Stored to choose a model to run locally or connect to a remote endpoint." = "Open Stored to choose a model to run locally or connect to a remote endpoint.";
"Open the sidebar to revisit any previous session without losing your spot." = "Open the sidebar to revisit any previous session without losing your spot.";
"OpenAI-style API — /v1/chat/completions, /v1/completions, /v1/models" = "OpenAI-style API — /v1/chat/completions, /v1/completions, /v1/models";
"Optimizations in use" = "Optimizations in use";
"PDF viewing not supported on this platform" = "PDF viewing not supported on this platform";
"Pick a model and add a dataset" = "Pick a model and add a dataset";
"Pick the SLM format when you want ultra-responsive models that run well anywhere." = "Pick the SLM format when you want ultra-responsive models that run well anywhere.";
"Pinned answer" = "Pinned answer";
"Pinned answer unavailable" = "Pinned answer unavailable";
"Preparation" = "Preparation";
"Preparing Embedding Model" = "Preparing Embedding Model";
"Preparing benchmark…" = "Preparing benchmark…";
"Preparing…" = "Preparing…";
"Presence penalty: %@" = "Presence penalty: %@";
"Projector (mmproj)" = "Projector (mmproj)";
"Projector downloaded automatically from Hugging Face. Keep this file alongside the weights so vision remains available." = "Projector downloaded automatically from Hugging Face. Keep this file alongside the weights so vision remains available.";
"Quantize the runtime key cache to save memory. Experimental." = "Quantize the runtime key cache to save memory. Experimental.";
"Quantize the runtime value cache to save memory when Flash Attention is enabled. Experimental." = "Quantize the runtime value cache to save memory when Flash Attention is enabled. Experimental.";
"Qwen 3 1.7B GGUF (Q3_K_M) gives you a dependable starting point. Delete it anytime if you need space." = "Qwen 3 1.7B GGUF (Q3_K_M) gives you a dependable starting point. Delete it anytime if you need space.";
"RAG embeds normalized paragraphs from your PDFs and EPUBs. On each question, the most relevant chunks are retrieved and added to the prompt. Images are ignored." = "RAG embeds normalized paragraphs from your PDFs and EPUBs. On each question, the most relevant chunks are retrieved and added to the prompt. Images are ignored.";
"RAM Safety Checks" = "RAM Safety Checks";
"RAM information for this device will be added in a future update." = "RAM information for this device will be added in a future update.";
"REST Endpoints" = "REST Endpoints";
"Reachable at" = "Reachable at";
"Ready for Use" = "Ready for Use";
"Recent Chats" = "Recent Chats";
"Recommended" = "Recommended";
"Recommended Starter Model" = "Recommended Starter Model";
"Relay ID" = "Relay ID";
"Relay Server Running" = "Relay Server Running";
"Relay Sources" = "Relay Sources";
"Remaining: %@" = "Remaining: %@";
"Remember:" = "Remember:";
"Remote Backends" = "Remote Backends";
"Remote endpoint is offline. This model can't be found at this time." = "Remote endpoint is offline. This model can't be found at this time.";
"Remote timeout: %@s" = "Remote timeout: %@s";
"Repeat last N tokens: %@" = "Repeat last N tokens: %@";
"Repetition penalty: %@" = "Repetition penalty: %@";
"Request Parameters" = "Request Parameters";
"Responses are generated by the macOS relay server. Configure the provider (LM Studio or Ollama) on the Mac app." = "Responses are generated by the macOS relay server. Configure the provider (LM Studio or Ollama) on the Mac app.";
"Result" = "Result";
"Results" = "Results";
"Save" = "Save";
"Saving…" = "Saving…";
"Score: %@" = "Score: %@";
"SearXNG web search is available without limits. There's nothing to purchase—just enable the globe button in chat whenever you need online results." = "SearXNG web search is available without limits. There's nothing to purchase—just enable the globe button in chat whenever you need online results.";
"SearXNG web search is enabled for this device." = "SearXNG web search is enabled for this device.";
"Search" = "Search";
"Search for any subject you're interested in." = "Search for any subject you're interested in.";
"Search requests are proxied through https://search.noemaai.com and are available without quotas." = "Search requests are proxied through https://search.noemaai.com and are available without quotas.";
"Seed" = "Seed";
"Selecting more experts keeps additional expert weights resident in RAM and increases memory usage." = "Selecting more experts keeps additional expert weights resident in RAM and increases memory usage.";
"Server Settings" = "Server Settings";
"Share Logs" = "Share Logs";
"Sharing relay payload with nearby devices…" = "Sharing relay payload with nearby devices…";
"Shows the last server response." = "Shows the last server response.";
"Signal" = "Signal";
"Similarity Threshold" = "Similarity Threshold";
"Simple" = "Simple";
"Smooth loops and phrase echo by balancing repetition controls." = "Smooth loops and phrase echo by balancing repetition controls.";
"Smooth loops and repeated phrases by tuning repetition controls." = "Smooth loops and repeated phrases by tuning repetition controls.";
"Some models do not provide the system prompts needed for Noema to detect and configure them properly. These models may be unusable until they include appropriate metadata or support." = "Some models do not provide the system prompts needed for Noema to detect and configure them properly. These models may be unusable until they include appropriate metadata or support.";
"Source unavailable. Check storage or network settings." = "Source unavailable. Check storage or network settings.";
"Source: %@" = "Source: %@";
"Specify identifiers for models that are not listed by the server. Leave blank to rely on the server's catalog." = "Specify identifiers for models that are not listed by the server. Leave blank to rely on the server's catalog.";
"Specify your model identifiers, or reload your custom models later." = "Specify your model identifiers, or reload your custom models later.";
"Speed up with a smaller helper model." = "Speed up with a smaller helper model.";
"Start by installing one model. Then add a dataset (like an open textbook) so the AI can answer with grounded knowledge." = "Start by installing one model. Then add a dataset (like an open textbook) so the AI can answer with grounded knowledge.";
"Start the relay to automatically share the latest payload with nearby devices." = "Start the relay to automatically share the latest payload with nearby devices.";
"Start with a reliable Qwen 3 1.7B build. It balances capability with small download size." = "Start with a reliable Qwen 3 1.7B build. It balances capability with small download size.";
"Startup defaults now live in Settings → Startup. Favorite models here to keep them handy." = "Startup defaults now live in Settings → Startup. Favorite models here to keep them handy.";
"Status" = "Status";
"Stay close to your Mac" = "Stay close to your Mac";
"Stop Using Dataset" = "Stop Using Dataset";
"Streaming" = "Streaming";
"Streaming response…" = "Streaming response…";
"Supported Endpoints" = "Supported Endpoints";
"Supported formats: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV" = "Supported formats: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV";
"Swap between the new stacked chat panel and the classic tab bar layout." = "Swap between the new stacked chat panel and the classic tab bar layout.";
"Swipe left to remove the embedding model from this device." = "Swipe left to remove the embedding model from this device.";
"Switch the selector to MLX for Apple Silicon‑optimized builds that excel at speed." = "Switch the selector to MLX for Apple Silicon‑optimized builds that excel at speed.";
"Switch to Raw to inspect the original response." = "Switch to Raw to inspect the original response.";
"System" = "System";
"Tap to load" = "Tap to load";
"Temperature" = "Temperature";
"Testing" = "Testing";
"The app memory usage budget is an estimate based on your device's total RAM and typical iOS memory management. The actual available memory may vary depending on system load, other running apps, and iOS memory pressure. Models that exceed this budget may cause the app to be terminated by iOS." = "The app memory usage budget is an estimate based on your device's total RAM and typical iOS memory management. The actual available memory may vary depending on system load, other running apps, and iOS memory pressure. Models that exceed this budget may cause the app to be terminated by iOS.";
"The embedding model is installed. Delete it to free ~320 MB." = "The embedding model is installed. Delete it to free ~320 MB.";
"The relay listens to the %@ container for new conversations and responds with your selected provider." = "The relay listens to the %@ container for new conversations and responds with your selected provider.";
"The tool returned data that can't be formatted. Switch to Raw to inspect the original response." = "The tool returned data that can't be formatted. Switch to Raw to inspect the original response.";
"These options stay in simple mode for clarity. Let’s cover the essentials." = "These options stay in simple mode for clarity. Let’s cover the essentials.";
"Think of Noema as a simple way to run AI on your device. To get useful answers, you pair a local model with datasets (like open textbooks). We’ll guide you through the first setup." = "Think of Noema as a simple way to run AI on your device. To get useful answers, you pair a local model with datasets (like open textbooks). We’ll guide you through the first setup.";
"This app bundles llama.cpp; we keep this in sync with upstream b‑releases." = "This app bundles llama.cpp; we keep this in sync with upstream b‑releases.";
"This backend is unavailable. Remove it or pick another option." = "This backend is unavailable. Remove it or pick another option.";
"This chat stays private—responses are generated on your device after you load a model." = "This chat stays private—responses are generated on your device after you load a model.";
"This configuration exceeds the current RAM safety guard, so benchmarking is disabled." = "This configuration exceeds the current RAM safety guard, so benchmarking is disabled.";
"This dataset is taking a while to load, still working…" = "This dataset is taking a while to load, still working…";
"This dataset's files are not currently supported for document retrieval." = "This dataset's files are not currently supported for document retrieval.";
"This device doesn't support GPU offload." = "This device doesn't support GPU offload.";
"This device doesn't support GPU offload; GGUF models will run on the CPU and generation speed will be significantly slower." = "This device doesn't support GPU offload; GGUF models will run on the CPU and generation speed will be significantly slower.";
"This model doesn't support GPU offload and generation speed will be significantly slower. Consider switching to an MLX model." = "This model doesn't support GPU offload and generation speed will be significantly slower. Consider switching to an MLX model.";
"This model doesn't support GPU offload and generation speed will be significantly slower. Fastest option on this device: use an SLM (Leap) model." = "This model doesn't support GPU offload and generation speed will be significantly slower. Fastest option on this device: use an SLM (Leap) model.";
"This model doesn't support GPU offload and may run slowly. Consider an MLX model." = "This model doesn't support GPU offload and may run slowly. Consider an MLX model.";
"This model doesn't support GPU offload and may run slowly. Fastest option: use an SLM model." = "This model doesn't support GPU offload and may run slowly. Fastest option: use an SLM model.";
"This permanently removes every chat conversation. This action cannot be undone." = "This permanently removes every chat conversation. This action cannot be undone.";
"This textbook appears to be available only as a web page. Noema can't import it as a dataset." = "This textbook appears to be available only as a web page. Noema can't import it as a dataset.";
"Tool calling isn't perfect. Although Noema implements many methods of detecting and instructing models to use tools, not all LLMs will follow instructions and some might not call them correctly or at all. Tool calling heavily depends on model pre-training and will get better as time passes." = "Tool calling isn't perfect. Although Noema implements many methods of detecting and instructing models to use tools, not all LLMs will follow instructions and some might not call them correctly or at all. Tool calling heavily depends on model pre-training and will get better as time passes.";
"Tools" = "Tools";
"Top-k: %@" = "Top-k: %@";
"Top-p" = "Top-p";
"Top-p: %@" = "Top-p: %@";
"Try again" = "Try again";
"Try another dataset if these formats aren't available." = "Try another dataset if these formats aren't available.";
"Try the Qwen 3 1.7B GGUF (Q3_K_M) build below. It's a good starting point and you can delete it anytime." = "Try the Qwen 3 1.7B GGUF (Q3_K_M) build below. It's a good starting point and you can delete it anytime.";
"Unable to load image" = "Unable to load image";
"Unknown error" = "Unknown error";
"Updates every second" = "Updates every second";
"Use" = "Use";
"Use Dataset" = "Use Dataset";
"Use this switch to flip between finding models or datasets." = "Use this switch to flip between finding models or datasets.";
"Using %@" = "Using %@";
"Using %@ of %@ budget" = "Using %1$@ of %2$@ budget";
"Using more than %@ significantly increases RAM usage." = "Using more than %@ significantly increases RAM usage.";
"Using server catalog" = "Using server catalog";
"V Cache Quant" = "V Cache Quant";
"Vendor recommendation: %@" = "Vendor recommendation: %@";
"Version" = "Version";
"Version %@" = "Version %@";
"Version 1.4" = "Version 1.4";
"Vision models require a companion projector (.mmproj). Noema will fetch it automatically the next time you download this model." = "Vision models require a companion projector (.mmproj). Noema will fetch it automatically the next time you download this model.";
"Wait for the response in your other chat to finish before sending a new message." = "Wait for the response in your other chat to finish before sending a new message.";
"Waiting for tool response…" = "Waiting for tool response…";
"We'll extract text and prepare embeddings. You can also start later from the dataset details." = "We'll extract text and prepare embeddings. You can also start later from the dataset details.";
"We'll route new conversations through %@ even if Wi‑Fi names differ. You can switch back by reloading the backend." = "We'll route new conversations through %@ even if Wi‑Fi names differ. You can switch back by reloading the backend.";
"We'll try remote models in priority order for this long before moving to the next option." = "We'll try remote models in priority order for this long before moving to the next option.";
"We'll try this saved identifier even though it's not in the latest catalog." = "We'll try this saved identifier even though it's not in the latest catalog.";
"Web Search Tool Calls" = "Web Search Tool Calls";
"Web Search button" = "Web Search button";
"Web search is included" = "Web search is included";
"Weights" = "Weights";
"Welcome to Noema" = "Welcome to Noema";
"Welcome to Noema for Mac" = "Welcome to Noema for Mac";
"What is Noema?" = "What is Noema?";
"When connecting from another device, point the base URL to your computer (for example http://192.168.0.10:11434) and start Ollama with `OLLAMA_HOST=0.0.0.0` so it accepts remote clients." = "When connecting from another device, point the base URL to your computer (for example http://192.168.0.10:11434) and start Ollama with `OLLAMA_HOST=0.0.0.0` so it accepts remote clients.";
"When enabled, pressing eject on iOS tells this Mac to unload the active relay model." = "When enabled, pressing eject on iOS tells this Mac to unload the active relay model.";
"When enabled, you will be asked to choose parameters every time a model loads." = "When enabled, you will be asked to choose parameters every time a model loads.";
"Wi-Fi: %@" = "Wi-Fi: %@";
"Working set estimate (%@): %@ @ %@ tokens" = "Working set estimate (%1$@): %2$@ @ %3$@ tokens";
"Write prompts, instructions, or notes here. Press return to add new lines." = "Write prompts, instructions, or notes here. Press return to add new lines.";
"You can keep chatting while indexing finishes" = "You can keep chatting while indexing finishes";
"You can only favorite up to three models." = "You can only favorite up to three models.";
"You can restart this process in the dataset settings any time." = "You can restart this process in the dataset settings any time.";
"You're in Off-Grid mode. The Explore tab is hidden and all network features are disabled. You can only use downloaded models and datasets." = "You're in Off-Grid mode. The Explore tab is hidden and all network features are disabled. You can only use downloaded models and datasets.";
"Your Datasets" = "Your Datasets";
"Your Models" = "Your Models";
"Your private AI workspace" = "Your private AI workspace";
"You’re ready to explore. Download models, add datasets, and start chatting." = "You’re ready to explore. Download models, add datasets, and start chatting.";
"minutes" = "minutes";
"•" = "•";
"• Close other applications to free up RAM" = "• Close other applications to free up RAM";
"• Embedding happens locally on your device" = "• Embedding happens locally on your device";
"• Larger datasets take exponentially more time" = "• Larger datasets take exponentially more time";
"• You can pause and resume downloads if needed" = "• You can pause and resume downloads if needed";
"…and %@ more parameter%@" = "…and %1$@ more parameter%2$@";
"⚠️ " = "⚠️ ";
"General" = "General";

"Privacy" = "Privacy";

"About" = "About";

"About & Support" = "About & Support";

"Network" = "Network";

"Embedding Model" = "Embedding Model";

"Retrieval" = "Retrieval";

"Early Testers" = "Early Testers";

"Build Info" = "Build Info";

"Settings" = "Settings";

"Language" = "Language";
"Startup" = "Startup";
"Search models" = "Search models";
"SLM Models - Liquid AI" = "SLM Models - Liquid AI";
"Import" = "Import";
"Import GGUF" = "Import GGUF";
"Import MLX" = "Import MLX";
"Import Failed" = "Import Failed";
"Switching between GGUF/MLX modes" = "Switching between GGUF/MLX modes";
"Switching between GGUF/SLM modes" = "Switching between GGUF/SLM modes";
"Vision-capable model" = "Vision-capable model";
"All" = "All";
"Text" = "Text";
"Vision" = "Vision";
"Continue" = "Continue";
"Try bullet" = "Try:\n• Different keywords (e.g., 'gemma-3' instead of 'gemma 3')\n• %@\n• Adjusting the text/vision filter\n• Checking your search filters";
"Select one or more .gguf files. For vision models, also select the projector .gguf (files containing ‘mmproj’ or ‘projector’). Files will be copied into your local model library." = "Select one or more .gguf files. For vision models, also select the projector .gguf (files containing ‘mmproj’ or ‘projector’). Files will be copied into your local model library.";
"Select the model folder that contains config.json and the weights (safetensors/npz). The entire folder will be imported into your local model library." = "Select the model folder that contains config.json and the weights (safetensors/npz). The entire folder will be imported into your local model library.";
"Memory Budget" = "Memory Budget";
"Startup Defaults" = "Startup Defaults";
"Runtime Safety" = "Runtime Safety";
"Working set estimate (%@): %@ @ %d tokens" = "Working set estimate (%@): %@ @ %d tokens";
"RAM information for this device will be added in a future update." = "RAM information for this device will be added in a future update.";
"Estimate for" = "Estimate for";
"Bypass RAM safety check (may cause crashes)" = "Bypass RAM safety check (may cause crashes)";
"Off-grid Mode" = "Off-grid Mode";
"Local default" = "Local default";
"Add remote default" = "Add remote default";
"When both are available" = "When both are available";
"Remote timeout: %ds" = "Remote timeout: %ds";
"We'll try remote models in priority order for this long before moving to the next option." = "We'll try remote models in priority order for this long before moving to the next option.";
"Appearance" = "Appearance";
"Override the app language. Defaults to the device language on first launch." = "Override the app language. Defaults to the device language on first launch.";
"Reopen Onboarding" = "Reopen Onboarding";
"Join Early Testers" = "Join Early Testers";
"Contact Support" = "Contact Support";
"Write a Review" = "Write a Review";
"Notes & Issues" = "Notes & Issues";
"Delete All Chats" = "Delete All Chats";
"Reset App Data" = "Reset App Data";
"This permanently removes every chat conversation. This action cannot be undone." = "This permanently removes every chat conversation. This action cannot be undone.";
"Chat History Deleted" = "Chat History Deleted";
"App Data Reset" = "App Data Reset";
"Noema has been reset. The embedding model remains installed." = "Noema has been reset. The embedding model remains installed.";
"Failed to Delete Embedding Model" = "Failed to Delete Embedding Model";
"About RAM Usage" = "About RAM Usage";
"The app memory usage budget is an estimate based on your device's total RAM and typical iOS memory management. The actual available memory may vary depending on system load, other running apps, and iOS memory pressure. Models that exceed this budget may cause the app to be terminated by iOS." = "The app memory usage budget is an estimate based on your device's total RAM and typical iOS memory management. The actual available memory may vary depending on system load, other running apps, and iOS memory pressure. Models that exceed this budget may cause the app to be terminated by iOS.";
"Max Chunks" = "Max Chunks";
"Similarity Threshold" = "Similarity Threshold";
"Delete Embedding Model" = "Delete Embedding Model";
"The embedding model is installed. Delete it to free ~320 MB." = "The embedding model is installed. Delete it to free ~320 MB.";
"Swipe left to remove the embedding model from this device." = "Swipe left to remove the embedding model from this device.";
"Verifying…" = "Verifying…";
"Installing…" = "Installing…";
"Download Embedding Model" = "Download Embedding Model";
"Custom Backend" = "Custom Backend";
"Backend" = "Backend";
"Endpoint Type" = "Endpoint Type";
"Endpoints" = "Endpoints";
"Authentication" = "Authentication";
"Model Identifiers" = "Model Identifiers";
"CloudKit container identifier" = "CloudKit container identifier";
"Host device ID" = "Host device ID";
"Base URL" = "Base URL";
"Auth header (optional)" = "Auth header (optional)";
"Model identifier" = "Model identifier";
"Add Identifier" = "Add Identifier";
"Remove identifier" = "Remove identifier";
"Specify your model identifiers, or reload your custom models later." = "Specify your model identifiers, or reload your custom models later.";
"When connecting from another device, point the base URL to your computer (for example http://192.168.0.10:11434) and start Ollama with `OLLAMA_HOST=0.0.0.0` so it accepts remote clients." = "When connecting from another device, point the base URL to your computer (for example http://192.168.0.10:11434) and start Ollama with `OLLAMA_HOST=0.0.0.0` so it accepts remote clients.";
"Connections to localhost may not work from other devices. Replace it with your machine's LAN IP address to allow remote access." = "Connections to localhost may not work from other devices. Replace it with your machine's LAN IP address to allow remote access.";
"Launch Ollama with `OLLAMA_HOST=0.0.0.0` so it can accept remote clients." = "Launch Ollama with `OLLAMA_HOST=0.0.0.0` so it can accept remote clients.";
"Model doesn't support GPU offload" = "Model doesn't support GPU offload";
"This model doesn't support GPU offload and may run slowly. Consider an MLX model." = "This model doesn't support GPU offload and may run slowly. Consider an MLX model.";
"This model doesn't support GPU offload and may run slowly. Fastest option: use an SLM model." = "This model doesn't support GPU offload and may run slowly. Fastest option: use an SLM model.";
"Load Failed" = "Load Failed";
"Don't show again" = "Don't show again";
"Select a model to load" = "Select a model to load";
"Loading model…" = "Loading model…";
"Please wait" = "Please wait";
"Models Library" = "Models Library";
"Streaming" = "Streaming";
"Type to filter models…" = "Type to filter models…";
"Sort" = "Sort";
"Recency" = "Recency";
"Model Library" = "Model Library";
"No models match your search." = "No models match your search.";
"Browse Explore tab" = "Browse Explore tab";
"Manually choose parameters" = "Manually choose parameters";
"Available Quantizations" = "Available Quantizations";
"Sort quantizations" = "Sort quantizations";
"Quant" = "Quant";
"Size ↑" = "Size ↑";
"Size ↓" = "Size ↓";
"Ready" = "Ready";
"Open" = "Open";
"Retry download" = "Retry download";
"Vision-capable" = "Vision-capable";
"Mixture-of-Experts" = "Mixture-of-Experts";
"Resume" = "Resume";
"Discover and download local models" = "Discover and download local models";
"Browse curated datasets for retrieval" = "Browse curated datasets for retrieval";
"Section" = "Section";
"Filter" = "Filter";
"Downloaded" = "Downloaded";
"Size" = "Size";
"Compressed Text" = "Compressed Text";
"Small" = "Small";
"Medium" = "Medium";
"Large" = "Large";
"Very Large" = "Very Large";
"Extreme" = "Extreme";
"Under 10 MB" = "Under 10 MB";
"10–50 MB" = "10–50 MB";
"50–200 MB" = "50–200 MB";
"200–500 MB" = "200–500 MB";
"Over 500 MB" = "Over 500 MB";
"Estimated Embedding Time" = "Estimated Embedding Time";
"Peak RAM Usage" = "Peak RAM Usage";
"Dataset Size" = "Dataset Size";
"Performance Note" = "Performance Note";
"Recommendation" = "Recommendation";
"Remember:" = "Remember:";
"• Close other applications to free up RAM" = "• Close other applications to free up RAM";
"• Embedding happens locally on your device" = "• Embedding happens locally on your device";
"• Larger datasets take exponentially more time" = "• Larger datasets take exponentially more time";
"• You can pause and resume downloads if needed" = "• You can pause and resume downloads if needed";
"Dataset Requirements" = "Dataset Requirements";
"Got it" = "Got it";
"Check Requirements" = "Check Requirements";
"< 1 minute" = "< 1 minute";
"%d minutes" = "%d minutes";
"This dataset should embed quickly with minimal resource usage. Perfect for testing and quick experiments." = "This dataset should embed quickly with minimal resource usage. Perfect for testing and quick experiments.";
"This dataset is a reasonable size for most systems. Embedding should complete in a few minutes." = "This dataset is a reasonable size for most systems. Embedding should complete in a few minutes.";
"This is a substantial dataset. Ensure you have adequate RAM and expect embedding to take 10–30 minutes." = "This is a substantial dataset. Ensure you have adequate RAM and expect embedding to take 10–30 minutes.";
"This is a very large dataset. Embedding may take 30–60 minutes and requires significant RAM." = "This is a very large dataset. Embedding may take 30–60 minutes and requires significant RAM.";
"This is an extremely large dataset. Consider splitting it into smaller parts for better performance." = "This is an extremely large dataset. Consider splitting it into smaller parts for better performance.";
"Go ahead and download! This size works well on all systems." = "Go ahead and download! This size works well on all systems.";
"Recommended for most users. Make sure you have at least 4GB of free RAM." = "Recommended for most users. Make sure you have at least 4GB of free RAM.";
"Recommended only if you have 8GB+ RAM available. Close other applications before embedding." = "Recommended only if you have 8GB+ RAM available. Close other applications before embedding.";
"Recommended only for systems with 16GB+ RAM. Consider processing during off-hours." = "Recommended only for systems with 16GB+ RAM. Consider processing during off-hours.";
"Not recommended for typical systems. Consider finding a smaller version or subset of this dataset." = "Not recommended for typical systems. Consider finding a smaller version or subset of this dataset.";
"Sample dataset" = "Sample dataset";
"Could not connect to Ollama at localhost. When connecting from another device, replace \"localhost\" with your computer's IP address or hostname and start Ollama with `OLLAMA_HOST=0.0.0.0` so it can accept remote connections." = "Could not connect to Ollama at localhost. When connecting from another device, replace \"localhost\" with your computer's IP address or hostname and start Ollama with `OLLAMA_HOST=0.0.0.0` so it can accept remote connections.";
"Could not connect to the Ollama server. Make sure Ollama is running on %@ and is configured to accept connections from this device (for example by launching it with `OLLAMA_HOST=0.0.0.0`)." = "Could not connect to the Ollama server. Make sure Ollama is running on %@ and is configured to accept connections from this device (for example by launching it with `OLLAMA_HOST=0.0.0.0`).";
"Move Up" = "Move Up";
"Move Down" = "Move Down";
"Remove" = "Remove";
"Startup remote options" = "Startup remote options";
"No models cached yet. Open the backend to refresh its catalog." = "No models cached yet. Open the backend to refresh its catalog.";
"We'll try this saved identifier even though it's not in the latest catalog." = "We'll try this saved identifier even though it's not in the latest catalog.";
"This backend is unavailable. Remove it or pick another option." = "This backend is unavailable. Remove it or pick another option.";
"Backend removed" = "Backend removed";
"What is Max Chunks?" = "What is Max Chunks?";
"What is Similarity Threshold?" = "What is Similarity Threshold?";
"Approx. %@" = "Approx. %@";
"Advanced mode shows developer options and diagnostics." = "Advanced mode shows developer options and diagnostics.";
"Simple mode hides advanced settings for a cleaner interface." = "Simple mode hides advanced settings for a cleaner interface.";
"Hide advanced controls" = "Hide advanced controls";
"Show advanced controls" = "Show advanced controls";
"Adjust model settings" = "Adjust model settings";
"Model Settings" = "Model Settings";
"SLM models are not supported on this platform." = "SLM models are not supported on this platform.";
"Model likely exceeds memory budget. Lower context or choose a smaller quant." = "Model likely exceeds memory budget. Lower context or choose a smaller quant.";
"Apple bundle models aren't supported on macOS yet." = "Apple bundle models aren't supported on macOS yet.";
"Estimate: %@\nBudget: %@\nContext length: %@ tokens\n\nThis is an estimate based on your device’s memory budget, context length (KV cache), and typical runtime overheads. Actual usage may vary." = "Estimate: %@\nBudget: %@\nContext length: %@ tokens\n\nThis is an estimate based on your device’s memory budget, context length (KV cache), and typical runtime overheads. Actual usage may vary.";
"Model likely fits in RAM" = "Model likely fits in RAM";
"Model may not fit in RAM" = "Model may not fit in RAM";
"Fits in RAM (estimated)" = "Fits in RAM (estimated)";
"May not fit (estimated)" = "May not fit (estimated)";
"Please provide a backend name." = "Please provide a backend name.";
"A backend with this name already exists." = "A backend with this name already exists.";
"Backend not found." = "Backend not found.";
"This Noema Relay device is already configured." = "This Noema Relay device is already configured.";
"OpenAI API" = "OpenAI API";
"LM Studio" = "LM Studio";
"Ollama" = "Ollama";
"Cloud Relay" = "Cloud Relay";
"Noema Relay" = "Noema Relay";
"Compatible with OpenAI-style /v1 endpoints" = "Compatible with OpenAI-style /v1 endpoints";
"Connect to LM Studio's REST server" = "Connect to LM Studio's REST server";
"Target an Ollama host for chat and pulls" = "Target an Ollama host for chat and pulls";
"Use Noema's Cloud Relay on macOS" = "Use Noema's Cloud Relay on macOS";
"Pair with your Mac over CloudKit" = "Pair with your Mac over CloudKit";
"Please provide the CloudKit container identifier." = "Please provide the CloudKit container identifier.";
"Please provide the host device ID from the Mac relay." = "Please provide the host device ID from the Mac relay.";
"Missing host device ID for Noema Relay." = "Missing host device ID for Noema Relay.";
"Missing CloudKit container identifier." = "Missing CloudKit container identifier.";
"Relay catalog unavailable." = "Relay catalog unavailable.";
"Relay catalog is still syncing. Open the Mac relay, ensure it is signed into iCloud, then try again in a moment." = "Relay catalog is still syncing. Open the Mac relay, ensure it is signed into iCloud, then try again in a moment.";
"Terms of Use" = "Terms of Use";
"Privacy Policy" = "Privacy Policy";
"Contact Support" = "Contact Support";
"Write a Review" = "Write a Review";
"Notes & Issues" = "Notes & Issues";
"Qwen3-1.7B is a compact and efficient model from the Qwen3 family, suitable for on-device usage with strong general capabilities." = "Qwen3-1.7B is a compact and efficient model from the Qwen3 family, suitable for on-device usage with strong general capabilities.";
"Gemma 3n E2B is a lightweight instruction-tuned model from Google's Gemma family, optimized for efficient on-device conversations." = "Gemma 3n E2B is a lightweight instruction-tuned model from Google's Gemma family, optimized for efficient on-device conversations.";
"Gemma 3n E2B is an instruction-tuned variant of Google's Gemma family built for efficient reasoning on low-resource devices.\nAvailable in GGUF quants (Q3_K_M, Q4_K_M, Q6_K) and an MLX 4-bit build for Apple Silicon.\n" = "Gemma 3n E2B is an instruction-tuned variant of Google's Gemma family built for efficient reasoning on low-resource devices.\nAvailable in GGUF quants (Q3_K_M, Q4_K_M, Q6_K) and an MLX 4-bit build for Apple Silicon.\n";
"Phi-4 Mini Reasoning is a lightweight model from the Phi-4 family, tuned for strong reasoning and efficiency across tasks." = "Phi-4 Mini Reasoning is a lightweight model from the Phi-4 family, tuned for strong reasoning and efficiency across tasks.";
"Phi-4 Mini Reasoning — a compact model in Microsoft’s Phi-4 line designed for logical reasoning, problem solving, and instruction-following. \nDistributed in efficient GGUF quants (Q3_K_L, Q4_K_M, Q6_K) and an MLX 4-bit variant for Apple Silicon devices.\n" = "Phi-4 Mini Reasoning — a compact model in Microsoft’s Phi-4 line designed for logical reasoning, problem solving, and instruction-following. \nDistributed in efficient GGUF quants (Q3_K_L, Q4_K_M, Q6_K) and an MLX 4-bit variant for Apple Silicon devices.\n";
"The base URL looks invalid. Please include the host (e.g. http://127.0.0.1:1234)." = "The base URL looks invalid. Please include the host (e.g. http://127.0.0.1:1234).";
"Could not build the remote endpoint URL." = "Could not build the remote endpoint URL.";
"The server returned an unexpected response." = "The server returned an unexpected response.";
"Server responded with status code %d." = "Server responded with status code %d.";
"Server responded with status code %d: %@" = "Server responded with status code %d: %@";
"Failed to decode server response." = "Failed to decode server response.";

"Name" = "Name";

"Explore" = "Explore";
"Search datasets" = "Search datasets";
"Download" = "Download";
"Offline" = "Offline";
"Tap to load" = "Tap to load";
"%d models" = "%d models";
"Updated %@" = "Updated %@";
"No models fetched yet" = "No models fetched yet";
"Auth" = "Auth";
"Local Network" = "Local Network";
"Direct" = "Direct";
"LAN" = "LAN";
"LAN · %@" = "LAN · %@";
"Chat Path" = "Chat Path";
"Models Path" = "Models Path";
"Endpoint Type" = "Endpoint Type";
"Endpoints" = "Endpoints";
"Authentication" = "Authentication";
"Model Identifiers" = "Model Identifiers";
"Field requirements will depend on your specific backend deployment." = "Field requirements will depend on your specific backend deployment.";
"Uses Noema Relay configuration" = "Uses Noema Relay configuration";
"Chat: %@\nModels: %@" = "Chat: %@\nModels: %@";
"Download Dataset" = "Download Dataset";
"No files listed for this dataset." = "No files listed for this dataset.";
"This dataset's files are not currently supported for document retrieval." = "This dataset's files are not currently supported for document retrieval.";
"Supported formats: %@" = "Supported formats: %@";
"Try another dataset if these formats aren't available." = "Try another dataset if these formats aren't available.";
"Found unsupported: %@ …" = "Found unsupported: %@ …";
"This textbook appears to be available only as a web page. Noema can't import it as a dataset." = "This textbook appears to be available only as a web page. Noema can't import it as a dataset.";
"Download complete" = "Download complete";
"Downloading…" = "Downloading…";
"No compatible files found for retrieval. Supported formats: %@" = "No compatible files found for retrieval. Supported formats: %@";
"No internet connection." = "No internet connection.";
"Request timed out. Please try again." = "Request timed out. Please try again.";
"Connection was lost. Please try again." = "Connection was lost. Please try again.";
"Unexpected error: %@" = "Unexpected error: %@";

/* DatasetRecommendationView – metrics and requirements */
"Est. Time" = "Est. Time";
"Peak RAM" = "Peak RAM";
"Things to keep in mind" = "Things to keep in mind";
"Close other applications to free up RAM" = "Close other applications to free up RAM";
"Embedding happens locally on your device" = "Embedding happens locally on your device";
"Larger datasets take exponentially more time" = "Larger datasets take exponentially more time";
"You can pause and resume downloads if needed" = "You can pause and resume downloads if needed";

/* Mac chat quick-load menu */
"Open Model Library" = "Open Model Library";
"Favorites" = "Favorites";
"Recent" = "Recent";

/* Noema Relay – status messages */
"Relay stopped" = "Relay stopped";
"Loaded model ready" = "Loaded model ready";
"Failed to load model" = "Failed to load model";
"Refreshing relay catalog…" = "Refreshing relay catalog…";
"Relay catalog refreshed" = "Relay catalog refreshed";
"Failed to refresh catalog: %@" = "Failed to refresh catalog: %@";
"Updating LAN status…" = "Updating LAN status…";
"Failed to update LAN status" = "Failed to update LAN status";
"Activating %@…" = "Activating %@…";
"Relay switched to %@" = "Relay switched to %@";
"Failed to activate %@" = "Failed to activate %@";
"Relay idle after ejecting %@" = "Relay idle after ejecting %@";
"Failed to eject %@" = "Failed to eject %@";
"Checking exposed endpoints…" = "Checking exposed endpoints…";
"Failed to start LAN server" = "Failed to start LAN server";
"Starting relay…" = "Starting relay…";
"Starting relay… Offline: %@" = "Starting relay… Offline: %@";
"Listening for conversations…" = "Listening for conversations…";
"iOS requested a relay switch. Start the relay to respond." = "iOS requested a relay switch. Start the relay to respond.";

/* Noema Relay – Bluetooth & CloudKit */
"Bluetooth ready to advertise" = "Bluetooth ready to advertise";
"Warming up Bluetooth radio…" = "Warming up Bluetooth radio…";
"Broadcasting relay details" = "Broadcasting relay details";
"Pairing refreshed %@" = "Pairing refreshed %@";
"Client Wi-Fi: %@" = "Client Wi-Fi: %@";
"Last seen %@" = "Last seen %@";
"Checking iCloud availability…" = "Checking iCloud availability…";
"CloudKit unavailable" = "CloudKit unavailable";
"Connected to iCloud" = "Connected to iCloud";
"Sign in to iCloud to enable the relay" = "Sign in to iCloud to enable the relay";
"iCloud access is restricted" = "iCloud access is restricted";
"Unable to determine iCloud status" = "Unable to determine iCloud status";
"CloudKit status unknown" = "CloudKit status unknown";
"Set a CloudKit container identifier in RelayConfiguration.swift to publish the catalog." = "Set a CloudKit container identifier in RelayConfiguration.swift to publish the catalog.";
"Verifying access to %@…" = "Verifying access to %@…";
"Open System Settings → Apple ID and sign in with the same account as your iPhone or iPad." = "Open System Settings → Apple ID and sign in with the same account as your iPhone or iPad.";
"Screen Time or device management restrictions may be blocking iCloud access." = "Screen Time or device management restrictions may be blocking iCloud access.";
"Check your internet connection and try again." = "Check your internet connection and try again.";
"Relay catalog is still syncing. Initial publishes typically finish within about 30 seconds after you start the relay." = "Relay catalog is still syncing. Initial publishes typically finish within about 30 seconds after you start the relay.";
"Publishing catalog updates to CloudKit…" = "Publishing catalog updates to CloudKit…";
"Catalog is live and ready for paired devices." = "Catalog is live and ready for paired devices.";
"Start the relay to resume CloudKit updates." = "Start the relay to resume CloudKit updates.";
"Waiting for the first catalog publish from this Mac." = "Waiting for the first catalog publish from this Mac.";
"CloudKit reported an error while publishing the catalog. Restart the relay to retry." = "CloudKit reported an error while publishing the catalog. Restart the relay to retry.";
"Catalog version %@ synced %@." = "Catalog version %@ synced %@.";
"Catalog version %@ is ready." = "Catalog version %@ is ready.";

/* Noema Relay – exposure controls */
"Clear All" = "Clear All";
"Select All" = "Select All";
"Hide every relay source from paired devices" = "Hide every relay source from paired devices";
"Expose every relay source to paired devices" = "Expose every relay source to paired devices";
"auth" = "auth";
"no auth" = "no auth";
"hidden" = "hidden";
"unavailable" = "unavailable";
"Eject button unloads relay model" = "Eject button unloads relay model";

/* Noema Relay – pairing & dataset helpers */
"Model file missing (.gguf)" = "Model file missing (.gguf)";
"Model path missing" = "Model path missing";
"Imported Dataset" = "Imported Dataset";
"Dataset name" = "Dataset name";
"Keep this device near the Mac that's running Noema Relay to import its settings." = "Keep this device near the Mac that's running Noema Relay to import its settings.";
"Scanning for your Mac relay…" = "Scanning for your Mac relay…";
"Ready to scan nearby relays" = "Ready to scan nearby relays";
"Bluetooth access is required to pair with the Mac relay." = "Bluetooth access is required to pair with the Mac relay.";
"Stop Scanning" = "Stop Scanning";
"Start Scan" = "Start Scan";
"Connection verified. Relay details imported from this Mac." = "Connection verified. Relay details imported from this Mac.";
"Signal strength unavailable" = "Signal strength unavailable";
"Very close" = "Very close";
"Nearby" = "Nearby";
"Within one room" = "Within one room";
"Move closer for a stronger signal" = "Move closer for a stronger signal";
"This Mac" = "This Mac";

/* Accessibility announcements */
"Model loaded." = "Model loaded.";
"Prompt submitted." = "Prompt submitted.";
"Generating response…" = "Generating response…";
"Response generated." = "Response generated.";

/* Tabs & accessibility labels */
"Stored" = "Stored";
"Web Search" = "Web Search";
"Open Stored" = "Open Stored";
"Message input" = "Message input";
"What is Web Search button?" = "What is Web Search button?";
