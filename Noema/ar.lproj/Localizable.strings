/* Auto-generated localization file. */
"%@" = "%@";
"%@ %" = "%1$@ %2$";
"%@ %@" = "%1$@ %2$@";
"%@ models" = "%@ النماذج";
"%@ of %@ budget" = "%1$@ من %2$@ الميزانية";
"%@ tokens" = "%@ الرموز المميزة";
"%@ – %@" = "%1$@ - %2$@";
"%@ • %@" = "%1$@ • %2$@";
"%@%" = "%1$@%2$";
"%@% · %@" = "%1$@%2$ · %3$@";
"%@." = "%@.";
"%@:" = "%@:";
"(+ mmproj %@%)" = "(+ mmproj %1$@%2$)";
"... and %@ more" = "... و%@ أكثر";
"320 MB • One-time download" = "320 ميجابايت • تنزيل لمرة واحدة";
"320 MB • One‑time download used for local dataset search" = "320 ميجابايت • يتم التنزيل مرة واحدة للبحث في مجموعة البيانات المحلية";
"A larger context keeps more conversation history, but also uses more memory. Adjust it here." = "يحتفظ السياق الأكبر بسجل أكبر للمحادثات، ولكنه يستخدم أيضًا المزيد من الذاكرة. اضبطه هنا.";
"Active" = "نشيط";
"Active Model" = "النموذج النشط";
"Active connection via %@" = "اتصال نشط عبر %@";
"Active experts per token: %@ of %@" = "الخبراء النشطون لكل رمز مميز: %1$@ من %2$@";
"Add a remote backend to configure remote startup fallbacks." = "أضف واجهة خلفية عن بعد لتكوين إجراءات احتياطية لبدء التشغيل عن بعد.";
"Add one or two datasets (like open textbooks) to keep responses accurate and help the AI cite sources." = "أضف مجموعة أو اثنتين من مجموعات البيانات (مثل الكتب المدرسية المفتوحة) للحفاظ على دقة الإجابات ومساعدة الذكاء الاصطناعي في الاستشهاد بالمصادر.";
"Add remote endpoint" = "إضافة نقطة النهاية البعيدة";
"Adjust appearance, privacy options, and network preferences here." = "اضبط المظهر وخيارات الخصوصية وتفضيلات الشبكة هنا.";
"Advanced" = "متقدم";
"Advanced Controls" = "الضوابط المتقدمة";
"Allows models to use a privacy-preserving web search API when you tap the globe in chat. Default is ON. In Offline Only mode, the button is disabled." = "يسمح للعارضات باستخدام واجهة برمجة تطبيقات بحث الويب التي تحافظ على الخصوصية عند النقر على الكرة الأرضية في الدردشة. الافتراضي قيد التشغيل. في وضع عدم الاتصال فقط، يتم تعطيل الزر.";
"Analyzing context..." = "تحليل السياق...";
"App Memory Usage (estimated)" = "استخدام ذاكرة التطبيق (تقديري)";
"App memory usage budget: %@ (conservative)" = "ميزانية استخدام ذاكرة التطبيق: %@ (محافظة)";
"Approx. Tokens" = "تقريبا. الرموز";
"Arm web search when you truly need outside info. It has a small daily limit and most chats don’t require it." = "قم بالبحث على الويب عندما تحتاج حقًا إلى معلومات خارجية. لها حد يومي صغير ومعظم الدردشات لا تتطلب ذلك.";
"Ask Noema anything" = "اسأل نويما أي شيء";
"Ask…" = "بسأل…";
"Attach Photos" = "إرفاق الصور";
"Backend not found" = "لم يتم العثور على الواجهة الخلفية";
"Benchmark running…" = "تشغيل المؤشر…";
"Benchmarking is not available for this model format." = "لا يتوفر قياس الأداء لتنسيق النموذج هذا.";
"Blocks all network traffic, model downloads, and cloud connections so everything stays on‑device." = "يحظر كل حركة مرور الشبكة وتنزيلات النماذج والاتصالات السحابية بحيث يبقى كل شيء على الجهاز.";
"Bluetooth Pairing" = "الاقتران بالبلوتوث";
"Browse community models and curated datasets to expand what Noema can do." = "تصفح نماذج المجتمع ومجموعات البيانات المنسقة لتوسيع ما يمكن أن تفعله Noema.";
"Browse curated datasets for retrieval" = "تصفح مجموعات البيانات المنسقة لاسترجاعها";
"CFBundleShortVersionString1.0" = "CFBundleShortVersionString1.0";
"Cancel" = "يلغي";
"Cancel Benchmark" = "إلغاء المعيار";
"Discover Intelligence" = "اكتشف الذكاء";
"Catalog" = "كتالوج";
"Chat" = "محادثة";
"Chat privately with your local models, sync datasets, and manage the relay server in one place." = "قم بالدردشة بشكل خاص مع النماذج المحلية الخاصة بك، وقم بمزامنة مجموعات البيانات، وإدارة خادم الترحيل في مكان واحد.";
"Chats" = "الدردشات";
"Checking…" = "جارٍ التحقق…";
"Citation %@" = "الاقتباس %@";
"Cloud Relay Container" = "حاوية ترحيل السحابة";
"Cloud Relay via CloudKit (auto-discovery and Bluetooth pairing)" = "Cloud Relay عبر CloudKit (الاكتشاف التلقائي والاقتران بالبلوتوث)";
"CloudKit" = "CloudKit";
"CloudKit bridge active. Local replies are generated on this Mac." = "جسر CloudKit نشط. يتم إنشاء الردود المحلية على جهاز Mac هذا.";
"Compiling Metal kernels for GGUF models can take up to a minute on first load." = "يمكن أن يستغرق تجميع النوى المعدنية لنماذج GGUF ما يصل إلى دقيقة عند التحميل الأول.";
"Complete the streaming response in the active chat before sending again." = "أكمل الرد المتدفق في الدردشة النشطة قبل الإرسال مرة أخرى.";
"Confirm and Start Embedding" = "تأكيد وبدء التضمين";
"Connected" = "متصل";
"Connection Modes" = "أوضاع الاتصال";
"Connection Status: %@" = "حالة الاتصال: %@";
"Container" = "حاوية";
"Context Length" = "طول السياق";
"Context Length: 4096 tokens" = "طول السياق: 4096 رمزًا";
"Context length is under 5000 tokens. With images and multi-sequence decoding (n_seq_max=16), per-sequence memory can be too small, leading to a crash. Increase context to at least 8192 in Model Settings." = "طول السياق أقل من 5000 رمزًا. مع الصور وفك التشفير متعدد التسلسل (n_seq_max=16)، يمكن أن تكون الذاكرة لكل تسلسل صغيرة جدًا، مما يؤدي إلى حدوث عطل. قم بزيادة السياق إلى 8192 على الأقل في إعدادات النموذج.";
"Controls how many high‑scoring passages (chunks) can be injected into the prompt. Higher values increase recall but consume more context window and can slow responses. Typical range 3–6." = "يتحكم في عدد المقاطع عالية الدرجات (الأجزاء) التي يمكن إدخالها في الموجه. تعمل القيم الأعلى على زيادة الاستدعاء ولكنها تستهلك المزيد من نوافذ السياق ويمكن أن تؤدي إلى إبطاء الاستجابات. النطاق النموذجي 3-6.";
"Couldn't load the recommended model." = "تعذر تحميل النموذج الموصى به.";
"Couldn’t load the recommended model right now." = "تعذر تحميل النموذج الموصى به الآن.";
"Creativity: %@. Low values focus responses; high values add variety." = "الإبداع: %@. استجابات تركيز القيم المنخفضة؛ القيم العالية تضيف التنوع.";
"Dark" = "مظلم";
"Dataset" = "مجموعة البيانات";
"Dataset indexing in progress..." = "جاري فهرسة مجموعة البيانات...";
"Dataset ready to use" = "مجموعة البيانات جاهزة للاستخدام";
"Datasets" = "مجموعات البيانات";
"Datasets enrich the model with focused knowledge. Toggle one on to use it in chat." = "تعمل مجموعات البيانات على إثراء النموذج بالمعرفة المركزة. قم بتبديل واحد لاستخدامه في الدردشة.";
"Default selection (~%@) balances RAM usage against model quality." = "يعمل التحديد الافتراضي (~%@) على موازنة استخدام ذاكرة الوصول العشوائي (RAM) مقابل جودة النموذج.";
"Delete" = "يمسح";
"Delete Dataset" = "حذف مجموعة البيانات";
"Deletes all chats, downloaded models, and datasets, and restores settings to defaults. The embedding model stays installed." = "يحذف جميع الدردشات والنماذج التي تم تنزيلها ومجموعات البيانات ويعيد الإعدادات إلى الإعدادات الافتراضية. يبقى نموذج التضمين مثبتًا.";
"Device" = "جهاز";
"Digest:" = "هضم:";
"Done" = "منتهي";
"Done!" = "منتهي!";
"Download Now" = "تحميل الآن";
"Download a model from Explore or add a remote endpoint to get started." = "قم بتنزيل نموذج من Explore أو قم بإضافة نقطة نهاية بعيدة للبدء.";
"Download a small embedding model so Noema can index and search your datasets" = "قم بتنزيل نموذج تضمين صغير حتى تتمكن Noema من فهرسة مجموعات البيانات الخاصة بك والبحث فيها";
"Downloaded datasets need on-device embedding. Give it a few minutes after download finishes." = "تحتاج مجموعات البيانات التي تم تنزيلها إلى التضمين على الجهاز. امنحها بضع دقائق بعد انتهاء التنزيل.";
"Downloaded models and datasets live here so you can manage them offline." = "النماذج ومجموعات البيانات التي تم تنزيلها موجودة هنا حتى تتمكن من إدارتها دون الاتصال بالإنترنت.";
"Downloading…" = "جارٍ التنزيل…";
"Draft tokens: %@" = "رموز المسودة: %@";
"Draft window: %@" = "نافذة المسودة: %@";
"EPUB viewing not supported on this platform" = "عرض EPUB غير مدعوم على هذا النظام الأساسي";
"Embedding" = "التضمين";
"Embedding Model Ready" = "نموذج التضمين جاهز";
"Embedding is resource intensive. For best performance, plug in your phone. Do you want to proceed on battery?" = "التضمين يتطلب الكثير من الموارد. للحصول على أفضل أداء، قم بتوصيل هاتفك. هل تريد المتابعة على البطارية؟";
"Enabling Bluetooth…" = "جارٍ تفعيل البلوتوث…";
"Enhance with Datasets" = "تعزيز مع مجموعات البيانات";
"Error" = "خطأ";
"Estimated working set: %@ · Budget: %@" = "مجموعة العمل المقدرة: %1$@ · الميزانية: %2$@";
"Experts Per Token" = "الخبراء لكل رمز";
"Explore Datasets" = "استكشاف مجموعات البيانات";
"Expose any downloaded models or connected remote endpoints from the Stored tab to your paired devices. Select which one should answer conversations when the relay is running." = "اكشف أي نماذج تم تنزيلها أو نقاط النهاية البعيدة المتصلة من علامة التبويب \"مخزن\" إلى أجهزتك المقترنة. حدد الشخص الذي يجب أن يجيب على المحادثات عند تشغيل التتابع.";
"Expose to iOS" = "فضح لنظام iOS";
"Explore the latest open-source models optimized for your Mac." = "استكشف أحدث النماذج مفتوحة المصدر المحسّنة لجهاز Mac الخاص بك.";
"Failed to load README" = "فشل تحميل README";
"Failed: %@" = "فشل: %@";
"Fastest option on this device: SLM (Leap) models." = "الخيار الأسرع على هذا الجهاز: طرازات SLM (Leap).";
"Field requirements will depend on your specific backend deployment." = "ستعتمد المتطلبات الميدانية على عملية النشر الخلفية المحددة لديك.";
"Files" = "ملفات";
"First, enable fast dataset search" = "أولاً، قم بتمكين البحث السريع في مجموعة البيانات";
"First-time GGUF load takes longer" = "يستغرق تحميل GGUF لأول مرة وقتًا أطول";
"First-time download from HuggingFace" = "التنزيل لأول مرة من HuggingFace";
"First‑time setup: download the Qwen‑1.7B model and embeddings.\nWi‑Fi recommended." = "الإعداد لأول مرة: قم بتنزيل نموذج Qwen‑1.7B وعناصر التضمين.\nيوصى باستخدام خدمة الواي فاي.";
"For best performance, please plug in your phone until this completes." = "للحصول على أفضل أداء، يرجى توصيل هاتفك حتى يكتمل ذلك.";
"Force Local Network" = "قوة الشبكة المحلية";
"Forces chat traffic through the last LAN host even if Wi‑Fi names don't match yet." = "يفرض حركة مرور الدردشة عبر مضيف LAN الأخير حتى إذا لم تتطابق أسماء Wi‑Fi حتى الآن.";
"Formatted view unavailable" = "العرض المنسق غير متاح";
"Found unsupported: %@ …" = "تم العثور على غير مدعوم: %@ ...";
"Frequency penalty: %@" = "عقوبة التردد: %@";
"GGUF models are the most compatible option. Use the format switch to explore the other builds when you need them." = "نماذج GGUF هي الخيار الأكثر توافقًا. استخدم مفتاح التنسيق لاستكشاف الإصدارات الأخرى عندما تحتاج إليها.";
"GGUF works everywhere. MLX targets Apple Silicon speed. SLM focuses on responsiveness on any device." = "GGUF يعمل في كل مكان. يستهدف MLX سرعة Apple Silicon. يركز SLM على الاستجابة على أي جهاز.";
"GPU Offload Layers" = "طبقات إلغاء تحميل GPU";
"GPU off-load is not supported for this model." = "لا يتم دعم إلغاء تحميل وحدة معالجة الرسومات لهذا الطراز.";
"Get Started" = "ابدأ";
"Help shape Noema by trying upcoming features and sharing feedback." = "ساعد في تشكيل Noema من خلال تجربة الميزات القادمة ومشاركة التعليقات.";
"High context lengths use more memory" = "تستخدم أطوال السياق العالية المزيد من الذاكرة";
"High-quality embedding model for local RAG" = "نموذج تضمين عالي الجودة لـ RAG المحلي";
"Host ID: %@" = "معرف المضيف: %@";
"How it works" = "كيف يعمل";
"I'm New to Local LLMs, Guide Me" = "أنا جديد في LLMs المحلية، أرشدني";
"If enabled, the app will attempt to load models even when they likely exceed your device's memory budget. This can cause the app to terminate." = "في حالة التمكين، سيحاول التطبيق تحميل النماذج حتى عندما تتجاوز على الأرجح ميزانية ذاكرة جهازك. يمكن أن يتسبب هذا في إنهاء التطبيق.";
"Import Dataset" = "استيراد مجموعة البيانات";
"Import PDFs, EPUBs, or text files to build local knowledge bases." = "قم باستيراد ملفات PDF أو EPUB أو ملفات نصية لبناء قواعد المعرفة المحلية.";
"Import your own PDFs, EPUBs, or TXT files and keep them local." = "قم باستيراد ملفات PDF أو EPUB أو ملفات TXT الخاصة بك واحتفظ بها محليًا.";
"Importing & Scanning..." = "الاستيراد والمسح...";
"In progress..." = "في تَقَدم...";
"Indexing %@" = "الفهرسة %@";
"Indexing dataset…" = "فهرسة مجموعة البيانات...";
"Indexing: %@% · %@" = "الفهرسة: %1$@%2$ · %3$@";
"Install a local model to make it available at launch." = "قم بتثبيت نموذج محلي لإتاحته عند الإطلاق.";
"Install another model with the same architecture and equal or smaller size to enable speculative decoding." = "قم بتثبيت نموذج آخر بنفس البنية وحجم متساوٍ أو أصغر لتمكين فك التشفير التخميني.";
"K Cache Quant" = "K ذاكرة التخزين المؤقت الكمية";
"Keep this iPhone or iPad within a few feet of the Mac that is advertising Noema Relay. We'll pull the relay details automatically once connected." = "احتفظ بجهاز iPhone أو iPad هذا على بعد بضعة أقدام من جهاز Mac الذي يعلن عن Noema Relay. سنقوم بسحب تفاصيل التتابع تلقائيًا بمجرد الاتصال.";
"LAN URL: %@" = "عنوان URL للشبكة المحلية: %@";
"Large Model Downloads" = "تنزيلات للنماذج الكبيرة";
"Last Sync" = "آخر مزامنة";
"Last refreshed %@" = "آخر تحديث %@";
"Latest benchmark" = "أحدث المعايير";
"Latest integrated release: %@" = "أحدث إصدار متكامل: %@";
"Library" = "مكتبة";
"Light" = "ضوء";
"Llama.cpp" = "Call.cpp";
"Load" = "حمولة";
"Load a local model before chatting. You can download one from the Explore tab or load a model you've already installed." = "قم بتحميل نموذج محلي قبل الدردشة. يمكنك تنزيل واحد من علامة التبويب \"استكشاف\" أو تحميل نموذج قمت بتثبيته بالفعل.";
"Loading recommendation…" = "جارٍ تحميل التوصية…";
"Loading…" = "تحميل…";
"Local Network HTTP server for LAN clients (OpenAI-compatible)" = "خادم HTTP للشبكة المحلية لعملاء LAN (متوافق مع OpenAI)";
"Low = focused. High = varied." = "منخفض = مركز. عالية = متنوعة.";
"Lower = more results (more noise). Higher = stricter matches." = "أقل = المزيد من النتائج (المزيد من الضوضاء). أعلى = تطابقات أكثر صرامة.";
"MLX currently manages expert routing automatically; manual selection is not supported." = "يقوم MLX حاليًا بإدارة توجيه الخبراء تلقائيًا؛ التحديد اليدوي غير مدعوم.";
"Many models are several gigabytes in size and require a stable connection and sufficient storage. Downloads can fail or take a long time on slow networks or devices with limited space." = "يبلغ حجم العديد من الطرز عدة غيغابايت وتتطلب اتصالاً مستقرًا ومساحة تخزين كافية. يمكن أن تفشل التنزيلات أو تستغرق وقتًا طويلاً على الشبكات البطيئة أو الأجهزة ذات المساحة المحدودة.";
"Max Chunks: %@" = "القطع القصوى: %@";
"Max recommended context on this device: ~%@ tokens" = "الحد الأقصى للسياق الموصى به على هذا الجهاز: ~%@ الرموز المميزة";
"Measure real-world generation speed for this configuration. A short scripted prompt will run locally and report timing and memory usage." = "قم بقياس سرعة التوليد في العالم الحقيقي لهذا التكوين. سيتم تشغيل مطالبة نصية قصيرة محليًا والإبلاغ عن التوقيت واستخدام الذاكرة.";
"Min-p" = "دقيقة ص";
"Min-p: %@" = "الحد الأدنى ع: %@";
"Minimum cosine similarity a passage must have to be considered relevant. Lower = more passages (higher recall, more noise). Higher = fewer, more precise passages. Try 0.2–0.4 for broad questions; 0.5–0.7 for precise lookups." = "الحد الأدنى من تشابه جيب التمام يجب أن يعتبر المقطع ذا صلة. أقل = المزيد من المقاطع (استدعاء أعلى، مزيد من الضوضاء). أعلى = مقاطع أقل وأكثر دقة. حاول 0.2-0.4 للأسئلة العامة؛ 0.5-0.7 لعمليات البحث الدقيقة.";
"MoE layers: %@ / %@" = "طبقات MoE: %1$@ / %2$@";
"Model Detection Limitations" = "قيود الكشف عن النموذج";
"Model Formats" = "تنسيقات النماذج";
"Models" = "نماذج";
"Models shown here are exposed by the Mac relay. Manage sources in the Relay tab on macOS to share more models." = "يتم عرض النماذج المعروضة هنا بواسطة مرحل Mac. قم بإدارة المصادر في علامة التبويب Relay على نظام macOS لمشاركة المزيد من النماذج.";
"Move your device closer to the Mac running the relay if it doesn't appear right away. Bluetooth discovery usually completes within a few seconds." = "انقل جهازك بالقرب من جهاز Mac الذي يقوم بتشغيل الترحيل إذا لم يظهر على الفور. عادةً ما يكتمل اكتشاف البلوتوث في غضون ثوانٍ قليلة.";
"Name your dataset" = "قم بتسمية مجموعة البيانات الخاصة بك";
"Nearby Relays" = "المرحلات القريبة";
"Nearby iPhone and iPad devices discover your Mac relay instantly and sync pairing codes over the air." = "تكتشف أجهزة iPhone وiPad القريبة جهاز Mac الخاص بك على الفور وتقوم بمزامنة رموز الاقتران عبر الهواء.";
"Need a fresh thread? Tap the plus button for a brand-new conversation." = "هل تحتاج إلى خيط جديد؟ اضغط على زر علامة الجمع لإجراء محادثة جديدة تمامًا.";
"Nice! You already have the recommended GGUF starter model ready to use." = "لطيف - جيد! لديك بالفعل نموذج بداية GGUF الموصى به جاهز للاستخدام.";
"No compatible files found for retrieval. Supported: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV" = "لم يتم العثور على ملفات متوافقة لاسترجاعها. المدعومة: PDF، EPUB، TXT، MD، JSON، JSONL، CSV، TSV";
"No connection responses recorded yet." = "لم يتم تسجيل أي ردود اتصال حتى الآن.";
"No datasets available yet. Import or download datasets to build your personal library." = "لا توجد مجموعات بيانات متاحة حتى الآن. قم باستيراد مجموعات البيانات أو تنزيلها لإنشاء مكتبتك الشخصية.";
"No datasets found. Try different keywords." = "لم يتم العثور على مجموعات بيانات. جرب كلمات رئيسية مختلفة.";
"No datasets imported yet." = "لم يتم استيراد أي مجموعات بيانات حتى الآن.";
"No datasets yet" = "لا توجد مجموعات بيانات حتى الآن";
"No files listed for this dataset." = "لا توجد ملفات مدرجة لمجموعة البيانات هذه.";
"No model >" = "لا يوجد نموذج>";
"No model loaded" = "لم يتم تحميل أي نموذج";
"No models available. Add downloads or remote connections in Stored to configure the relay." = "لا توجد نماذج متاحة. أضف التنزيلات أو الاتصالات عن بعد في المخزن لتكوين الترحيل.";
"No models cached yet. Open the backend to refresh its catalog." = "لم يتم تخزين أي نماذج مؤقتًا حتى الآن. افتح الواجهة الخلفية لتحديث الكتالوج الخاص بها.";
"No models found for '%@'" = "لم يتم العثور على نماذج لـ '%@'";
"No models loaded right now. We'll spin one up when a request arrives." = "لم يتم تحميل أي نماذج الآن. سنقوم بتدوير واحدة عند وصول الطلب.";
"No models match your search." = "لا توجد نماذج تطابق بحثك.";
"No models yet" = "لا توجد نماذج حتى الآن";
"No parameters" = "لا توجد معلمات";
"No quant files available" = "لا توجد ملفات الكمية المتاحة";
"No recent devices. We'll list clients the next time they talk to this relay." = "لا توجد أجهزة حديثة. سنقوم بإدراج العملاء في المرة القادمة التي يتحدثون فيها إلى هذا التتابع.";
"No remote endpoints configured yet." = "لم يتم تكوين نقاط النهاية البعيدة حتى الآن.";
"No remote endpoints configured." = "لم يتم تكوين أي نقاط نهاية بعيدة.";
"No ≥Q3 quants are available for this model." = "لا تتوفر كميات ≥Q3 لهذا النموذج.";
"Noema" = "نوفمبر";
"Noema REST API — /api/v0/* for model catalog & operations" = "Noema REST API — /api/v0/* لكتالوج النماذج والعمليات";
"Noema Relay" = "تتابع نويما";
"Noema Server" = "خادم نويما";
"Noema attempts to gauge available memory to prevent models from exceeding device limits. These checks may occasionally miss risky situations and allow a model to crash your app, or they may be overly conservative and block a model that could have run fine." = "تحاول Noema قياس الذاكرة المتوفرة لمنع النماذج من تجاوز حدود الجهاز. قد تفوت عمليات التحقق هذه أحيانًا مواقف محفوفة بالمخاطر وتسمح للنموذج بتعطل تطبيقك، أو قد تكون متحفظة بشكل مفرط وتحظر نموذجًا كان من الممكن أن يعمل بشكل جيد.";
"Noema could not find a projector in the repository. If the model advertises vision, ensure the mmproj file is present in the same folder as the weights." = "لم تتمكن Noema من العثور على جهاز عرض في المستودع. إذا كان النموذج يعلن عن الرؤية، فتأكد من وجود ملف mmproj في نفس المجلد مثل الأوزان.";
"Noema has been reset. The embedding model remains installed." = "تمت إعادة ضبط Noema. يظل نموذج التضمين مثبتًا.";
"Nomic Embed Text v1.5 (Q4_K_M)" = "Nomic تضمين النص v1.5 (Q4_K_M)";
"None" = "لا أحد";
"Not found" = "لم يتم العثور عليه";
"Not provided" = "غير متوفر";
"OK" = "نعم";
"Off-Grid" = "خارج الشبكة";
"Off-grid mode blocks every network call so the app stays self-contained. Good luck exploring Noema!" = "يعمل الوضع خارج الشبكة على حظر كل مكالمة عبر الشبكة حتى يظل التطبيق مستقلاً بذاته. حظا سعيدا في استكشاف Noema!";
"Only one expert is available for this model; the active expert count is fixed." = "يتوفر خبير واحد فقط لهذا النموذج؛ تم إصلاح عدد الخبراء النشطين.";
"Open Stored to choose a model to run locally or connect to a remote endpoint." = "افتح Stored لاختيار نموذج لتشغيله محليًا أو الاتصال بنقطة نهاية بعيدة.";
"Open the sidebar to revisit any previous session without losing your spot." = "افتح الشريط الجانبي لزيارة أي جلسة سابقة دون أن تفقد مكانك.";
"OpenAI-style API — /v1/chat/completions, /v1/completions, /v1/models" = "واجهة برمجة التطبيقات على نمط OpenAI — /v1/chat/completions، /v1/completions، /v1/models";
"Optimizations in use" = "التحسينات قيد الاستخدام";
"PDF viewing not supported on this platform" = "عرض PDF غير مدعوم على هذا النظام الأساسي";
"Pick a model and add a dataset" = "اختر نموذجًا وأضف مجموعة بيانات";
"Pick the SLM format when you want ultra-responsive models that run well anywhere." = "اختر تنسيق SLM عندما تريد نماذج فائقة الاستجابة تعمل بشكل جيد في أي مكان.";
"Pinned answer" = "الإجابة المثبتة";
"Pinned answer unavailable" = "الإجابة المثبتة غير متاحة";
"Preparation" = "تحضير";
"Preparing Embedding Model" = "إعداد نموذج التضمين";
"Preparing benchmark…" = "جارٍ إعداد المعيار…";
"Preparing…" = "جارٍ التحضير…";
"Presence penalty: %@" = "عقوبة الحضور: %@";
"Projector (mmproj)" = "جهاز عرض (ممبروج)";
"Projector downloaded automatically from Hugging Face. Keep this file alongside the weights so vision remains available." = "يتم تنزيل جهاز العرض تلقائيًا من Hugging Face. احتفظ بهذا الملف بجانب الأوزان حتى تظل الرؤية متاحة.";
"Quantize the runtime key cache to save memory. Experimental." = "قم بقياس ذاكرة التخزين المؤقت لمفتاح وقت التشغيل لتوفير الذاكرة. تجريبي.";
"Quantize the runtime value cache to save memory when Flash Attention is enabled. Experimental." = "قم بقياس ذاكرة التخزين المؤقت لقيمة وقت التشغيل لحفظ الذاكرة عند تمكين Flash Attention. تجريبي.";
"Qwen 3 1.7B GGUF (Q3_K_M) gives you a dependable starting point. Delete it anytime if you need space." = "يمنحك Qwen 3 1.7B GGUF (Q3_K_M) نقطة بداية يمكن الاعتماد عليها. احذفه في أي وقت إذا كنت بحاجة إلى مساحة.";
"RAG embeds normalized paragraphs from your PDFs and EPUBs. On each question, the most relevant chunks are retrieved and added to the prompt. Images are ignored." = "يقوم RAG بتضمين فقرات تمت تسويتها من ملفات PDF وEPUB الخاصة بك. في كل سؤال، يتم استرداد الأجزاء الأكثر صلة وإضافتها إلى الموجه. يتم تجاهل الصور.";
"RAM Safety Checks" = "فحوصات سلامة ذاكرة الوصول العشوائي";
"RAM information for this device will be added in a future update." = "ستتم إضافة معلومات ذاكرة الوصول العشوائي (RAM) لهذا الجهاز في التحديث المستقبلي.";
"REST Endpoints" = "نقاط نهاية REST";
"Reachable at" = "يمكن الوصول إليه في";
"Ready for Use" = "جاهز للاستخدام";
"Recent Chats" = "الدردشات الأخيرة";
"Recommended" = "مُستَحسَن";
"Recommended Starter Model" = "نموذج البداية الموصى به";
"Relay ID" = "معرف التتابع";
"Relay Server Running" = "تشغيل خادم الترحيل";
"Relay Sources" = "مصادر التتابع";
"Remaining: %@" = "المتبقي: %@";
"Remember:" = "يتذكر:";
"Remote Backends" = "الواجهات الخلفية البعيدة";
"Remote endpoint is offline. This model can't be found at this time." = "نقطة النهاية البعيدة غير متصلة بالإنترنت. لا يمكن العثور على هذا النموذج في هذا الوقت.";
"Remote timeout: %@s" = "المهلة البعيدة: %@s";
"Repeat last N tokens: %@" = "كرر آخر رموز N: %@";
"Repetition penalty: %@" = "عقوبة التكرار: %@";
"Request Parameters" = "طلب المعلمات";
"Responses are generated by the macOS relay server. Configure the provider (LM Studio or Ollama) on the Mac app." = "يتم إنشاء الاستجابات بواسطة خادم ترحيل macOS. قم بتكوين الموفر (LM Studio أو Ollama) على تطبيق Mac.";
"Result" = "نتيجة";
"Results" = "نتائج";
"Save" = "يحفظ";
"Saving…" = "توفير…";
"Score: %@" = "النتيجة: %@";
"SearXNG web search is available without limits. There's nothing to purchase—just enable the globe button in chat whenever you need online results." = "بحث الويب SearXNG متاح بلا حدود. لا يوجد شيء يمكنك شراؤه — فقط قم بتمكين زر الكرة الأرضية في الدردشة عندما تحتاج إلى نتائج عبر الإنترنت.";
"SearXNG web search is enabled for this device." = "تم تمكين بحث الويب SearXNG لهذا الجهاز.";
"Search" = "يبحث";
"Search for any subject you're interested in." = "ابحث عن أي موضوع يهمك.";
"Search requests are proxied through https://search.noemaai.com and are available without quotas." = "يتم إرسال طلبات البحث عبر https://search.noemaai.com وهي متاحة بدون حصص.";
"Seed" = "بذرة";
"Selecting more experts keeps additional expert weights resident in RAM and increases memory usage." = "يؤدي تحديد المزيد من الخبراء إلى الاحتفاظ بأوزان الخبراء الإضافية الموجودة في ذاكرة الوصول العشوائي (RAM) وزيادة استخدام الذاكرة.";
"Server Settings" = "إعدادات الخادم";
"Share Logs" = "مشاركة السجلات";
"Sharing relay payload with nearby devices…" = "مشاركة حمولة الترحيل مع الأجهزة القريبة...";
"Shows the last server response." = "يظهر آخر استجابة للخادم.";
"Signal" = "إشارة";
"Similarity Threshold" = "عتبة التشابه";
"Simple" = "بسيط";
"Smooth loops and phrase echo by balancing repetition controls." = "حلقات سلسة وصدى العبارة من خلال موازنة عناصر التحكم في التكرار.";
"Smooth loops and repeated phrases by tuning repetition controls." = "حلقات سلسة وعبارات متكررة عن طريق ضبط عناصر التحكم في التكرار.";
"Some models do not provide the system prompts needed for Noema to detect and configure them properly. These models may be unusable until they include appropriate metadata or support." = "لا توفر بعض الطرز مطالبات النظام اللازمة لـ Noema لاكتشافها وتكوينها بشكل صحيح. قد تكون هذه النماذج غير قابلة للاستخدام حتى تتضمن بيانات تعريف مناسبة أو دعمًا مناسبًا.";
"Source unavailable. Check storage or network settings." = "المصدر غير متاح. تحقق من إعدادات التخزين أو الشبكة.";
"Source: %@" = "المصدر: %@";
"Specify identifiers for models that are not listed by the server. Leave blank to rely on the server's catalog." = "حدد معرفات للنماذج التي لم يتم إدراجها بواسطة الخادم. اتركه فارغًا للاعتماد على كتالوج الخادم.";
"Specify your model identifiers, or reload your custom models later." = "حدد معرفات النموذج الخاص بك، أو قم بإعادة تحميل النماذج المخصصة الخاصة بك لاحقًا.";
"Speed up with a smaller helper model." = "تسريع العمل باستخدام نموذج مساعد أصغر.";
"Start by installing one model. Then add a dataset (like an open textbook) so the AI can answer with grounded knowledge." = "ابدأ بتثبيت نموذج واحد. ثم أضف مجموعة بيانات (مثل كتاب مدرسي مفتوح) حتى يتمكن الذكاء الاصطناعي من الإجابة بمعرفة راسخة.";
"Start the relay to automatically share the latest payload with nearby devices." = "ابدأ التتابع لمشاركة أحدث الحمولة تلقائيًا مع الأجهزة القريبة.";
"Start with a reliable Qwen 3 1.7B build. It balances capability with small download size." = "ابدأ ببناء Qwen 3 1.7B موثوق به. إنه يوازن بين القدرة وحجم التنزيل الصغير.";
"Startup defaults now live in Settings → Startup. Favorite models here to keep them handy." = "الإعدادات الافتراضية لبدء التشغيل موجودة الآن في الإعدادات → بدء التشغيل. النماذج المفضلة هنا لإبقائها في متناول يديك.";
"Status" = "حالة";
"Stay close to your Mac" = "ابق على مقربة من جهاز Mac الخاص بك";
"Stop Using Dataset" = "التوقف عن استخدام مجموعة البيانات";
"Streaming" = "جاري";
"Streaming response…" = "استجابة البث…";
"Supported Endpoints" = "نقاط النهاية المدعومة";
"Supported formats: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV" = "التنسيقات المدعومة: PDF، EPUB، TXT، MD، JSON، JSONL، CSV، TSV";
"Swap between the new stacked chat panel and the classic tab bar layout." = "قم بالتبديل بين لوحة الدردشة المكدسة الجديدة وتخطيط شريط علامات التبويب الكلاسيكي.";
"Swipe left to remove the embedding model from this device." = "اسحب لليسار لإزالة نموذج التضمين من هذا الجهاز.";
"Switch the selector to MLX for Apple Silicon‑optimized builds that excel at speed." = "قم بتبديل المحدد إلى MLX للإصدارات المحسنة من Apple Silicon والتي تتميز بالسرعة.";
"Switch to Raw to inspect the original response." = "قم بالتبديل إلى Raw لفحص الاستجابة الأصلية.";
"System" = "نظام";
"Tap to load" = "انقر للتحميل";
"Temperature" = "درجة حرارة";
"Testing" = "اختبار";
"The app memory usage budget is an estimate based on your device's total RAM and typical iOS memory management. The actual available memory may vary depending on system load, other running apps, and iOS memory pressure. Models that exceed this budget may cause the app to be terminated by iOS." = "تعد ميزانية استخدام ذاكرة التطبيق عبارة عن تقدير يعتمد على إجمالي ذاكرة الوصول العشوائي (RAM) بجهازك وإدارة ذاكرة iOS النموذجية. قد تختلف الذاكرة الفعلية المتاحة اعتمادًا على تحميل النظام والتطبيقات الأخرى قيد التشغيل وضغط ذاكرة iOS. قد تتسبب النماذج التي تتجاوز هذه الميزانية في إنهاء التطبيق بواسطة iOS.";
"The embedding model is installed. Delete it to free ~320 MB." = "تم تثبيت نموذج التضمين. احذفه لتحرير ~ 320 ميجابايت.";
"The relay listens to the %@ container for new conversations and responds with your selected provider." = "يستمع التتابع إلى حاوية %@ للمحادثات الجديدة ويستجيب مع المزود الذي حددته.";
"The tool returned data that can't be formatted. Switch to Raw to inspect the original response." = "قامت الأداة بإرجاع البيانات التي لا يمكن تنسيقها. قم بالتبديل إلى Raw لفحص الاستجابة الأصلية.";
"These options stay in simple mode for clarity. Let’s cover the essentials." = "تظل هذه الخيارات في الوضع البسيط من أجل الوضوح. دعونا نغطي الأساسيات.";
"Think of Noema as a simple way to run AI on your device. To get useful answers, you pair a local model with datasets (like open textbooks). We’ll guide you through the first setup." = "فكر في Noema كطريقة بسيطة لتشغيل الذكاء الاصطناعي على جهازك. للحصول على إجابات مفيدة، يمكنك إقران نموذج محلي بمجموعات البيانات (مثل الكتب المدرسية المفتوحة). سنرشدك خلال الإعداد الأول.";
"This app bundles llama.cpp; we keep this in sync with upstream b‑releases." = "حزم هذا التطبيق llama.cpp؛ نحن نحافظ على تزامن هذا مع إصدارات b المنبع.";
"This backend is unavailable. Remove it or pick another option." = "هذه الواجهة الخلفية غير متوفرة. قم بإزالته أو اختر خيارًا آخر.";
"This chat stays private—responses are generated on your device after you load a model." = "تظل هذه الدردشة خاصة، حيث يتم إنشاء الردود على جهازك بعد تحميل النموذج.";
"This configuration exceeds the current RAM safety guard, so benchmarking is disabled." = "يتجاوز هذا التكوين حماية أمان ذاكرة الوصول العشوائي (RAM) الحالية، لذا تم تعطيل قياس الأداء.";
"This dataset is taking a while to load, still working…" = "يستغرق تحميل مجموعة البيانات هذه بعض الوقت، ولا تزال تعمل...";
"This dataset's files are not currently supported for document retrieval." = "ملفات مجموعة البيانات هذه غير مدعومة حاليًا لاسترداد المستندات.";
"This device doesn't support GPU offload." = "هذا الجهاز لا يدعم إلغاء تحميل وحدة معالجة الرسومات.";
"This device doesn't support GPU offload; GGUF models will run on the CPU and generation speed will be significantly slower." = "هذا الجهاز لا يدعم إلغاء تحميل وحدة معالجة الرسومات؛ سيتم تشغيل نماذج GGUF على وحدة المعالجة المركزية وستكون سرعة الإنشاء أبطأ بشكل ملحوظ.";
"This model doesn't support GPU offload and generation speed will be significantly slower. Consider switching to an MLX model." = "لا يدعم هذا الطراز إلغاء تحميل وحدة معالجة الرسومات وستكون سرعة الإنشاء أبطأ بشكل ملحوظ. فكر في التبديل إلى طراز MLX.";
"This model doesn't support GPU offload and generation speed will be significantly slower. Fastest option on this device: use an SLM (Leap) model." = "لا يدعم هذا الطراز إلغاء تحميل وحدة معالجة الرسومات وستكون سرعة الإنشاء أبطأ بشكل ملحوظ. الخيار الأسرع على هذا الجهاز: استخدم نموذج SLM (Leap).";
"This model doesn't support GPU offload and may run slowly. Consider an MLX model." = "لا يدعم هذا الطراز إلغاء تحميل وحدة معالجة الرسومات وقد يعمل ببطء. النظر في نموذج MLX.";
"This model doesn't support GPU offload and may run slowly. Fastest option: use an SLM model." = "لا يدعم هذا الطراز إلغاء تحميل وحدة معالجة الرسومات وقد يعمل ببطء. الخيار الأسرع: استخدم نموذج SLM.";
"This permanently removes every chat conversation. This action cannot be undone." = "يؤدي هذا إلى إزالة كل محادثة دردشة بشكل دائم. لا يمكن التراجع عن هذا الإجراء.";
"This textbook appears to be available only as a web page. Noema can't import it as a dataset." = "يبدو أن هذا الكتاب المدرسي متاح كصفحة ويب فقط. لا يمكن لـ Noema استيرادها كمجموعة بيانات.";
"Tool calling isn't perfect. Although Noema implements many methods of detecting and instructing models to use tools, not all LLMs will follow instructions and some might not call them correctly or at all. Tool calling heavily depends on model pre-training and will get better as time passes." = "استدعاء الأداة ليس مثاليًا. على الرغم من أن Noema تنفذ العديد من أساليب الكشف وتوجيه النماذج لاستخدام الأدوات، إلا أنه لن يتبع جميع طلاب LLM التعليمات وقد لا يستدعيها البعض بشكل صحيح أو على الإطلاق. يعتمد استدعاء الأداة بشكل كبير على التدريب المسبق للنموذج وسيتحسن مع مرور الوقت.";
"Tools" = "أدوات";
"Top-k: %@" = "توب ك: %@";
"Top-p" = "أعلى ص";
"Top-p: %@" = "أعلى ص: %@";
"Try again" = "حاول ثانية";
"Try another dataset if these formats aren't available." = "جرّب مجموعة بيانات أخرى إذا لم تكن هذه التنسيقات متوفرة.";
"Try the Qwen 3 1.7B GGUF (Q3_K_M) build below. It's a good starting point and you can delete it anytime." = "جرب إصدار Qwen 3 1.7B GGUF (Q3_K_M) أدناه. إنها نقطة بداية جيدة ويمكنك حذفها في أي وقت.";
"Unable to load image" = "غير قادر على تحميل الصورة";
"Unknown error" = "خطأ غير معروف";
"Updates every second" = "تحديثات كل ثانية";
"Use" = "يستخدم";
"Use Dataset" = "استخدم مجموعة البيانات";
"Use this switch to flip between finding models or datasets." = "استخدم رمز التبديل هذا للتنقل بين البحث عن النماذج أو مجموعات البيانات.";
"Using %@" = "باستخدام %@";
"Using %@ of %@ budget" = "استخدام %1$@ من %2$@ الميزانية";
"Using more than %@ significantly increases RAM usage." = "يؤدي استخدام أكثر من %@ إلى زيادة استخدام ذاكرة الوصول العشوائي (RAM) بشكل ملحوظ.";
"Using server catalog" = "باستخدام كتالوج الخادم";
"V Cache Quant" = "كمية ذاكرة التخزين المؤقت V";
"Vendor recommendation: %@" = "توصية البائع: %@";
"Version" = "إصدار";
"Version %@" = "الإصدار %@";
"Version 1.4" = "الإصدار 1.4";
"Vision models require a companion projector (.mmproj). Noema will fetch it automatically the next time you download this model." = "تتطلب نماذج الرؤية جهاز عرض مصاحبًا (.mmproj). ستقوم Noema بإحضاره تلقائيًا في المرة التالية التي تقوم فيها بتنزيل هذا النموذج.";
"Wait for the response in your other chat to finish before sending a new message." = "انتظر حتى ينتهي الرد في محادثتك الأخرى قبل إرسال رسالة جديدة.";
"Waiting for tool response…" = "في انتظار استجابة الأداة...";
"We'll extract text and prepare embeddings. You can also start later from the dataset details." = "سنقوم باستخراج النص وإعداد التضمينات. يمكنك أيضًا البدء لاحقًا من تفاصيل مجموعة البيانات.";
"We'll route new conversations through %@ even if Wi‑Fi names differ. You can switch back by reloading the backend." = "سنقوم بتوجيه المحادثات الجديدة عبر %@ حتى لو اختلفت أسماء Wi‑Fi. يمكنك التبديل مرة أخرى عن طريق إعادة تحميل الواجهة الخلفية.";
"We'll try remote models in priority order for this long before moving to the next option." = "سنجرب النماذج البعيدة حسب ترتيب الأولوية لفترة طويلة قبل الانتقال إلى الخيار التالي.";
"We'll try this saved identifier even though it's not in the latest catalog." = "سنجرب هذا المعرف المحفوظ على الرغم من عدم وجوده في أحدث كتالوج.";
"Web Search Tool Calls" = "مكالمات أداة بحث الويب";
"Web Search button" = "زر بحث الويب";
"Web search is included" = "يتم تضمين البحث على شبكة الإنترنت";
"Weights" = "الأوزان";
"Welcome to Noema" = "مرحبا بكم في نويما";
"Welcome to Noema for Mac" = "مرحبًا بك في Noema لنظام التشغيل Mac";
"What is Noema?" = "ما هو النويما؟";
"When connecting from another device, point the base URL to your computer (for example http://192.168.0.10:11434) and start Ollama with `OLLAMA_HOST=0.0.0.0` so it accepts remote clients." = "عند الاتصال من جهاز آخر، قم بتوجيه عنوان URL الأساسي إلى جهاز الكمبيوتر الخاص بك (على سبيل المثال http://192.168.0.10:11434) وابدأ تشغيل Ollama باستخدام `OLLAMA_HOST=0.0.0.0` حتى يقبل العملاء البعيدين.";
"When enabled, pressing eject on iOS tells this Mac to unload the active relay model." = "عند التمكين، يؤدي الضغط على زر الإخراج على نظام iOS إلى إخبار جهاز Mac هذا بإلغاء تحميل نموذج الترحيل النشط.";
"When enabled, you will be asked to choose parameters every time a model loads." = "عند التمكين، سيُطلب منك اختيار المعلمات في كل مرة يتم فيها تحميل النموذج.";
"Wi-Fi: %@" = "واي فاي: %@";
"Working set estimate (%@): %@ @ %@ tokens" = "تقدير مجموعة العمل (%1$@): %2$@ @ %3$@ الرموز المميزة";
"Write prompts, instructions, or notes here. Press return to add new lines." = "اكتب المطالبات أو التعليمات أو الملاحظات هنا. اضغط على العودة لإضافة خطوط جديدة.";
"You can keep chatting while indexing finishes" = "يمكنك الاستمرار في الدردشة أثناء انتهاء الفهرسة";
"You can only favorite up to three models." = "يمكنك فقط تفضيل ما يصل إلى ثلاثة نماذج.";
"You can restart this process in the dataset settings any time." = "يمكنك إعادة تشغيل هذه العملية في إعدادات مجموعة البيانات في أي وقت.";
"You're in Off-Grid mode. The Explore tab is hidden and all network features are disabled. You can only use downloaded models and datasets." = "أنت في وضع خارج الشبكة. تكون علامة التبويب \"استكشاف\" مخفية ويتم تعطيل جميع ميزات الشبكة. يمكنك فقط استخدام النماذج ومجموعات البيانات التي تم تنزيلها.";
"Your Datasets" = "مجموعات البيانات الخاصة بك";
"Your Models" = "النماذج الخاصة بك";
"Your private AI workspace" = "مساحة عمل الذكاء الاصطناعي الخاصة بك";
"You’re ready to explore. Download models, add datasets, and start chatting." = "أنت جاهز للاستكشاف. قم بتنزيل النماذج وإضافة مجموعات البيانات وبدء الدردشة.";
"minutes" = "دقائق";
"•" = "";
"• Close other applications to free up RAM" = "• أغلق التطبيقات الأخرى لتحرير ذاكرة الوصول العشوائي";
"• Embedding happens locally on your device" = "• يتم التضمين محليًا على جهازك";
"• Larger datasets take exponentially more time" = "• تستغرق مجموعات البيانات الأكبر حجمًا وقتًا أطول بشكل كبير";
"• You can pause and resume downloads if needed" = "• يمكنك إيقاف التنزيلات مؤقتًا واستئنافها إذا لزم الأمر";
"…and %@ more parameter%@" = "…و %1$@ المزيد من المعلمات%2$@";
"⚠️ " = "";
"General" = "عام";

"Privacy" = "الخصوصية";

"About" = "حول";

"About & Support" = "حول والدعم";

"Network" = "الشبكة";

"Embedding Model" = "نموذج التضمين";

"Retrieval" = "الاسترجاع";

"Early Testers" = "المختبرون الأوائل";

"Build Info" = "معلومات البناء";

"Settings" = "الإعدادات";

"Language" = "اللغة";
"Startup" = "بدء التشغيل";
"Search models" = "ابحث عن النماذج";
"SLM Models - Liquid AI" = "SLM Models - Liquid AI";
"Import" = "استيراد";
"Import GGUF" = "استيراد GGUF";
"Import MLX" = "استيراد MLX";
"Import Failed" = "فشل الاستيراد";
"Switching between GGUF/MLX modes" = "التبديل بين أوضاع GGUF/MLX";
"Switching between GGUF/SLM modes" = "التبديل بين أوضاع GGUF/SLM";
"Vision-capable model" = "نموذج يدعم الرؤية";
"All" = "الكل";
"Text" = "نص";
"Vision" = "رؤية";
"Continue" = "متابعة";
"Try bullet" = "جرّب:\n• كلمات مفتاحية مختلفة (مثلاً 'gemma-3' بدلاً من 'gemma 3')\n• %@\n• ضبط مرشح النص/الرؤية\n• التحقق من فلاتر البحث";
"Select one or more .gguf files. For vision models, also select the projector .gguf (files containing ‘mmproj’ or ‘projector’). Files will be copied into your local model library." = "Select one or more .gguf files. For vision models, also select the projector .gguf (files containing ‘mmproj’ or ‘projector’). Files will be copied into your local model library.";
"Select the model folder that contains config.json and the weights (safetensors/npz). The entire folder will be imported into your local model library." = "Select the model folder that contains config.json and the weights (safetensors/npz). The entire folder will be imported into your local model library.";
"K Cache Quantization" = "تحويل تكميم ذاكرة K";
"V Cache Quantization" = "تحويل تكميم ذاكرة V";
"Favorite Limit Reached" = "تم بلوغ حد المفضلة";
"Overview" = "نظرة عامة";
"Sampling" = "أخذ العينات";
"Speculative Decoding" = "فك التشفير التخمينى";
"Benchmark" = "الاختبار القياسي";
"Maintenance" = "الصيانة";
"MLX" = "MLX";
"Tokenizer Path (tokenizer.json)" = "مسار المُقَطِّع (tokenizer.json)";
"Back" = "رجوع";
"Favorite Model" = "النموذج المفضل";
"Reset to Default Settings" = "إعادة التعيين للإعدادات الافتراضية";
"Delete Model" = "حذف النموذج";
"Delete %@?" = "هل تريد حذف %@؟";
"Not provided by repository" = "غير متوفر في المستودع";
"Unknown (not checked yet)" = "غير معروف (لم يُفحص بعد)";
"Keep Model In Memory" = "الاحتفاظ بالنموذج في الذاكرة";
"GPU Offload Layers: %@/%@" = "طبقات إزاحة GPU: ‎%1$@/%2$@";
"CPU Threads: %@" = "خيوط المعالج: ‎%@";
"Offload KV Cache to GPU" = "إزاحة ذاكرة KV إلى GPU";
"Use mmap()" = "استخدام ‎mmap()‎";
"Random" = "عشوائي";
"Flash Attention" = "فلاش أتنشن";
"1 expert" = "خبير واحد";
"%@ experts" = "%@ خبراء";
"Helper Model" = "نموذج مساعد";
"Draft strategy" = "إستراتيجية المسودة";
"Run Benchmark" = "تشغيل الاختبار القياسي";
"Benchmarking…" = "جارٍ إجراء الاختبار…";
"Leap SLM models manage runtime optimizations automatically." = "نماذج Leap SLM تدير تحسينات وقت التشغيل تلقائيًا.";
"This format doesn't expose tunable runtime optimizations." = "هذا التنسيق لا يوفر تحسينات وقت تشغيل قابلة للضبط.";
"Token processing" = "معالجة الرموز";
"Token generation" = "توليد الرموز";
"Total time" = "الوقت الكلي";
"First token" = "أول رمز";
"Peak memory" = "الذاكرة القصوى";
"Output tokens" = "الرموز الناتجة";
"End Guide" = "إنهاء الدليل";
"Streaming benchmark output…" = "يتم بث ناتج الاختبار…";
"Streaming… %@ chunks (~%@ tok est.)" = "بث… ‎%1$@ مقطع (حوالي ‎%2$@ رمز متوقع)";
"Streaming… %d chunks (~%d tok est.)" = "بث… ‎%d مقطع (حوالي ‎%d رمز متوقع)";
"The selected model's weights could not be located." = "تعذر العثور على أوزان النموذج المحدد.";
"Failed to load model for benchmark: %@" = "فشل تحميل النموذج للاختبار: ‎%@";
"Benchmark generation failed: %@" = "فشل إنشاء الاختبار القياسي: ‎%@";
"K Cache" = "ذاكرة K المؤقتة";
"V Cache" = "ذاكرة V المؤقتة";
"KV Offload" = "إزاحة KV";
"On" = "تشغيل";
"Off" = "إيقاف";
"GPU" = "GPU";
"CPU" = "CPU";
"%.1f tok/s" = "%.1f tok/s";
"%.1fs" = "%.1fs";
"%.2fs" = "%.2fs";
"Move Up" = "نقل لأعلى";
"Move Down" = "نقل لأسفل";
"Remove" = "إزالة";
"Startup remote options" = "خيارات البدء عن بُعد";
"No models cached yet. Open the backend to refresh its catalog." = "لا توجد نماذج مخزنة مؤقتًا بعد. افتح الواجهة الخلفية لتحديث الكتالوج.";
"We'll try this saved identifier even though it's not in the latest catalog." = "سنحاول هذا المعرّف المحفوظ حتى لو لم يكن في أحدث كتالوج.";
"This backend is unavailable. Remove it or pick another option." = "الواجهة الخلفية غير متاحة. أزلها أو اختر خيارًا آخر.";
"Backend removed" = "تمت إزالة الواجهة الخلفية";
"What is Max Chunks?" = "ما هو الحد الأقصى للقطع؟";
"What is Similarity Threshold?" = "ما هو حد التشابه؟";
"Approx. %@" = "تقريبًا %@";
"Advanced mode shows developer options and diagnostics." = "الوضع المتقدم يعرض خيارات المطور والتشخيص.";
"Simple mode hides advanced settings for a cleaner interface." = "الوضع البسيط يخفي الإعدادات المتقدمة لواجهة أنظف.";
"Hide advanced controls" = "إخفاء عناصر التحكم المتقدمة";
"Show advanced controls" = "إظهار عناصر التحكم المتقدمة";
"Adjust model settings" = "ضبط إعدادات النموذج";
"Model Settings" = "إعدادات النموذج";
"SLM models are not supported on this platform." = "نماذج SLM غير مدعومة على هذا النظام.";
"Model likely exceeds memory budget. Lower context or choose a smaller quant." = "قد يتجاوز النموذج ميزانية الذاكرة. خفّض السياق أو اختر كمّية أصغر.";
"Apple bundle models aren't supported on macOS yet." = "نماذج Apple المجمّعة غير مدعومة على macOS بعد.";
"Estimate: %@\nBudget: %@\nContext length: %@ tokens\n\nThis is an estimate based on your device’s memory budget, context length (KV cache), and typical runtime overheads. Actual usage may vary." = "التقدير: %@\nالميزانية: %@\nطول السياق: %@ رمز\n\nهذا تقدير يعتمد على ميزانية الذاكرة للجهاز وطول السياق (ذاكرة KV) والنفقات التشغيلية المعتادة. قد يختلف الاستخدام الفعلي.";
"Model likely fits in RAM" = "من المحتمل أن النموذج يناسب الذاكرة العشوائية";
"Model may not fit in RAM" = "قد لا يناسب النموذج الذاكرة العشوائية";
"Fits in RAM (estimated)" = "يناسب الذاكرة (تقديري)";
"May not fit (estimated)" = "قد لا يناسب (تقديري)";
"Please provide a backend name." = "يرجى إدخال اسم للواجهة الخلفية.";
"A backend with this name already exists." = "توجد واجهة خلفية بهذا الاسم بالفعل.";
"Backend not found." = "الواجهة الخلفية غير موجودة.";
"This Noema Relay device is already configured." = "تم تكوين جهاز Noema Relay هذا بالفعل.";
"OpenAI API" = "OpenAI API";
"LM Studio" = "LM Studio";
"Ollama" = "Ollama";
"Cloud Relay" = "Cloud Relay";
"Noema Relay" = "Noema Relay";
"Compatible with OpenAI-style /v1 endpoints" = "متوافق مع نقاط نهاية ‎/v1 بأسلوب OpenAI";
"Connect to LM Studio's REST server" = "الاتصال بخادم REST الخاص بـ LM Studio";
"Target an Ollama host for chat and pulls" = "استهداف مضيف Ollama للدردشة والتنزيل";
"Use Noema's Cloud Relay on macOS" = "استخدام Cloud Relay من Noema على macOS";
"Pair with your Mac over CloudKit" = "الإقران مع جهاز Mac عبر CloudKit";
"Please provide the CloudKit container identifier." = "يرجى إدخال معرف حاوية CloudKit.";
"Please provide the host device ID from the Mac relay." = "يرجى إدخال معرف جهاز المضيف من ريلّي Mac.";
"Missing host device ID for Noema Relay." = "معرف جهاز المضيف لـ Noema Relay مفقود.";
"Missing CloudKit container identifier." = "معرف حاوية CloudKit مفقود.";
"Relay catalog unavailable." = "كتالوج الريلّي غير متاح.";
"Relay catalog is still syncing. Open the Mac relay, ensure it is signed into iCloud, then try again in a moment." = "كتالوج الريلّي ما زال يتزامن. افتح الريلّي على Mac، وتأكد من تسجيل الدخول إلى iCloud، ثم حاول مرة أخرى.";
"Terms of Use" = "شروط الاستخدام";
"Privacy Policy" = "سياسة الخصوصية";
"Contact Support" = "اتصل بالدعم";
"Write a Review" = "اكتب مراجعة";
"Notes & Issues" = "ملاحظات ومشكلات";
"Qwen3-1.7B is a compact and efficient model from the Qwen3 family, suitable for on-device usage with strong general capabilities." = "Qwen3-1.7B نموذج مدمج وفعال من عائلة Qwen3، مناسب للاستخدام على الجهاز بقدرات عامة قوية.";
"Gemma 3n E2B is a lightweight instruction-tuned model from Google's Gemma family, optimized for efficient on-device conversations." = "Gemma 3n E2B نموذج خفيف مضبوط على التعليمات من عائلة Gemma من Google، محسّن لمحادثات محلية فعالة.";
"Gemma 3n E2B is an instruction-tuned variant of Google's Gemma family built for efficient reasoning on low-resource devices.\nAvailable in GGUF quants (Q3_K_M, Q4_K_M, Q6_K) and an MLX 4-bit build for Apple Silicon.\n" = "Gemma 3n E2B هو إصدار موجه للتعليمات من عائلة Gemma، بُني للاستدلال بكفاءة على الأجهزة محدودة الموارد.\nمتوفر بتكميمات GGUF (Q3_K_M وQ4_K_M وQ6_K) وبناء MLX 4 بت لأجهزة Apple Silicon.\n";
"Phi-4 Mini Reasoning is a lightweight model from the Phi-4 family, tuned for strong reasoning and efficiency across tasks." = "Phi-4 Mini Reasoning نموذج خفيف من عائلة Phi-4، مضبوط لقوة الاستدلال والكفاءة عبر المهام.";
"Phi-4 Mini Reasoning — a compact model in Microsoft’s Phi-4 line designed for logical reasoning, problem solving, and instruction-following. \nDistributed in efficient GGUF quants (Q3_K_L, Q4_K_M, Q6_K) and an MLX 4-bit variant for Apple Silicon devices.\n" = "Phi-4 Mini Reasoning — نموذج مدمج من خط Phi-4 من Microsoft، مصمم للاستدلال المنطقي وحل المشكلات واتباع التعليمات.\nموزع بتكميمات GGUF فعالة (Q3_K_L وQ4_K_M وQ6_K) وبنسخة MLX 4 بت لأجهزة Apple Silicon.\n";
"Runtime Safety" = "أمان وقت التشغيل";
"Bypass RAM safety check (may cause crashes)" = "تخطي فحص أمان الذاكرة (قد يسبب أعطال)";
"Estimate for" = "تقدير لـ";
"Off-grid Mode" = "وضع خارج الشبكة";
"Delete All Chats" = "حذف كل الدردشات";
"Reset App Data" = "إعادة تعيين بيانات التطبيق";
"Max Chunks" = "القطع القصوى";
"Delete Embedding Model" = "حذف نموذج التضمين";
"Override the app language. Defaults to the device language on first launch." = "تجاوز لغة التطبيق. بشكل افتراضي تُستخدم لغة الجهاز عند أول تشغيل.";
"Swap between the new stacked chat panel and the classic tab bar layout." = "التبديل بين لوحة الدردشة المكدسة الجديدة وتخطيط شريط التبويبات الكلاسيكي.";
"Available Quantizations" = "الكَمّيات المتاحة";
"Sort quantizations" = "فرز الكميات";
"Quant" = "كمّ";
"Size ↑" = "الحجم ↑";
"Size ↓" = "الحجم ↓";
"Model Library" = "مكتبة النماذج";
"Type to filter models…" = "اكتب لتصفية النماذج…";
"No models match your search." = "لا توجد نماذج تطابق بحثك.";
"Browse Explore tab" = "افتح علامة تبويب الاستكشاف";
"Manually choose parameters" = "اختر المعلمات يدويًا";
"The base URL looks invalid. Please include the host (e.g. http://127.0.0.1:1234)." = "عنوان URL الأساسي غير صالح. يرجى تضمين المضيف (مثلاً http://127.0.0.1:1234).";
"Could not build the remote endpoint URL." = "تعذر إنشاء عنوان URL لنقطة النهاية البعيدة.";
"The server returned an unexpected response." = "أعاد الخادم استجابة غير متوقعة.";
"Server responded with status code %d." = "استجاب الخادم برمز حالة %d.";
"Server responded with status code %d: %@" = "استجاب الخادم برمز حالة %1$d: %2$@";
"Failed to decode server response." = "فشل في فك تشفير استجابة الخادم.";

"Model doesn't support GPU offload" = "النموذج لا يدعم التفريغ إلى GPU";
"Loading model…" = "جارٍ تحميل النموذج…";
"Select a model to load" = "اختر نموذجًا لتحميله";
"Please wait" = "يرجى الانتظار";
"Models Library" = "مكتبة النماذج";
"Sort" = "فرز";
"Recency" = "الأحدث";
"Size" = "الحجم";
"Name" = "الاسم";
"Load Failed" = "فشل التحميل";
"Don't show again" = "لا تظهر مرة أخرى";

"Explore" = "استكشف";
"Search datasets" = "ابحث عن مجموعات البيانات";
"Download" = "تنزيل";
"Offline" = "غير متصل";
"Tap to load" = "انقر للتحميل";
"%d models" = "%d نماذج";
"Updated %@" = "محدَّث منذ %@";
"No models fetched yet" = "لم يتم جلب نماذج بعد";
"Auth" = "المصادقة";
"Local Network" = "الشبكة المحلية";
"Direct" = "مباشر";
"LAN" = "LAN";
"LAN · %@" = "LAN · %@";
"Backend" = "الخادم الخلفي";
"Base URL" = "عنوان URL الأساسي";
"Chat Path" = "مسار الدردشة";
"Models Path" = "مسار النماذج";
"Endpoint Type" = "نوع نقطة النهاية";
"Endpoints" = "نقاط النهاية";
"Authentication" = "المصادقة";
"Model Identifiers" = "معرفات النماذج";
"Name" = "الاسم";
"Host device ID" = "معرّف جهاز المضيف";
"Host Device ID" = "معرّف جهاز المضيف";
"CloudKit container identifier" = "معرّف حاوية CloudKit";
"Field requirements will depend on your specific backend deployment." = "متطلبات الحقول تعتمد على نشر الخادم الخلفي لديك.";
"Uses Noema Relay configuration" = "يستخدم تهيئة Noema Relay";
"Chat: %@\nModels: %@" = "الدردشة: %@\nالنماذج: %@";
"Download Dataset" = "تنزيل مجموعة البيانات";
"No files listed for this dataset." = "لا توجد ملفات مدرجة لمجموعة البيانات هذه.";
"This dataset's files are not currently supported for document retrieval." = "ملفات مجموعة البيانات هذه غير مدعومة حاليًا لاسترجاع المستندات.";
"Supported formats: %@" = "الصيغ المدعومة: %@";
"Try another dataset if these formats aren't available." = "جرّب مجموعة بيانات أخرى إذا لم تكن هذه الصيغ متاحة.";
"Found unsupported: %@ …" = "تم العثور على صيغ غير مدعومة: %@ …";
"This textbook appears to be available only as a web page. Noema can't import it as a dataset." = "يبدو أن هذا الكتاب الدراسي متاح فقط كصفحة ويب. لا يمكن لـ Noema استيراده كمجموعة بيانات.";
"Download complete" = "اكتمل التنزيل";
"Downloading…" = "جارٍ التنزيل…";
"No compatible files found for retrieval. Supported formats: %@" = "لم يتم العثور على ملفات متوافقة للاسترجاع. الصيغ المدعومة: %@";
"No internet connection." = "لا يوجد اتصال بالإنترنت.";
"Request timed out. Please try again." = "انتهت مهلة الطلب. يرجى المحاولة مرة أخرى.";
"Connection was lost. Please try again." = "انقطع الاتصال. يرجى المحاولة مرة أخرى.";
"Unexpected error: %@" = "خطأ غير متوقع: %@";

"Downloaded" = "تم التنزيل";
"Compressed Text" = "نص مضغوط";
"Small" = "صغير";
"Medium" = "متوسط";
"Large" = "كبير";
"Very Large" = "كبير جدًا";
"Extreme" = "هائل";
"Under 10 MB" = "أقل من 10 ميجابايت";
"10–50 MB" = "10–50 ميجابايت";
"50–200 MB" = "50–200 ميجابايت";
"200–500 MB" = "200–500 ميجابايت";
"Over 500 MB" = "أكثر من 500 ميجابايت";
"Estimated Embedding Time" = "الوقت التقديري للدمج";
"Peak RAM Usage" = "أقصى استخدام للذاكرة";
"Dataset Size" = "حجم مجموعة البيانات";
"Performance Note" = "ملاحظة الأداء";
"Recommendation" = "توصية";
"Remember:" = "تذكير:";
"• Close other applications to free up RAM" = "• أغلق التطبيقات الأخرى لتحرير الذاكرة";
"• Embedding happens locally on your device" = "• تتم عملية الدمج محليًا على جهازك";
"• Larger datasets take exponentially more time" = "• المجموعات الأكبر تستغرق وقتًا أطول بشكل أُسِّي";
"• You can pause and resume downloads if needed" = "• يمكنك إيقاف التنزيلات مؤقتًا واستئنافها عند الحاجة";
"Dataset Requirements" = "متطلبات مجموعة البيانات";
"Got it" = "حسنًا";
"Check Requirements" = "تحقق من المتطلبات";
"< 1 minute" = "أقل من دقيقة واحدة";
"%d minutes" = "%d دقيقة";
"This dataset should embed quickly with minimal resource usage. Perfect for testing and quick experiments." = "يجب أن يتم دمج هذا النموذج بسرعة مع استخدام موارد ضئيل. مثالي للاختبارات والتجارب السريعة.";
"This dataset is a reasonable size for most systems. Embedding should complete in a few minutes." = "هذا النموذج بحجم مناسب لمعظم الأنظمة. يجب أن يكتمل الدمج في غضون بضع دقائق.";
"This is a substantial dataset. Ensure you have adequate RAM and expect embedding to take 10–30 minutes." = "هذه مجموعة بيانات كبيرة. تأكد من توفر ذاكرة كافية وتوقع أن يستغرق الدمج 10–30 دقيقة.";
"This is a very large dataset. Embedding may take 30–60 minutes and requires significant RAM." = "هذه مجموعة بيانات كبيرة جدًا. قد يستغرق الدمج 30–60 دقيقة ويتطلب الكثير من الذاكرة.";
"This is an extremely large dataset. Consider splitting it into smaller parts for better performance." = "هذه مجموعة بيانات ضخمة جدًا. فكر في تقسيمها إلى أجزاء أصغر للحصول على أداء أفضل.";
"Go ahead and download! This size works well on all systems." = "تابع التنزيل! هذا الحجم يعمل جيدًا على جميع الأنظمة.";
"Recommended for most users. Make sure you have at least 4GB of free RAM." = "موصى به لمعظم المستخدمين. تأكد من توفر 4 جيجابايت من الذاكرة على الأقل.";
"Recommended only if you have 8GB+ RAM available. Close other applications before embedding." = "موصى به فقط إذا كان لديك أكثر من 8 جيجابايت من الذاكرة المتاحة. أغلق التطبيقات الأخرى قبل الدمج.";
"Recommended only for systems with 16GB+ RAM. Consider processing during off-hours." = "موصى به فقط للأنظمة التي تحتوي على 16 جيجابايت أو أكثر من الذاكرة. فكر في التشغيل خارج أوقات العمل.";
"Not recommended for typical systems. Consider finding a smaller version or subset of this dataset." = "غير موصى به للأنظمة العادية. فكر في العثور على نسخة أصغر أو جزء من هذه البيانات.";
"Sample dataset" = "مجموعة بيانات نموذجية";
"Ready" = "جاهز";
"Open" = "فتح";

/* Noema Relay – pairing & dataset helpers */
"Model file missing (.gguf)" = "ملف النموذج مفقود (.gguf)";
"Model path missing" = "مسار النموذج مفقود";
"Imported Dataset" = "مجموعة بيانات مستوردة";
"Dataset name" = "اسم مجموعة البيانات";
"Keep this device near the Mac that's running Noema Relay to import its settings." = "احتفظ بهذا الجهاز بالقرب من جهاز الـ Mac الذي يعمل عليه Noema Relay لاستيراد إعداداته.";
"Scanning for your Mac relay…" = "يتم البحث عن ترحيل الـ Mac الخاص بك…";
"Ready to scan nearby relays" = "جاهز لفحص أجهزة الترحيل القريبة";
"Bluetooth access is required to pair with the Mac relay." = "يلزم الوصول إلى البلوتوث لإقران الجهاز بترحيل الـ Mac.";
"Stop Scanning" = "إيقاف الفحص";
"Start Scan" = "بدء الفحص";
"Connection verified. Relay details imported from this Mac." = "تم التحقق من الاتصال. تم استيراد تفاصيل الترحيل من هذا الـ Mac.";
"Signal strength unavailable" = "قوة الإشارة غير متاحة";
"Very close" = "قريب جدًا";
"Nearby" = "بالقرب";
"Within one room" = "في نفس الغرفة";
"Move closer for a stronger signal" = "اقترب للحصول على إشارة أقوى.";
"This Mac" = "هذا الـ Mac";

/* Accessibility announcements */
"Model loaded." = "تم تحميل النموذج.";
"Prompt submitted." = "تم إرسال الموجه.";
"Generating response…" = "جارٍ توليد الرد…";
"Response generated." = "تم توليد الرد.";

/* Tabs & accessibility labels */
"Stored" = "مخزن";
"Web Search" = "بحث الويب";
"Open Stored" = "فتح مخزن";
"Message input" = "إدخال الرسالة";
"What is Web Search button?" = "ما هو زر بحث الويب؟";

/* Mac chat quick-load menu */
"Open Model Library" = "فتح مكتبة النماذج";
"Favorites" = "المفضلة";
"Recent" = "الأخيرة";
