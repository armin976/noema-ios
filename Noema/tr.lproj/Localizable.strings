/* Auto-generated localization file. */
"%@" = "%@";
"%@ %" = "%1$@ %2$";
"%@ %@" = "%1$@ %2$@";
"%@ models" = "%@ modelleri";
"%@ of %@ budget" = "%1$@ / %2$@ bütçe";
"%@ tokens" = "%@ jetonları";
"%@ – %@" = "%1$@ – %2$@";
"%@ • %@" = "%1$@ • %2$@";
"%@%" = "%1$@%2$";
"%@% · %@" = "%1$@%2$ · %3$@";
"%@." = "%@.";
"%@:" = "%@:";
"(+ mmproj %@%)" = "(+ mmproj %1$@%2$)";
"... and %@ more" = "... ve %@ daha";
"320 MB • One-time download" = "320 MB • Tek seferlik indirme";
"320 MB • One‑time download used for local dataset search" = "320 MB • Yerel veri kümesi araması için kullanılan tek seferlik indirme";
"A larger context keeps more conversation history, but also uses more memory. Adjust it here." = "Daha geniş bir bağlam daha fazla konuşma geçmişini saklar ancak aynı zamanda daha fazla bellek kullanır. Buradan ayarlayın.";
"Active" = "Aktif";
"Active Model" = "Aktif Model";
"Active connection via %@" = "%@ aracılığıyla etkin bağlantı";
"Active experts per token: %@ of %@" = "Token başına aktif uzmanlar: %1$@ / %2$@";
"Add a remote backend to configure remote startup fallbacks." = "Uzaktan başlatma yedeklerini yapılandırmak için uzak bir arka uç ekleyin.";
"Add one or two datasets (like open textbooks) to keep responses accurate and help the AI cite sources." = "Yanıtların doğru olmasını sağlamak ve yapay zekanın kaynaklardan alıntı yapmasına yardımcı olmak için bir veya iki veri kümesi (açık ders kitapları gibi) ekleyin.";
"Add remote endpoint" = "Uzak uç nokta ekle";
"Adjust appearance, privacy options, and network preferences here." = "Görünümü, gizlilik seçeneklerini ve ağ tercihlerini buradan ayarlayın.";
"Advanced" = "Gelişmiş";
"Advanced Controls" = "Gelişmiş Kontroller";
"Allows models to use a privacy-preserving web search API when you tap the globe in chat. Default is ON. In Offline Only mode, the button is disabled." = "Sohbette dünyaya dokunduğunuzda modellerin gizliliği koruyan bir web arama API'si kullanmasına izin verir. Varsayılan AÇIK'tır. Yalnızca Çevrimdışı modunda düğme devre dışı bırakılır.";
"Analyzing context..." = "Bağlam analiz ediliyor...";
"App Memory Usage (estimated)" = "Uygulama Belleği Kullanımı (tahmini)";
"App memory usage budget: %@ (conservative)" = "Uygulama belleği kullanım bütçesi: %@ (ihtiyatlı)";
"Approx. Tokens" = "Yaklaşık. Jetonlar";
"Arm web search when you truly need outside info. It has a small daily limit and most chats don’t require it." = "Gerçekten dışarıdan bilgiye ihtiyaç duyduğunuzda web aramasını etkinleştirin. Küçük bir günlük limiti vardır ve çoğu sohbette buna gerek yoktur.";
"Ask Noema anything" = "Noema'ya bir şey sor";
"Ask…" = "Sorunuz…";
"Attach Photos" = "Fotoğraf Ekle";
"Backend not found" = "Arka uç bulunamadı";
"Benchmark running…" = "Karşılaştırma çalışıyor…";
"Benchmarking is not available for this model format." = "Bu model formatı için karşılaştırma mevcut değildir.";
"Blocks all network traffic, model downloads, and cloud connections so everything stays on‑device." = "Tüm ağ trafiğini, model indirmelerini ve bulut bağlantılarını engelleyerek her şeyin cihazda kalmasını sağlar.";
"Bluetooth Pairing" = "Bluetooth Eşleştirme";
"Browse community models and curated datasets to expand what Noema can do." = "Noema'nın yapabileceklerini genişletmek için topluluk modellerine ve seçilmiş veri kümelerine göz atın.";
"Browse curated datasets for retrieval" = "Geri almak için seçilmiş veri kümelerine göz atın";
"CFBundleShortVersionString1.0" = "CFBundleShortVersionString1.0";
"Cancel" = "İptal etmek";
"Cancel Benchmark" = "Karşılaştırmayı İptal Et";
"Discover Intelligence" = "Zekayı keşfedin";
"Catalog" = "Katalog";
"Chat" = "Sohbet";
"Chat privately with your local models, sync datasets, and manage the relay server in one place." = "Yerel modellerinizle özel olarak sohbet edin, veri kümelerini senkronize edin ve geçiş sunucusunu tek bir yerden yönetin.";
"Chats" = "Sohbetler";
"Checking…" = "Kontrol ediliyor…";
"Citation %@" = "Alıntı %@";
"Cloud Relay Container" = "Bulut Aktarma Kabı";
"Cloud Relay via CloudKit (auto-discovery and Bluetooth pairing)" = "CloudKit aracılığıyla Cloud Relay (otomatik keşif ve Bluetooth eşleştirme)";
"CloudKit" = "Bulut Kiti";
"CloudKit bridge active. Local replies are generated on this Mac." = "CloudKit köprüsü etkin. Yerel yanıtlar bu Mac'te oluşturuluyor.";
"Compiling Metal kernels for GGUF models can take up to a minute on first load." = "GGUF modelleri için Metal çekirdeklerin derlenmesi ilk yüklemede bir dakika kadar sürebilir.";
"Complete the streaming response in the active chat before sending again." = "Tekrar göndermeden önce aktif sohbetteki akış yanıtını tamamlayın.";
"Confirm and Start Embedding" = "Onaylayın ve Yerleştirmeye Başlayın";
"Connected" = "Bağlı";
"Connection Modes" = "Bağlantı Modları";
"Connection Status: %@" = "Bağlantı Durumu: %@";
"Container" = "Konteyner";
"Context Length" = "Bağlam Uzunluğu";
"Context Length: 4096 tokens" = "Bağlam Uzunluğu: 4096 jeton";
"Context length is under 5000 tokens. With images and multi-sequence decoding (n_seq_max=16), per-sequence memory can be too small, leading to a crash. Increase context to at least 8192 in Model Settings." = "Bağlam uzunluğu 5000 jetonun altında. Görüntüler ve çoklu dizi kod çözme (n_seq_max=16) ile dizi başına bellek çok küçük olabilir ve bu da çökmeye yol açabilir. Model Ayarlarında bağlamı en az 8192'ye yükseltin.";
"Controls how many high‑scoring passages (chunks) can be injected into the prompt. Higher values increase recall but consume more context window and can slow responses. Typical range 3–6." = "İsteme kaç tane yüksek puanlı pasajın (parça) eklenebileceğini kontrol eder. Daha yüksek değerler hatırlamayı artırır ancak daha fazla bağlam penceresi tüketir ve yanıtları yavaşlatabilir. Tipik aralık 3–6.";
"Couldn't load the recommended model." = "Önerilen model yüklenemedi.";
"Couldn’t load the recommended model right now." = "Önerilen model şu anda yüklenemedi.";
"Creativity: %@. Low values focus responses; high values add variety." = "Yaratıcılık: %@. Düşük değerlere odaklanma tepkileri; yüksek değerler çeşitlilik katar.";
"Dark" = "Karanlık";
"Dataset" = "Veri kümesi";
"Dataset indexing in progress..." = "Veri kümesi indeksleme işlemi devam ediyor...";
"Dataset ready to use" = "Veri kümesi kullanıma hazır";
"Datasets" = "Veri kümeleri";
"Datasets enrich the model with focused knowledge. Toggle one on to use it in chat." = "Veri kümeleri, modeli odaklanmış bilgilerle zenginleştirir. Sohbette kullanmak için birini açın.";
"Default selection (~%@) balances RAM usage against model quality." = "Varsayılan seçim (~%@), RAM kullanımını model kalitesine göre dengeler.";
"Delete" = "Silmek";
"Delete Dataset" = "Veri Kümesini Sil";
"Deletes all chats, downloaded models, and datasets, and restores settings to defaults. The embedding model stays installed." = "Tüm sohbetleri, indirilen modelleri ve veri kümelerini siler ve ayarları varsayılanlara geri yükler. Katıştırma modeli yüklü kalır.";
"Device" = "Cihaz";
"Digest:" = "Özet:";
"Done" = "Tamamlamak";
"Done!" = "Tamamlamak!";
"Download Now" = "Şimdi İndir";
"Download a model from Explore or add a remote endpoint to get started." = "Başlamak için Keşfet'ten bir model indirin veya uzak bir uç nokta ekleyin.";
"Download a small embedding model so Noema can index and search your datasets" = "Noema'nın veri kümelerinizi dizine ekleyebilmesi ve arayabilmesi için küçük bir yerleştirme modeli indirin";
"Downloaded datasets need on-device embedding. Give it a few minutes after download finishes." = "İndirilen veri kümelerinin cihaza yerleştirilmesi gerekir. İndirme bittikten sonra birkaç dakika verin.";
"Downloaded models and datasets live here so you can manage them offline." = "İndirilen modeller ve veri kümeleri burada yayınlanır, böylece bunları çevrimdışı olarak yönetebilirsiniz.";
"Downloading…" = "İndiriliyor…";
"Draft tokens: %@" = "Taslak jetonları: %@";
"Draft window: %@" = "Taslak penceresi: %@";
"EPUB viewing not supported on this platform" = "EPUB görüntüleme bu platformda desteklenmiyor";
"Embedding" = "Gömme";
"Embedding Model Ready" = "Gömme Modeli Hazır";
"Embedding is resource intensive. For best performance, plug in your phone. Do you want to proceed on battery?" = "Gömme kaynak yoğundur. En iyi performans için telefonunuzu takın. Pille devam etmek istiyor musunuz?";
"Enabling Bluetooth…" = "Bluetooth etkinleştiriliyor…";
"Enhance with Datasets" = "Veri Kümeleri ile Geliştirin";
"Error" = "Hata";
"Estimated working set: %@ · Budget: %@" = "Tahmini çalışma grubu: %1$@ · Bütçe: %2$@";
"Experts Per Token" = "Token Başına Uzmanlar";
"Explore Datasets" = "Veri Kümelerini Keşfedin";
"Expose any downloaded models or connected remote endpoints from the Stored tab to your paired devices. Select which one should answer conversations when the relay is running." = "İndirilen modelleri veya bağlı uzak uç noktaları Saklanan sekmesinden eşleştirilmiş cihazlarınıza gösterin. Aktarıcı çalışırken konuşmalara hangisinin yanıt vereceğini seçin.";
"Expose to iOS" = "iOS'a maruz kalma";
"Explore the latest open-source models optimized for your Mac." = "Mac'iniz için optimize edilmiş en yeni açık kaynaklı modelleri keşfedin.";
"Failed to load README" = "README yüklenemedi";
"Failed: %@" = "Başarısız: %@";
"Fastest option on this device: SLM (Leap) models." = "Bu cihazdaki en hızlı seçenek: SLM (Leap) modelleri.";
"Field requirements will depend on your specific backend deployment." = "Alan gereksinimleri, özel arka uç dağıtımınıza bağlı olacaktır.";
"Files" = "Dosyalar";
"First, enable fast dataset search" = "İlk olarak hızlı veri kümesi aramasını etkinleştirin";
"First-time GGUF load takes longer" = "İlk kez GGUF yüklemesi daha uzun sürüyor";
"First-time download from HuggingFace" = "HuggingFace'ten ilk kez indirme";
"First‑time setup: download the Qwen‑1.7B model and embeddings.\nWi‑Fi recommended." = "İlk kurulum: Qwen‑1.7B modelini ve eklemelerini indirin.\nWi-Fi önerilir.";
"For best performance, please plug in your phone until this completes." = "En iyi performansı elde etmek için lütfen bu işlem tamamlanana kadar telefonunuzu fişe takın.";
"Force Local Network" = "Yerel Ağı Zorla";
"Forces chat traffic through the last LAN host even if Wi‑Fi names don't match yet." = "Wi‑Fi adları henüz eşleşmese bile sohbet trafiğinin son LAN ana bilgisayarı üzerinden geçmesini sağlar.";
"Formatted view unavailable" = "Biçimlendirilmiş görünüm kullanılamıyor";
"Found unsupported: %@ …" = "Desteklenmeyen bulundu: %@ …";
"Frequency penalty: %@" = "Frekans cezası: %@";
"GGUF models are the most compatible option. Use the format switch to explore the other builds when you need them." = "GGUF modelleri en uyumlu seçenektir. İhtiyacınız olduğunda diğer yapıları keşfetmek için format anahtarını kullanın.";
"GGUF works everywhere. MLX targets Apple Silicon speed. SLM focuses on responsiveness on any device." = "GGUF her yerde çalışır. MLX, Apple Silicon hızını hedefliyor. SLM, herhangi bir cihazdaki yanıt hızına odaklanır.";
"GPU Offload Layers" = "GPU Boşaltma Katmanları";
"GPU off-load is not supported for this model." = "Bu model için GPU yükünün boşaltılması desteklenmez.";
"Get Started" = "Başlayın";
"Help shape Noema by trying upcoming features and sharing feedback." = "Gelecek özellikleri deneyerek ve geri bildirimleri paylaşarak Noema'nın şekillenmesine yardımcı olun.";
"High context lengths use more memory" = "Yüksek bağlam uzunlukları daha fazla bellek kullanır";
"High-quality embedding model for local RAG" = "Yerel RAG için yüksek kaliteli yerleştirme modeli";
"Host ID: %@" = "Ana Bilgisayar Kimliği: %@";
"How it works" = "Nasıl çalışır?";
"I'm New to Local LLMs, Guide Me" = "Yerel Yüksek Lisans Programlarında Yeniyim, Bana Rehberlik Edin";
"If enabled, the app will attempt to load models even when they likely exceed your device's memory budget. This can cause the app to terminate." = "Etkinleştirilirse uygulama, muhtemelen cihazınızın bellek bütçesini aşsa bile modelleri yüklemeye çalışır. Bu, uygulamanın sonlandırılmasına neden olabilir.";
"Import Dataset" = "Veri Kümesini İçe Aktar";
"Import PDFs, EPUBs, or text files to build local knowledge bases." = "Yerel bilgi tabanları oluşturmak için PDF'leri, EPUB'ları veya metin dosyalarını içe aktarın.";
"Import your own PDFs, EPUBs, or TXT files and keep them local." = "Kendi PDF'lerinizi, EPUB'larınızı veya TXT dosyalarınızı içe aktarın ve bunları yerel tutun.";
"Importing & Scanning..." = "İçe Aktarılıyor ve Taranıyor...";
"In progress..." = "Devam etmekte...";
"Indexing %@" = "Dizine ekleniyor %@";
"Indexing dataset…" = "Veri kümesi dizine ekleniyor…";
"Indexing: %@% · %@" = "Dizin oluşturma: %1$@%2$ · %3$@";
"Install a local model to make it available at launch." = "Lansman sırasında kullanılabilir hale getirmek için yerel bir model yükleyin.";
"Install another model with the same architecture and equal or smaller size to enable speculative decoding." = "Spekülatif kod çözmeyi etkinleştirmek için aynı mimariye ve eşit veya daha küçük boyuta sahip başka bir model kurun.";
"K Cache Quant" = "K Önbellek Miktarı";
"Keep this iPhone or iPad within a few feet of the Mac that is advertising Noema Relay. We'll pull the relay details automatically once connected." = "Bu iPhone veya iPad'i Noema Relay'in reklamını yapan Mac'in birkaç metre yakınında tutun. Bağlandıktan sonra röle ayrıntılarını otomatik olarak alacağız.";
"LAN URL: %@" = "LAN URL'si: %@";
"Large Model Downloads" = "Büyük Model İndirmeleri";
"Last Sync" = "Son Senkronizasyon";
"Last refreshed %@" = "Son yenilenme tarihi: %@";
"Latest benchmark" = "En son karşılaştırma";
"Latest integrated release: %@" = "En son entegre sürüm: %@";
"Library" = "Kütüphane";
"Light" = "Işık";
"Llama.cpp" = "Çağrı.cpp";
"Load" = "Yük";
"Load a local model before chatting. You can download one from the Explore tab or load a model you've already installed." = "Sohbet etmeden önce yerel bir model yükleyin. Keşfet sekmesinden bir tane indirebilir veya önceden yüklediğiniz bir modeli yükleyebilirsiniz.";
"Loading recommendation…" = "Öneri yükleniyor…";
"Loading…" = "Yükleniyor…";
"Local Network HTTP server for LAN clients (OpenAI-compatible)" = "LAN istemcileri için Yerel Ağ HTTP sunucusu (OpenAI uyumlu)";
"Low = focused. High = varied." = "Düşük = odaklı. Yüksek = çeşitli.";
"Lower = more results (more noise). Higher = stricter matches." = "Daha düşük = daha fazla sonuç (daha fazla gürültü). Daha yüksek = daha katı eşleşmeler.";
"MLX currently manages expert routing automatically; manual selection is not supported." = "MLX şu anda uzman yönlendirmeyi otomatik olarak yönetmektedir; manuel seçim desteklenmez.";
"Many models are several gigabytes in size and require a stable connection and sufficient storage. Downloads can fail or take a long time on slow networks or devices with limited space." = "Çoğu modelin boyutu birkaç gigabayttır ve istikrarlı bir bağlantı ve yeterli depolama alanı gerektirir. Yavaş ağlarda veya sınırlı alana sahip cihazlarda indirme işlemleri başarısız olabilir veya uzun sürebilir.";
"Max Chunks: %@" = "Maksimum Parça: %@";
"Max recommended context on this device: ~%@ tokens" = "Bu cihazda önerilen maksimum içerik: ~%@ jeton";
"Measure real-world generation speed for this configuration. A short scripted prompt will run locally and report timing and memory usage." = "Bu yapılandırma için gerçek dünyadaki üretim hızını ölçün. Kısa bir komut dosyası istemi yerel olarak çalışacak ve zamanlamayı ve bellek kullanımını bildirecektir.";
"Min-p" = "Min-p";
"Min-p: %@" = "Min-p: %@";
"Minimum cosine similarity a passage must have to be considered relevant. Lower = more passages (higher recall, more noise). Higher = fewer, more precise passages. Try 0.2–0.4 for broad questions; 0.5–0.7 for precise lookups." = "Minimum kosinüs benzerliği bir pasajın ilgili olduğu düşünülmelidir. Daha düşük = daha fazla pasaj (daha yüksek hatırlama, daha fazla gürültü). Daha yüksek = daha az, daha kesin pasajlar. Geniş kapsamlı sorular için 0,2–0,4'ü deneyin; Hassas aramalar için 0,5–0,7.";
"MoE layers: %@ / %@" = "MoE katmanları: %1$@ / %2$@";
"Model Detection Limitations" = "Model Algılama Sınırlamaları";
"Model Formats" = "Model Formatları";
"Models" = "Modeller";
"Models shown here are exposed by the Mac relay. Manage sources in the Relay tab on macOS to share more models." = "Burada gösterilen modeller Mac rölesi tarafından açığa çıkarılmıştır. Daha fazla model paylaşmak için macOS'taki Aktarma sekmesindeki kaynakları yönetin.";
"Move your device closer to the Mac running the relay if it doesn't appear right away. Bluetooth discovery usually completes within a few seconds." = "Hemen görünmezse, aygıtınızı aktarmayı çalıştıran Mac'in yakınına taşıyın. Bluetooth keşfi genellikle birkaç saniye içinde tamamlanır.";
"Name your dataset" = "Veri kümenizi adlandırın";
"Nearby Relays" = "Yakındaki Röleler";
"Nearby iPhone and iPad devices discover your Mac relay instantly and sync pairing codes over the air." = "Yakındaki iPhone ve iPad aygıtları Mac aktarıcınızı anında keşfeder ve eşleştirme kodlarını kablosuz olarak senkronize eder.";
"Need a fresh thread? Tap the plus button for a brand-new conversation." = "Yeni bir konuya mı ihtiyacınız var? Yepyeni bir görüşme için artı düğmesine dokunun.";
"Nice! You already have the recommended GGUF starter model ready to use." = "Güzel! Önerilen GGUF başlangıç ​​modeline zaten kullanıma hazırsınız.";
"No compatible files found for retrieval. Supported: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV" = "Alınacak uyumlu dosya bulunamadı. Desteklenenler: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV";
"No connection responses recorded yet." = "Henüz hiçbir bağlantı yanıtı kaydedilmedi.";
"No datasets available yet. Import or download datasets to build your personal library." = "Henüz veri kümesi mevcut değil. Kişisel kitaplığınızı oluşturmak için veri kümelerini içe aktarın veya indirin.";
"No datasets found. Try different keywords." = "Hiçbir veri kümesi bulunamadı. Farklı anahtar kelimeler deneyin.";
"No datasets imported yet." = "Henüz içe aktarılan veri kümesi yok.";
"No datasets yet" = "Henüz veri kümesi yok";
"No files listed for this dataset." = "Bu veri kümesi için listelenmiş dosya yok.";
"No model >" = "Model yok >";
"No model loaded" = "Hiçbir model yüklenmedi";
"No models available. Add downloads or remote connections in Stored to configure the relay." = "Hiçbir model mevcut değil. Aktarıcıyı yapılandırmak için Stored'a indirmeleri veya uzak bağlantıları ekleyin.";
"No models cached yet. Open the backend to refresh its catalog." = "Henüz önbelleğe alınmış model yok. Kataloğunu yenilemek için arka ucu açın.";
"No models found for '%@'" = "'%@' için model bulunamadı";
"No models loaded right now. We'll spin one up when a request arrives." = "Şu anda yüklü model yok. Bir istek geldiğinde bir tanesini başlatacağız.";
"No models match your search." = "Aramanızla eşleşen model yok.";
"No models yet" = "Henüz model yok";
"No parameters" = "Parametre yok";
"No quant files available" = "Quant dosyası yok";
"No recent devices. We'll list clients the next time they talk to this relay." = "Yeni cihaz yok. Bu aktarıcıyla bir dahaki sefere konuştuklarında müşterileri listeleyeceğiz.";
"No remote endpoints configured yet." = "Henüz yapılandırılmış uzak uç nokta yok.";
"No remote endpoints configured." = "Hiçbir uzak uç nokta yapılandırılmadı.";
"No ≥Q3 quants are available for this model." = "Bu model için ≥Q3 niceliği mevcut değildir.";
"Noema" = "Kasım";
"Noema REST API — /api/v0/* for model catalog & operations" = "Noema REST API — model kataloğu ve işlemler için /api/v0/*";
"Noema Relay" = "Noema Rölesi";
"Noema Server" = "Noema Sunucusu";
"Noema attempts to gauge available memory to prevent models from exceeding device limits. These checks may occasionally miss risky situations and allow a model to crash your app, or they may be overly conservative and block a model that could have run fine." = "Noema, modellerin cihaz sınırlarını aşmasını önlemek için kullanılabilir belleği ölçmeye çalışır. Bu kontroller bazen riskli durumları gözden kaçırabilir ve bir modelin uygulamanızı çökertmesine neden olabilir veya aşırı ihtiyatlı davranıp düzgün çalışabilecek bir modeli engelleyebilir.";
"Noema could not find a projector in the repository. If the model advertises vision, ensure the mmproj file is present in the same folder as the weights." = "Noema depoda projektör bulamadı. Model vizyonu tanıtıyorsa mmproj dosyasının ağırlıklarla aynı klasörde bulunduğundan emin olun.";
"Noema has been reset. The embedding model remains installed." = "Noema sıfırlandı. Gömme modeli yüklü kalır.";
"Nomic Embed Text v1.5 (Q4_K_M)" = "Nomic Gömülü Metin v1.5 (Q4_K_M)";
"None" = "Hiçbiri";
"Not found" = "Bulunamadı";
"Not provided" = "Sağlanmadı";
"OK" = "TAMAM";
"Off-Grid" = "Şebeke Dışı";
"Off-grid mode blocks every network call so the app stays self-contained. Good luck exploring Noema!" = "Şebekeden bağımsız mod her ağ aramasını engeller, böylece uygulama kendi kendine yetebilir. Noema'yı keşfederken iyi şanslar!";
"Only one expert is available for this model; the active expert count is fixed." = "Bu model için yalnızca bir uzman mevcuttur; aktif uzman sayısı sabittir.";
"Open Stored to choose a model to run locally or connect to a remote endpoint." = "Yerel olarak çalıştırılacak veya uzak bir uç noktaya bağlanacak bir model seçmek için Saklanan'ı açın.";
"Open the sidebar to revisit any previous session without losing your spot." = "Yerinizi kaybetmeden önceki herhangi bir oturumu tekrar ziyaret etmek için kenar çubuğunu açın.";
"OpenAI-style API — /v1/chat/completions, /v1/completions, /v1/models" = "OpenAI tarzı API — /v1/chat/completions, /v1/completions, /v1/models";
"Optimizations in use" = "Kullanımdaki optimizasyonlar";
"PDF viewing not supported on this platform" = "PDF görüntüleme bu platformda desteklenmiyor";
"Pick a model and add a dataset" = "Bir model seçin ve veri kümesi ekleyin";
"Pick the SLM format when you want ultra-responsive models that run well anywhere." = "Her yerde iyi çalışan, ultra duyarlı modeller istiyorsanız SLM formatını seçin.";
"Pinned answer" = "Yanıt sabitlendi";
"Pinned answer unavailable" = "Sabitlenmiş yanıt kullanılamıyor";
"Preparation" = "Hazırlık";
"Preparing Embedding Model" = "Gömme Modelinin Hazırlanması";
"Preparing benchmark…" = "Benchmark hazırlanıyor…";
"Preparing…" = "Hazırlanıyor…";
"Presence penalty: %@" = "Varlık cezası: %@";
"Projector (mmproj)" = "Projektör (mmproj)";
"Projector downloaded automatically from Hugging Face. Keep this file alongside the weights so vision remains available." = "Projektör Hugging Face'ten otomatik olarak indirilir. Görüşün mevcut kalması için bu dosyayı ağırlıkların yanında tutun.";
"Quantize the runtime key cache to save memory. Experimental." = "Bellekten tasarruf etmek için çalışma zamanı anahtar önbelleğini nicelendirin. Deneysel.";
"Quantize the runtime value cache to save memory when Flash Attention is enabled. Experimental." = "Flash Attention etkinleştirildiğinde bellekten tasarruf etmek için çalışma zamanı değeri önbelleğini nicelendirin. Deneysel.";
"Qwen 3 1.7B GGUF (Q3_K_M) gives you a dependable starting point. Delete it anytime if you need space." = "Qwen 3 1.7B GGUF (Q3_K_M) size güvenilir bir başlangıç ​​noktası sunar. Boş alana ihtiyacınız olursa istediğiniz zaman silin.";
"RAG embeds normalized paragraphs from your PDFs and EPUBs. On each question, the most relevant chunks are retrieved and added to the prompt. Images are ignored." = "RAG, PDF'lerinizden ve EPUB'larınızdan normalleştirilmiş paragraflar ekler. Her soruda en alakalı parçalar alınır ve bilgi istemine eklenir. Resimler dikkate alınmaz.";
"RAM Safety Checks" = "RAM Güvenlik Kontrolleri";
"RAM information for this device will be added in a future update." = "Bu cihazın RAM bilgileri gelecekteki bir güncellemeye eklenecektir.";
"REST Endpoints" = "REST Uç Noktaları";
"Reachable at" = "Şu saatte ulaşılabilir:";
"Ready for Use" = "Kullanıma Hazır";
"Recent Chats" = "Son Sohbetler";
"Recommended" = "Tavsiye edilen";
"Recommended Starter Model" = "Önerilen Başlangıç ​​Modeli";
"Relay ID" = "Röle Kimliği";
"Relay Server Running" = "Aktarma Sunucusu Çalışıyor";
"Relay Sources" = "Röle Kaynakları";
"Remaining: %@" = "Kalan: %@";
"Remember:" = "Hatırlamak:";
"Remote Backends" = "Uzak Arka Uçlar";
"Remote endpoint is offline. This model can't be found at this time." = "Uzak uç nokta çevrimdışı. Bu model şu anda bulunamıyor.";
"Remote timeout: %@s" = "Uzaktan zaman aşımı: %@s";
"Repeat last N tokens: %@" = "Son N jetonu tekrarla: %@";
"Repetition penalty: %@" = "Tekrarlama cezası: %@";
"Request Parameters" = "İstek Parametreleri";
"Responses are generated by the macOS relay server. Configure the provider (LM Studio or Ollama) on the Mac app." = "Yanıtlar macOS geçiş sunucusu tarafından oluşturulur. Mac uygulamasında sağlayıcıyı (LM Studio veya Ollama) yapılandırın.";
"Result" = "Sonuç";
"Results" = "Sonuçlar";
"Save" = "Kaydetmek";
"Saving…" = "Kaydediliyor…";
"Score: %@" = "Puan: %@";
"SearXNG web search is available without limits. There's nothing to purchase—just enable the globe button in chat whenever you need online results." = "SearXNG web araması sınırsız olarak kullanılabilir. Satın alınacak hiçbir şey yok; çevrimiçi sonuçlara ihtiyaç duyduğunuzda sohbetteki dünya düğmesini etkinleştirmeniz yeterli.";
"SearXNG web search is enabled for this device." = "Bu cihaz için SearXNG web araması etkinleştirildi.";
"Search" = "Aramak";
"Search for any subject you're interested in." = "İlgilendiğiniz herhangi bir konuyu arayın.";
"Search requests are proxied through https://search.noemaai.com and are available without quotas." = "Arama istekleri https://search.noemaai.com aracılığıyla proxy olarak gerçekleştirilir ve kota olmadan kullanılabilir.";
"Seed" = "Tohum";
"Selecting more experts keeps additional expert weights resident in RAM and increases memory usage." = "Daha fazla uzmanın seçilmesi, ek uzman ağırlıklarının RAM'de kalmasını sağlar ve bellek kullanımını artırır.";
"Server Settings" = "Sunucu Ayarları";
"Share Logs" = "Günlükleri Paylaş";
"Sharing relay payload with nearby devices…" = "Aktarma yükü yakındaki cihazlarla paylaşılıyor…";
"Shows the last server response." = "Son sunucu yanıtını gösterir.";
"Signal" = "Sinyal";
"Similarity Threshold" = "Benzerlik Eşiği";
"Simple" = "Basit";
"Smooth loops and phrase echo by balancing repetition controls." = "Tekrarlama kontrollerini dengeleyerek düzgün döngüler ve cümle yankısı.";
"Smooth loops and repeated phrases by tuning repetition controls." = "Tekrarlama kontrollerini ayarlayarak düzgün döngüler ve tekrarlanan ifadeler.";
"Some models do not provide the system prompts needed for Noema to detect and configure them properly. These models may be unusable until they include appropriate metadata or support." = "Bazı modeller, Noema'nın bunları doğru şekilde algılaması ve yapılandırması için gereken sistem istemlerini sağlamaz. Bu modeller, uygun meta veriler veya destek sağlanana kadar kullanılamayabilir.";
"Source unavailable. Check storage or network settings." = "Kaynak kullanılamıyor. Depolama veya ağ ayarlarını kontrol edin.";
"Source: %@" = "Kaynak: %@";
"Specify identifiers for models that are not listed by the server. Leave blank to rely on the server's catalog." = "Sunucu tarafından listelenmeyen modeller için tanımlayıcıları belirtin. Sunucunun kataloğuna güvenmek için boş bırakın.";
"Specify your model identifiers, or reload your custom models later." = "Model tanımlayıcılarınızı belirtin veya özel modellerinizi daha sonra yeniden yükleyin.";
"Speed up with a smaller helper model." = "Daha küçük bir yardımcı modelle hızınızı artırın.";
"Start by installing one model. Then add a dataset (like an open textbook) so the AI can answer with grounded knowledge." = "Bir model kurarak başlayın. Ardından yapay zekanın temel bilgilerle yanıt verebilmesi için bir veri kümesi (açık bir ders kitabı gibi) ekleyin.";
"Start the relay to automatically share the latest payload with nearby devices." = "En son veriyi yakındaki cihazlarla otomatik olarak paylaşmak için aktarmayı başlatın.";
"Start with a reliable Qwen 3 1.7B build. It balances capability with small download size." = "Güvenilir bir Qwen 3 1.7B yapısıyla başlayın. Kapasiteyi küçük indirme boyutuyla dengeler.";
"Startup defaults now live in Settings → Startup. Favorite models here to keep them handy." = "Başlangıç ​​varsayılanları artık Ayarlar → Başlangıç ​​bölümünde mevcuttur. El altında tutmak için favori modelleri burada.";
"Status" = "Durum";
"Stay close to your Mac" = "Mac'inize yakın kalın";
"Stop Using Dataset" = "Veri Kümesini Kullanmayı Durdurun";
"Streaming" = "Akış";
"Streaming response…" = "Yanıt akışı…";
"Supported Endpoints" = "Desteklenen Uç Noktalar";
"Supported formats: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV" = "Desteklenen formatlar: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV";
"Swap between the new stacked chat panel and the classic tab bar layout." = "Yeni yığılmış sohbet paneli ile klasik sekme çubuğu düzeni arasında geçiş yapın.";
"Swipe left to remove the embedding model from this device." = "Gömme modelini bu cihazdan kaldırmak için sola kaydırın.";
"Switch the selector to MLX for Apple Silicon‑optimized builds that excel at speed." = "Hız konusunda üstün olan, Apple Silicon için optimize edilmiş yapılar için seçiciyi MLX'e değiştirin.";
"Switch to Raw to inspect the original response." = "Orijinal yanıtı incelemek için Raw'a geçin.";
"System" = "Sistem";
"Tap to load" = "Yüklemek için dokunun";
"Temperature" = "Sıcaklık";
"Testing" = "Test";
"The app memory usage budget is an estimate based on your device's total RAM and typical iOS memory management. The actual available memory may vary depending on system load, other running apps, and iOS memory pressure. Models that exceed this budget may cause the app to be terminated by iOS." = "Uygulama hafızası kullanım bütçesi, cihazınızın toplam RAM'ına ve tipik iOS hafıza yönetimine dayalı bir tahmindir. Gerçek kullanılabilir bellek, sistem yüküne, çalışan diğer uygulamalara ve iOS bellek basıncına bağlı olarak değişebilir. Bu bütçeyi aşan modeller uygulamanın iOS tarafından sonlandırılmasına neden olabilir.";
"The embedding model is installed. Delete it to free ~320 MB." = "Gömme modeli yüklenir. ~320 MB boşaltmak için silin.";
"The relay listens to the %@ container for new conversations and responds with your selected provider." = "Aktarıcı, yeni görüşmeler için %@ kapsayıcısını dinler ve seçtiğiniz sağlayıcıyla yanıt verir.";
"The tool returned data that can't be formatted. Switch to Raw to inspect the original response." = "Araç, biçimlendirilemeyen veriler döndürdü. Orijinal yanıtı incelemek için Raw'a geçin.";
"These options stay in simple mode for clarity. Let’s cover the essentials." = "Bu seçenekler netlik sağlamak için basit modda kalır. Temel konuları ele alalım.";
"Think of Noema as a simple way to run AI on your device. To get useful answers, you pair a local model with datasets (like open textbooks). We’ll guide you through the first setup." = "Noema'yı cihazınızda yapay zekayı çalıştırmanın basit bir yolu olarak düşünün. Yararlı yanıtlar almak için yerel bir modeli veri kümeleriyle (açık ders kitapları gibi) eşleştirirsiniz. İlk kurulumda size rehberlik edeceğiz.";
"This app bundles llama.cpp; we keep this in sync with upstream b‑releases." = "Bu uygulama llama.cpp'yi paketler; bunu yukarı akış b-sürümleriyle senkronize tutuyoruz.";
"This backend is unavailable. Remove it or pick another option." = "Bu arka uç kullanılamıyor. Kaldır veya başka bir seçenek seç.";
"This chat stays private—responses are generated on your device after you load a model." = "Bu sohbet gizli kalır; bir model yükledikten sonra yanıtlar cihazınızda oluşturulur.";
"This configuration exceeds the current RAM safety guard, so benchmarking is disabled." = "Bu yapılandırma mevcut RAM güvenlik korumasını aşıyor, bu nedenle kıyaslama devre dışı.";
"This dataset is taking a while to load, still working…" = "Bu veri kümesinin yüklenmesi biraz zaman alıyor ve hâlâ çalışıyor…";
"This dataset's files are not currently supported for document retrieval." = "Bu veri kümesinin dosyaları şu anda belge alımı için desteklenmiyor.";
"This device doesn't support GPU offload." = "Bu cihaz GPU aktarımını desteklemiyor.";
"This device doesn't support GPU offload; GGUF models will run on the CPU and generation speed will be significantly slower." = "Bu cihaz GPU aktarımını desteklemiyor; GGUF modelleri CPU üzerinde çalışacak ve üretim hızı önemli ölçüde yavaşlayacaktır.";
"This model doesn't support GPU offload and generation speed will be significantly slower. Consider switching to an MLX model." = "Bu model GPU boşaltmayı desteklemez ve üretim hızı önemli ölçüde daha yavaş olacaktır. Bir MLX modeline geçmeyi düşünün.";
"This model doesn't support GPU offload and generation speed will be significantly slower. Fastest option on this device: use an SLM (Leap) model." = "Bu model GPU boşaltmayı desteklemez ve üretim hızı önemli ölçüde daha yavaş olacaktır. Bu cihazdaki en hızlı seçenek: SLM (Sıçrama) modelini kullanın.";
"This model doesn't support GPU offload and may run slowly. Consider an MLX model." = "Bu model GPU aktarımını desteklemez ve yavaş çalışabilir. Bir MLX modelini düşünün.";
"This model doesn't support GPU offload and may run slowly. Fastest option: use an SLM model." = "Bu model GPU aktarımını desteklemez ve yavaş çalışabilir. En hızlı seçenek: bir SLM modeli kullanın.";
"This permanently removes every chat conversation. This action cannot be undone." = "Bu, her sohbet görüşmesini kalıcı olarak kaldırır. Bu eylem geri alınamaz.";
"This textbook appears to be available only as a web page. Noema can't import it as a dataset." = "Bu ders kitabının yalnızca bir web sayfası olarak mevcut olduğu görülmektedir. Noema bunu veri kümesi olarak içe aktaramaz.";
"Tool calling isn't perfect. Although Noema implements many methods of detecting and instructing models to use tools, not all LLMs will follow instructions and some might not call them correctly or at all. Tool calling heavily depends on model pre-training and will get better as time passes." = "Araç çağırma mükemmel değildir. Noema, modelleri tespit etmek ve araçları kullanmaları için talimat vermek için birçok yöntem uygulasa da, tüm LLM'ler talimatları takip etmeyecek ve bazıları bunları doğru şekilde veya hiç çağırmayabilir. Takım çağırma büyük ölçüde modelin ön eğitimine bağlıdır ve zaman geçtikçe daha iyi hale gelecektir.";
"Tools" = "Aletler";
"Top-k: %@" = "Üst-k: %@";
"Top-p" = "Üst-p";
"Top-p: %@" = "Üst sayfa: %@";
"Try again" = "Tekrar deneyin";
"Try another dataset if these formats aren't available." = "Bu formatlar mevcut değilse başka bir veri kümesi deneyin.";
"Try the Qwen 3 1.7B GGUF (Q3_K_M) build below. It's a good starting point and you can delete it anytime." = "Aşağıdaki Qwen 3 1.7B GGUF (Q3_K_M) yapısını deneyin. Bu iyi bir başlangıç ​​noktasıdır ve istediğiniz zaman silebilirsiniz.";
"Unable to load image" = "Resim yüklenemiyor";
"Unknown error" = "Bilinmeyen hata";
"Updates every second" = "Her saniye güncellenir";
"Use" = "Kullanmak";
"Use Dataset" = "Veri Kümesini Kullan";
"Use this switch to flip between finding models or datasets." = "Modelleri veya veri kümelerini bulma arasında geçiş yapmak için bu anahtarı kullanın.";
"Using %@" = "%@ kullanma";
"Using %@ of %@ budget" = "%1$@ / %2$@ bütçesi kullanılıyor";
"Using more than %@ significantly increases RAM usage." = "%@ değerinden fazlasını kullanmak RAM kullanımını önemli ölçüde artırır.";
"Using server catalog" = "Sunucu kataloğunu kullanma";
"V Cache Quant" = "V Önbellek Miktarı";
"Vendor recommendation: %@" = "Satıcı tavsiyesi: %@";
"Version" = "Sürüm";
"Version %@" = "Sürüm %@";
"Version 1.4" = "Sürüm 1.4";
"Vision models require a companion projector (.mmproj). Noema will fetch it automatically the next time you download this model." = "Vision modelleri bir yardımcı projektör (.mmproj) gerektirir. Noema, bu modeli bir sonraki indirişinizde otomatik olarak getirecektir.";
"Wait for the response in your other chat to finish before sending a new message." = "Yeni bir mesaj göndermeden önce diğer sohbetinizdeki yanıtın bitmesini bekleyin.";
"Waiting for tool response…" = "Araç yanıtı bekleniyor…";
"We'll extract text and prepare embeddings. You can also start later from the dataset details." = "Metni çıkaracağız ve yerleştirmeleri hazırlayacağız. Daha sonra veri kümesi ayrıntılarından da başlayabilirsiniz.";
"We'll route new conversations through %@ even if Wi‑Fi names differ. You can switch back by reloading the backend." = "Wi-Fi adları farklı olsa bile yeni konuşmaları %@ üzerinden yönlendireceğiz. Arka ucu yeniden yükleyerek geri dönebilirsiniz.";
"We'll try remote models in priority order for this long before moving to the next option." = "Bir sonraki seçeneğe geçmeden önce uzak modelleri öncelik sırasına göre deneyeceğiz.";
"We'll try this saved identifier even though it's not in the latest catalog." = "En son katalogda olmasa da bu kayıtlı tanımlayıcıyı deneyeceğiz.";
"Web Search Tool Calls" = "Web Arama Aracı Çağrıları";
"Web Search button" = "Web Arama düğmesi";
"Web search is included" = "Web araması dahildir";
"Weights" = "Ağırlıklar";
"Welcome to Noema" = "Noema'ya hoş geldiniz";
"Welcome to Noema for Mac" = "Mac için Noema'ya hoş geldiniz";
"What is Noema?" = "Noema nedir?";
"When connecting from another device, point the base URL to your computer (for example http://192.168.0.10:11434) and start Ollama with `OLLAMA_HOST=0.0.0.0` so it accepts remote clients." = "Başka bir cihazdan bağlanırken, temel URL'yi bilgisayarınıza yönlendirin (örneğin http://192.168.0.10:11434) ve Ollama'yı uzak istemcileri kabul etmesi için `OLLAMA_HOST=0.0.0.0` ile başlatın.";
"When enabled, pressing eject on iOS tells this Mac to unload the active relay model." = "Etkinleştirildiğinde, iOS'ta çıkar tuşuna basmak bu Mac'e etkin aktarma modelini kaldırmasını söyler.";
"When enabled, you will be asked to choose parameters every time a model loads." = "Etkinleştirildiğinde, model her yüklendiğinde parametreleri seçmeniz istenecektir.";
"Wi-Fi: %@" = "WiFi: %@";
"Working set estimate (%@): %@ @ %@ tokens" = "Çalışma kümesi tahmini (%1$@): %2$@ @ %3$@ belirteçleri";
"Write prompts, instructions, or notes here. Press return to add new lines." = "İstemleri, talimatları veya notları buraya yazın. Yeni satırlar eklemek için Return tuşuna basın.";
"You can keep chatting while indexing finishes" = "Dizine ekleme işlemi tamamlanırken sohbete devam edebilirsiniz";
"You can only favorite up to three models." = "En fazla üç modeli favorilerinize ekleyebilirsiniz.";
"You can restart this process in the dataset settings any time." = "Bu işlemi istediğiniz zaman veri kümesi ayarlarından yeniden başlatabilirsiniz.";
"You're in Off-Grid mode. The Explore tab is hidden and all network features are disabled. You can only use downloaded models and datasets." = "Şebeke Dışı moddasınız. Keşfet sekmesi gizlenir ve tüm ağ özellikleri devre dışı bırakılır. Yalnızca indirilen modelleri ve veri kümelerini kullanabilirsiniz.";
"Your Datasets" = "Veri Kümeleriniz";
"Your Models" = "Modelleriniz";
"Your private AI workspace" = "Özel yapay zeka çalışma alanınız";
"You’re ready to explore. Download models, add datasets, and start chatting." = "Keşfetmeye hazırsınız. Modelleri indirin, veri kümeleri ekleyin ve sohbete başlayın.";
"minutes" = "dakika";
"•" = "";
"• Close other applications to free up RAM" = "• RAM'de yer açmak için diğer uygulamaları kapatın";
"• Embedding happens locally on your device" = "• Yerleştirme cihazınızda yerel olarak gerçekleşir";
"• Larger datasets take exponentially more time" = "• Daha büyük veri kümeleri katlanarak daha fazla zaman alır";
"• You can pause and resume downloads if needed" = "• Gerekirse indirme işlemlerini duraklatabilir ve devam ettirebilirsiniz";
"…and %@ more parameter%@" = "…ve %1$@ daha fazla parametre%2$@";
"⚠️ " = "";
"General" = "Genel";

"Privacy" = "Gizlilik";

"About" = "Hakkında";

"About & Support" = "Hakkında ve Destek";

"Network" = "Ağ";

"Embedding Model" = "Gömme modeli";

"Retrieval" = "Getirme";

"Early Testers" = "Erken testçiler";

"Build Info" = "Derleme bilgisi";

"Settings" = "Ayarlar";

"Language" = "Dil";
"Startup" = "Başlangıç";
"Search models" = "Modelleri ara";
"SLM Models - Liquid AI" = "SLM Models - Liquid AI";
"Import" = "İçe aktar";
"Import GGUF" = "GGUF içe aktar";
"Import MLX" = "MLX içe aktar";
"Import Failed" = "İçe aktarma başarısız oldu";
"Switching between GGUF/MLX modes" = "GGUF/MLX modları arasında geçiş yapın";
"Switching between GGUF/SLM modes" = "GGUF/SLM modları arasında geçiş yapın";
"Vision-capable model" = "Görüş destekli model";
"All" = "Tümü";
"Text" = "Metin";
"Vision" = "Görüş";
"Continue" = "Devam et";
"Try bullet" = "Şunları deneyin:\n• Farklı anahtar kelimeler (ör. 'gemma 3' yerine 'gemma-3')\n• %@\n• Metin/görüş filtresini ayarlayın\n• Arama filtrelerinizi kontrol edin";
"Select one or more .gguf files. For vision models, also select the projector .gguf (files containing ‘mmproj’ or ‘projector’). Files will be copied into your local model library." = "Select one or more .gguf files. For vision models, also select the projector .gguf (files containing ‘mmproj’ or ‘projector’). Files will be copied into your local model library.";
"Select the model folder that contains config.json and the weights (safetensors/npz). The entire folder will be imported into your local model library." = "Select the model folder that contains config.json and the weights (safetensors/npz). The entire folder will be imported into your local model library.";
"K Cache Quantization" = "K önbellek quantizasyonu";
"V Cache Quantization" = "V önbellek quantizasyonu";
"Favorite Limit Reached" = "Favori sınırına ulaşıldı";
"Overview" = "Genel bakış";
"Sampling" = "Örnekleme";
"Speculative Decoding" = "Spekülatif kod çözme";
"Benchmark" = "Benchmark";
"Maintenance" = "Bakım";
"MLX" = "MLX";
"Tokenizer Path (tokenizer.json)" = "Tokenizer yolu (tokenizer.json)";
"Back" = "Geri";
"Favorite Model" = "Favori model";
"Reset to Default Settings" = "Varsayılan ayarlara sıfırla";
"Delete Model" = "Modeli sil";
"Delete %@?" = "%@ silinsin mi?";
"Not provided by repository" = "Depo tarafından sağlanmadı";
"Unknown (not checked yet)" = "Bilinmiyor (henüz kontrol edilmedi)";
"Keep Model In Memory" = "Modeli bellekte tut";
"GPU Offload Layers: %@/%@" = "GPU offload katmanı: %1$@/%2$@";
"CPU Threads: %@" = "CPU iş parçacığı: %@";
"Offload KV Cache to GPU" = "KV önbelleğini GPU'ya aktar";
"Use mmap()" = "mmap() kullan";
"Random" = "Rastgele";
"Flash Attention" = "Flash Attention";
"1 expert" = "1 uzman";
"%@ experts" = "%@ uzman";
"Helper Model" = "Yardımcı model";
"Draft strategy" = "Taslak stratejisi";
"Run Benchmark" = "Benchmark çalıştır";
"Benchmarking…" = "Karşılaştırma yapılıyor…";
"Leap SLM models manage runtime optimizations automatically." = "Leap SLM modelleri çalışma zamanı iyileştirmelerini otomatik yönetir.";
"This format doesn't expose tunable runtime optimizations." = "Bu format ayarlanabilir çalışma zamanı optimizasyonları sunmaz.";
"Token processing" = "Token işleme";
"Token generation" = "Token üretimi";
"Total time" = "Toplam süre";
"First token" = "İlk token";
"Peak memory" = "Tepe bellek";
"Output tokens" = "Çıktı token";
"End Guide" = "Kılavuzu bitir";
"Streaming benchmark output…" = "Benchmark çıktısı akıtılıyor…";
"Streaming… %@ chunks (~%@ tok est.)" = "Yayınlanıyor… %1$@ parça (~%2$@ tahmini token)";
"Streaming… %d chunks (~%d tok est.)" = "Yayınlanıyor… %d parça (~%d tahmini token)";
"The selected model's weights could not be located." = "Seçilen modelin ağırlıkları bulunamadı.";
"Failed to load model for benchmark: %@" = "Benchmark için model yüklenemedi: %@";
"Benchmark generation failed: %@" = "Benchmark üretimi başarısız: %@";
"K Cache" = "K önbelleği";
"V Cache" = "V önbelleği";
"KV Offload" = "KV offload";
"On" = "Açık";
"Off" = "Kapalı";
"GPU" = "GPU";
"CPU" = "CPU";
"%.1f tok/s" = "%.1f tok/s";
"%.1fs" = "%.1fs";
"%.2fs" = "%.2fs";
"Move Up" = "Yukarı taşı";
"Move Down" = "Aşağı taşı";
"Remove" = "Kaldır";
"Startup remote options" = "Uzak başlatma seçenekleri";
"No models cached yet. Open the backend to refresh its catalog." = "Önbellekte model yok. Kataloğu yenilemek için arka ucu aç.";
"We'll try this saved identifier even though it's not in the latest catalog." = "Bu kaydedilmiş tanımlayıcıyı, en güncel katalogda olmasa da deneyeceğiz.";
"This backend is unavailable. Remove it or pick another option." = "Bu arka uç kullanılamıyor. Kaldır veya başka bir seçenek seç.";
"Backend removed" = "Arka uç kaldırıldı";
"What is Max Chunks?" = "Maksimum Parça nedir?";
"What is Similarity Threshold?" = "Benzerlik eşiği nedir?";
"Approx. %@" = "Yakl. %@";
"Advanced mode shows developer options and diagnostics." = "Gelişmiş mod geliştirici seçenekleri ve teşhisleri gösterir.";
"Simple mode hides advanced settings for a cleaner interface." = "Basit mod, arayüzü sadeleştirmek için gelişmiş ayarları gizler.";
"Hide advanced controls" = "Gelişmiş kontrolleri gizle";
"Show advanced controls" = "Gelişmiş kontrolleri göster";
"Adjust model settings" = "Model ayarlarını düzenle";
"Model Settings" = "Model Ayarları";
"SLM models are not supported on this platform." = "SLM modelleri bu platformda desteklenmiyor.";
"Model likely exceeds memory budget. Lower context or choose a smaller quant." = "Model muhtemelen bellek bütçesini aşıyor. Bağlamı düşürün veya daha küçük bir quant seçin.";
"Apple bundle models aren't supported on macOS yet." = "Apple paket modelleri macOS'ta henüz desteklenmiyor.";
"Estimate: %@\nBudget: %@\nContext length: %@ tokens\n\nThis is an estimate based on your device’s memory budget, context length (KV cache), and typical runtime overheads. Actual usage may vary." = "Tahmin: %@\nBütçe: %@\nBağlam uzunluğu: %@ token\n\nBu, cihazınızın bellek bütçesi, bağlam uzunluğu (KV önbelleği) ve tipik çalışma yükleri temel alınarak yapılmış bir tahmindir. Gerçek kullanım değişebilir.";
"Model likely fits in RAM" = "Model büyük olasılıkla RAM’e sığar";
"Model may not fit in RAM" = "Model RAM’e sığmayabilir";
"Fits in RAM (estimated)" = "RAM’e sığar (tahmini)";
"May not fit (estimated)" = "Sığmayabilir (tahmini)";
"Please provide a backend name." = "Lütfen bir arka uç adı girin.";
"A backend with this name already exists." = "Bu ada sahip bir arka uç zaten var.";
"Backend not found." = "Arka uç bulunamadı.";
"This Noema Relay device is already configured." = "Bu Noema Relay cihazı zaten yapılandırılmış.";
"OpenAI API" = "OpenAI API";
"LM Studio" = "LM Studio";
"Ollama" = "Ollama";
"Cloud Relay" = "Cloud Relay";
"Noema Relay" = "Noema Relay";
"Compatible with OpenAI-style /v1 endpoints" = "OpenAI tarzı /v1 uç noktalarıyla uyumlu";
"Connect to LM Studio's REST server" = "LM Studio'nun REST sunucusuna bağlan";
"Target an Ollama host for chat and pulls" = "Sohbet ve indirme için bir Ollama ana bilgisayarını hedefle";
"Use Noema's Cloud Relay on macOS" = "macOS'ta Noema'nın Cloud Relay'ini kullan";
"Pair with your Mac over CloudKit" = "CloudKit üzerinden Mac'inle eşleştir";
"Please provide the CloudKit container identifier." = "CloudKit kapsayıcı tanımlayıcısını girin.";
"Please provide the host device ID from the Mac relay." = "Mac röleden ana cihaz kimliğini girin.";
"Missing host device ID for Noema Relay." = "Noema Relay için ana cihaz kimliği eksik.";
"Missing CloudKit container identifier." = "CloudKit kapsayıcı tanımlayıcısı eksik.";
"Relay catalog unavailable." = "Relay kataloğu kullanılamıyor.";
"Relay catalog is still syncing. Open the Mac relay, ensure it is signed into iCloud, then try again in a moment." = "Relay kataloğu hâlâ senkronize ediliyor. Mac'te rele'yi açın, iCloud'a bağlı olduğundan emin olun ve tekrar deneyin.";
"Terms of Use" = "Kullanım Koşulları";
"Privacy Policy" = "Gizlilik Politikası";
"Contact Support" = "Destekle İletişime Geç";
"Write a Review" = "Değerlendirme Yaz";
"Notes & Issues" = "Notlar ve Sorunlar";
"Qwen3-1.7B is a compact and efficient model from the Qwen3 family, suitable for on-device usage with strong general capabilities." = "Qwen3-1.7B, Qwen3 ailesinden kompakt ve verimli bir modeldir; güçlü genel yeteneklerle cihaz üzerinde kullanım için uygundur.";
"Gemma 3n E2B is a lightweight instruction-tuned model from Google's Gemma family, optimized for efficient on-device conversations." = "Gemma 3n E2B, Google'ın Gemma ailesinden hafif, talimatlara ayarlı bir modeldir; yerel sohbetlerde verimlilik için optimize edilmiştir.";
"Gemma 3n E2B is an instruction-tuned variant of Google's Gemma family built for efficient reasoning on low-resource devices.\nAvailable in GGUF quants (Q3_K_M, Q4_K_M, Q6_K) and an MLX 4-bit build for Apple Silicon.\n" = "Gemma 3n E2B, düşük kaynaklı cihazlarda verimli çıkarım için tasarlanmış, talimat odaklı Gemma varyantıdır.\nGGUF quant'ları (Q3_K_M, Q4_K_M, Q6_K) ve Apple Silicon için MLX 4‑bit yapı olarak sunulur.\n";
"Phi-4 Mini Reasoning is a lightweight model from the Phi-4 family, tuned for strong reasoning and efficiency across tasks." = "Phi-4 Mini Reasoning, Phi-4 ailesinden hafif bir modeldir; güçlü akıl yürütme ve verimlilik için ayarlanmıştır.";
"Phi-4 Mini Reasoning — a compact model in Microsoft’s Phi-4 line designed for logical reasoning, problem solving, and instruction-following. \nDistributed in efficient GGUF quants (Q3_K_L, Q4_K_M, Q6_K) and an MLX 4-bit variant for Apple Silicon devices.\n" = "Phi-4 Mini Reasoning — Microsoft'un Phi-4 serisinden, mantıksal akıl yürütme, problem çözme ve talimat izleme için tasarlanmış kompakt bir modeldir.\nGGUF quant'ları (Q3_K_L, Q4_K_M, Q6_K) ve Apple Silicon için MLX 4‑bit varyantıyla dağıtılır.\n";
"Runtime Safety" = "Çalışma zamanı güvenliği";
"Bypass RAM safety check (may cause crashes)" = "RAM güvenlik kontrolünü atla (çökme olabilir)";
"Estimate for" = "Şunun için tahmin";
"Off-grid Mode" = "Şebeke dışı modu";
"Delete All Chats" = "Tüm sohbetleri sil";
"Reset App Data" = "Uygulama verilerini sıfırla";
"Max Chunks" = "Maksimum Parça";
"Delete Embedding Model" = "Gömme modelini sil";
"Override the app language. Defaults to the device language on first launch." = "Uygulama dilini geçersiz kıl. İlk açılışta varsayılan olarak cihaz dili kullanılır.";
"Swap between the new stacked chat panel and the classic tab bar layout." = "Yeni yığılmış sohbet paneli ile klasik sekme çubuğu arasında geçiş yap.";
"Available Quantizations" = "Kullanılabilir Kuantizasyonlar";
"Sort quantizations" = "Kuantizasyonları sırala";
"Quant" = "Kuant";
"Size ↑" = "Boyut ↑";
"Size ↓" = "Boyut ↓";
"Model Library" = "Model Kütüphanesi";
"Type to filter models…" = "Modelleri filtrelemek için yazın…";
"No models match your search." = "Aramanıza uyan model yok.";
"Browse Explore tab" = "Explore sekmesini aç";
"Manually choose parameters" = "Parametreleri elle seç";
"The base URL looks invalid. Please include the host (e.g. http://127.0.0.1:1234)." = "Temel URL geçersiz görünüyor. Lütfen ana makineyi ekleyin (ör. http://127.0.0.1:1234).";
"Could not build the remote endpoint URL." = "Uzak uç nokta URL'si oluşturulamadı.";
"The server returned an unexpected response." = "Sunucu beklenmeyen bir yanıt verdi.";
"Server responded with status code %d." = "Sunucu %d durum kodu ile yanıt verdi.";
"Server responded with status code %d: %@" = "Sunucu durum kodu %1$d ile yanıt verdi: %2$@";
"Failed to decode server response." = "Sunucu yanıtı çözülemedi.";

"Model doesn't support GPU offload" = "Model GPU aktarımını desteklemiyor";
"Loading model…" = "Model yükleniyor…";
"Select a model to load" = "Yüklenecek bir model seçin";
"Please wait" = "Lütfen bekleyin";
"Models Library" = "Model Kütüphanesi";
"Sort" = "Sırala";
"Recency" = "En yeniler";
"Size" = "Boyut";
"Name" = "Ad";
"Load Failed" = "Yükleme başarısız";
"Don't show again" = "Bir daha gösterme";

"Explore" = "Keşfet";
"Search datasets" = "Veri kümelerini ara";
"Download" = "İndir";
"Offline" = "Çevrimdışı";
"Tap to load" = "Yüklemek için dokunun";
"%d models" = "%d model";
"Updated %@" = "%@ güncellendi";
"No models fetched yet" = "Henüz model alınmadı";
"Auth" = "Kimlik Doğrulama";
"Local Network" = "Yerel Ağ";
"Direct" = "Doğrudan";
"LAN" = "LAN";
"LAN · %@" = "LAN · %@";
"Backend" = "Arka uç";
"Base URL" = "Temel URL";
"Chat Path" = "Sohbet Yolu";
"Models Path" = "Model Yolu";
"Endpoint Type" = "Uç nokta türü";
"Endpoints" = "Uç noktalar";
"Authentication" = "Kimlik doğrulama";
"Model Identifiers" = "Model tanımlayıcıları";
"Name" = "Ad";
"Host device ID" = "Ana cihaz kimliği";
"Host Device ID" = "Ana cihaz kimliği";
"CloudKit container identifier" = "CloudKit kapsayıcı tanımlayıcısı";
"Field requirements will depend on your specific backend deployment." = "Alan gereksinimleri, arka uç dağıtımınıza bağlıdır.";
"Uses Noema Relay configuration" = "Noema Relay yapılandırmasını kullanır";
"Chat: %@\nModels: %@" = "Sohbet: %@\nModeller: %@";
"Download Dataset" = "Veri setini indir";
"No files listed for this dataset." = "Bu veri seti için listelenmiş dosya yok.";
"This dataset's files are not currently supported for document retrieval." = "Bu veri setinin dosyaları şu anda belge arama için desteklenmiyor.";
"Supported formats: %@" = "Desteklenen formatlar: %@";
"Try another dataset if these formats aren't available." = "Bu formatlar mevcut değilse başka bir veri seti deneyin.";
"Found unsupported: %@ …" = "Desteklenmeyen formatlar bulundu: %@ …";
"This textbook appears to be available only as a web page. Noema can't import it as a dataset." = "Bu ders kitabı yalnızca bir web sayfası olarak görünüyor. Noema bunu bir veri seti olarak içe aktaramıyor.";
"Download complete" = "İndirme tamamlandı";
"Downloading…" = "İndiriliyor…";
"No compatible files found for retrieval. Supported formats: %@" = "Arama için uyumlu dosya bulunamadı. Desteklenen formatlar: %@";
"No internet connection." = "İnternet bağlantısı yok.";
"Request timed out. Please try again." = "İstek zaman aşımına uğradı. Lütfen tekrar deneyin.";
"Connection was lost. Please try again." = "Bağlantı kesildi. Lütfen tekrar deneyin.";
"Unexpected error: %@" = "Beklenmeyen hata: %@";

"Downloaded" = "İndirildi";
"Compressed Text" = "Sıkıştırılmış Metin";
"Small" = "Küçük";
"Medium" = "Orta";
"Large" = "Büyük";
"Very Large" = "Çok büyük";
"Extreme" = "Aşırı büyük";
"Under 10 MB" = "10 MB'nin altında";
"10–50 MB" = "10–50 MB";
"50–200 MB" = "50–200 MB";
"200–500 MB" = "200–500 MB";
"Over 500 MB" = "500 MB'nin üzerinde";
"Estimated Embedding Time" = "Tahmini gömme süresi";
"Peak RAM Usage" = "Tepe RAM kullanımı";
"Dataset Size" = "Veri seti boyutu";
"Performance Note" = "Performans notu";
"Recommendation" = "Öneri";
"Remember:" = "Unutmayın:";
"• Close other applications to free up RAM" = "• RAM boşaltmak için diğer uygulamaları kapatın";
"• Embedding happens locally on your device" = "• Gömme işlemi cihazınızda yerel olarak yapılır";
"• Larger datasets take exponentially more time" = "• Daha büyük veri setleri kat kat daha uzun sürer";
"• You can pause and resume downloads if needed" = "• Gerekirse indirmeleri duraklatıp devam ettirebilirsiniz";
"Dataset Requirements" = "Veri seti gereksinimleri";
"Got it" = "Anladım";
"Check Requirements" = "Gereksinimleri kontrol et";
"< 1 minute" = "1 dakikadan az";
"%d minutes" = "%d dakika";
"This dataset should embed quickly with minimal resource usage. Perfect for testing and quick experiments." = "Bu veri seti çok az kaynakla hızlıca gömülmelidir. Testler ve hızlı denemeler için ideal.";
"This dataset is a reasonable size for most systems. Embedding should complete in a few minutes." = "Bu veri seti çoğu sistem için makul boyutta. Gömme birkaç dakika içinde tamamlanmalı.";
"This is a substantial dataset. Ensure you have adequate RAM and expect embedding to take 10–30 minutes." = "Bu oldukça büyük bir veri seti. Yeterli RAM olduğundan emin olun ve 10–30 dakika sürebileceğini bekleyin.";
"This is a very large dataset. Embedding may take 30–60 minutes and requires significant RAM." = "Bu çok büyük bir veri seti. Gömme 30–60 dakika sürebilir ve ciddi miktarda RAM ister.";
"This is an extremely large dataset. Consider splitting it into smaller parts for better performance." = "Bu son derece büyük bir veri seti. Daha iyi performans için daha küçük parçalara bölmeyi düşünün.";
"Go ahead and download! This size works well on all systems." = "İndirip devam edebilirsiniz! Bu boyut tüm sistemlerde iyi çalışır.";
"Recommended for most users. Make sure you have at least 4GB of free RAM." = "Çoğu kullanıcı için önerilir. En az 4GB boş RAM olduğundan emin olun.";
"Recommended only if you have 8GB+ RAM available. Close other applications before embedding." = "Yalnızca 8GB+ RAM varsa önerilir. Gömmeden önce diğer uygulamaları kapatın.";
"Recommended only for systems with 16GB+ RAM. Consider processing during off-hours." = "Yalnızca 16GB+ RAM olan sistemler için önerilir. Mümkünse mesai dışında çalıştırın.";
"Not recommended for typical systems. Consider finding a smaller version or subset of this dataset." = "Tipik sistemler için önerilmez. Daha küçük bir sürüm veya alt küme bulmayı düşünün.";
"Sample dataset" = "Örnek veri seti";
"Ready" = "Hazır";
"Open" = "Aç";

/* Noema Relay – pairing & dataset helpers */
"Model file missing (.gguf)" = "Model dosyası eksik (.gguf)";
"Model path missing" = "Model yolu eksik";
"Imported Dataset" = "İçe aktarılan veri kümesi";
"Dataset name" = "Veri kümesi adı";
"Keep this device near the Mac that's running Noema Relay to import its settings." = "Ayarları içe aktarmak için bu aygıtı Noema Relay çalıştıran Mac'in yakınında tutun.";
"Scanning for your Mac relay…" = "Mac röleniz aranıyor…";
"Ready to scan nearby relays" = "Yakındaki röleleri taramaya hazır";
"Bluetooth access is required to pair with the Mac relay." = "Mac rölesiyle eşleştirmek için Bluetooth erişimi gereklidir.";
"Stop Scanning" = "Taramayı durdur";
"Start Scan" = "Taramayı başlat";
"Connection verified. Relay details imported from this Mac." = "Bağlantı doğrulandı. Röle ayrıntıları bu Mac'ten içe aktarıldı.";
"Signal strength unavailable" = "Sinyal gücü kullanılabilir değil";
"Very close" = "Çok yakın";
"Nearby" = "Yakında";
"Within one room" = "Aynı odanın içinde";
"Move closer for a stronger signal" = "Daha güçlü sinyal için daha yakına gelin.";
"This Mac" = "Bu Mac";

/* Accessibility announcements */
"Model loaded." = "Model yüklendi.";
"Prompt submitted." = "İstem gönderildi.";
"Generating response…" = "Yanıt oluşturuluyor…";
"Response generated." = "Yanıt oluşturuldu.";

/* Tabs & accessibility labels */
"Stored" = "Saklanan";
"Web Search" = "Web Arama";
"Open Stored" = "Saklanan'ı Aç";
"Message input" = "Mesaj girişi";
"What is Web Search button?" = "Web Arama düğmesi nedir?";

/* Mac chat quick-load menu */
"Open Model Library" = "Model Kitaplığını Aç";
"Favorites" = "Favoriler";
"Recent" = "Son Kullanılanlar";
