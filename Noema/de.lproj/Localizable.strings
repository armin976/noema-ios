/* Auto-generated localization file. */
"%@" = "%@";
"%@ %" = "%1$@ %2$";
"%@ %@" = "%1$@ %2$@";
"%@ models" = "%@ Modelle";
"%@ of %@ budget" = "%1$@ von %2$@ Budget";
"%@ tokens" = "%@-Token";
"%@ – %@" = "%1$@ – %2$@";
"%@ • %@" = "%1$@ • %2$@";
"%@%" = "%1$@%2$";
"%@% · %@" = "%1$@%2$ · %3$@";
"%@." = "%@.";
"%@:" = "%@:";
"(+ mmproj %@%)" = "(+ mmproj %1$@%2$)";
"... and %@ more" = "... und %@ mehr";
"320 MB • One-time download" = "320 MB • Einmaliger Download";
"320 MB • One‑time download used for local dataset search" = "320 MB • Einmaliger Download für die lokale Datensatzsuche";
"A larger context keeps more conversation history, but also uses more memory. Adjust it here." = "Ein größerer Kontext speichert mehr Konversationsverlauf, verbraucht aber auch mehr Speicher. Passen Sie es hier an.";
"Active" = "Aktiv";
"Active Model" = "Aktives Modell";
"Active connection via %@" = "Aktive Verbindung über %@";
"Active experts per token: %@ of %@" = "Aktive Experten pro Token: %1$@ von %2$@";
"Add a remote backend to configure remote startup fallbacks." = "Fügen Sie ein Remote-Backend hinzu, um Remote-Start-Fallbacks zu konfigurieren.";
"Add one or two datasets (like open textbooks) to keep responses accurate and help the AI cite sources." = "Fügen Sie einen oder zwei Datensätze hinzu (z. B. offene Lehrbücher), um die Antworten korrekt zu halten und die KI beim Zitieren von Quellen zu unterstützen.";
"Add remote endpoint" = "Remote-Endpunkt hinzufügen";
"Adjust appearance, privacy options, and network preferences here." = "Passen Sie hier das Erscheinungsbild, die Datenschutzoptionen und die Netzwerkeinstellungen an.";
"Advanced" = "Fortschrittlich";
"Advanced Controls" = "Erweiterte Steuerelemente";
"Allows models to use a privacy-preserving web search API when you tap the globe in chat. Default is ON. In Offline Only mode, the button is disabled." = "Ermöglicht Models die Verwendung einer datenschutzfreundlichen Web-Such-API, wenn Sie im Chat auf den Globus tippen. Die Standardeinstellung ist EIN. Im Nur-Offline-Modus ist die Schaltfläche deaktiviert.";
"Analyzing context..." = "Kontext analysieren...";
"App Memory Usage (estimated)" = "App-Speichernutzung (geschätzt)";
"App memory usage budget: %@ (conservative)" = "Budget für App-Speichernutzung: %@ (konservativ)";
"Approx. Tokens" = "Ca. Token";
"Arm web search when you truly need outside info. It has a small daily limit and most chats don’t require it." = "Aktivieren Sie die Websuche, wenn Sie wirklich externe Informationen benötigen. Es gibt ein kleines Tageslimit und die meisten Chats erfordern es nicht.";
"Ask Noema anything" = "Frag Noema alles";
"Ask…" = "Fragen…";
"Attach Photos" = "Fotos anhängen";
"Backend not found" = "Backend nicht gefunden";
"Benchmark running…" = "Benchmark läuft…";
"Benchmarking is not available for this model format." = "Für dieses Modellformat ist kein Benchmarking verfügbar.";
"Blocks all network traffic, model downloads, and cloud connections so everything stays on‑device." = "Blockiert den gesamten Netzwerkverkehr, Modell-Downloads und Cloud-Verbindungen, sodass alles auf dem Gerät bleibt.";
"Bluetooth Pairing" = "Bluetooth-Kopplung";
"Browse community models and curated datasets to expand what Noema can do." = "Durchsuchen Sie Community-Modelle und kuratierte Datensätze, um die Möglichkeiten von Noema zu erweitern.";
"Browse curated datasets for retrieval" = "Durchsuchen Sie kuratierte Datensätze zum Abrufen";
"CFBundleShortVersionString1.0" = "CFBundleShortVersionString1.0";
"Cancel" = "Stornieren";
"Cancel Benchmark" = "Benchmark abbrechen";
"Discover Intelligence" = "Intelligenz entdecken";
"Catalog" = "Katalog";
"Chat" = "Chatten";
"Chat privately with your local models, sync datasets, and manage the relay server in one place." = "Chatten Sie privat mit Ihren lokalen Models, synchronisieren Sie Datensätze und verwalten Sie den Relay-Server an einem Ort.";
"Chats" = "Chats";
"Checking…" = "Überprüfung…";
"Citation %@" = "Zitat %@";
"Cloud Relay Container" = "Cloud-Relay-Container";
"Cloud Relay via CloudKit (auto-discovery and Bluetooth pairing)" = "Cloud Relay über CloudKit (automatische Erkennung und Bluetooth-Kopplung)";
"CloudKit" = "CloudKit";
"CloudKit bridge active. Local replies are generated on this Mac." = "CloudKit-Brücke aktiv. Auf diesem Mac werden lokale Antworten generiert.";
"Compiling Metal kernels for GGUF models can take up to a minute on first load." = "Das Kompilieren von Metal-Kerneln für GGUF-Modelle kann beim ersten Laden bis zu einer Minute dauern.";
"Complete the streaming response in the active chat before sending again." = "Vervollständigen Sie die Streaming-Antwort im aktiven Chat, bevor Sie sie erneut senden.";
"Confirm and Start Embedding" = "Bestätigen Sie und beginnen Sie mit der Einbettung";
"Connected" = "Verbunden";
"Connection Modes" = "Verbindungsmodi";
"Connection Status: %@" = "Verbindungsstatus: %@";
"Container" = "Container";
"Context Length" = "Kontextlänge";
"Context Length: 4096 tokens" = "Kontextlänge: 4096 Token";
"Context length is under 5000 tokens. With images and multi-sequence decoding (n_seq_max=16), per-sequence memory can be too small, leading to a crash. Increase context to at least 8192 in Model Settings." = "Die Kontextlänge liegt unter 5000 Token. Bei Bildern und Multisequenz-Decodierung (n_seq_max=16) kann der Speicher pro Sequenz zu klein sein, was zu einem Absturz führt. Erhöhen Sie den Kontext in den Modelleinstellungen auf mindestens 8192.";
"Controls how many high‑scoring passages (chunks) can be injected into the prompt. Higher values increase recall but consume more context window and can slow responses. Typical range 3–6." = "Steuert, wie viele Passagen mit hoher Punktzahl (Chunks) in die Eingabeaufforderung eingefügt werden können. Höhere Werte steigern die Erinnerung, verbrauchen jedoch mehr Kontextfenster und können die Antworten verlangsamen. Typischer Bereich 3–6.";
"Couldn't load the recommended model." = "Das empfohlene Modell konnte nicht geladen werden.";
"Couldn’t load the recommended model right now." = "Das empfohlene Modell konnte momentan nicht geladen werden.";
"Creativity: %@. Low values focus responses; high values add variety." = "Kreativität: %@. Niedrige Werte konzentrieren sich auf Antworten; Hohe Werte sorgen für Abwechslung.";
"Dark" = "Dunkel";
"Dataset" = "Datensatz";
"Dataset indexing in progress..." = "Datensatzindizierung läuft...";
"Dataset ready to use" = "Datensatz sofort einsatzbereit";
"Datasets" = "Datensätze";
"Datasets enrich the model with focused knowledge. Toggle one on to use it in chat." = "Datensätze bereichern das Modell mit gezieltem Wissen. Schalten Sie eines ein, um es im Chat zu verwenden.";
"Default selection (~%@) balances RAM usage against model quality." = "Die Standardauswahl (~%@) gleicht die RAM-Nutzung mit der Modellqualität aus.";
"Delete" = "Löschen";
"Delete Dataset" = "Datensatz löschen";
"Deletes all chats, downloaded models, and datasets, and restores settings to defaults. The embedding model stays installed." = "Löscht alle Chats, heruntergeladenen Modelle und Datensätze und stellt die Einstellungen auf die Standardwerte zurück. Das Einbettungsmodell bleibt installiert.";
"Device" = "Gerät";
"Digest:" = "Verdauen:";
"Done" = "Erledigt";
"Done!" = "Erledigt!";
"Download Now" = "Jetzt herunterladen";
"Download a model from Explore or add a remote endpoint to get started." = "Laden Sie ein Modell von Explore herunter oder fügen Sie einen Remote-Endpunkt hinzu, um loszulegen.";
"Download a small embedding model so Noema can index and search your datasets" = "Laden Sie ein kleines Einbettungsmodell herunter, damit Noema Ihre Datensätze indizieren und durchsuchen kann";
"Downloaded datasets need on-device embedding. Give it a few minutes after download finishes." = "Heruntergeladene Datensätze müssen auf dem Gerät eingebettet werden. Warten Sie nach Abschluss des Downloads einige Minuten.";
"Downloaded models and datasets live here so you can manage them offline." = "Heruntergeladene Modelle und Datensätze sind hier verfügbar, sodass Sie sie offline verwalten können.";
"Downloading…" = "Herunterladen…";
"Draft tokens: %@" = "Draft-Token: %@";
"Draft window: %@" = "Entwurfsfenster: %@";
"EPUB viewing not supported on this platform" = "Die EPUB-Anzeige wird auf dieser Plattform nicht unterstützt";
"Embedding" = "Einbetten";
"Embedding Model Ready" = "Einbettungsmodell bereit";
"Embedding is resource intensive. For best performance, plug in your phone. Do you want to proceed on battery?" = "Das Einbetten ist ressourcenintensiv. Für optimale Leistung schließen Sie Ihr Telefon an. Möchten Sie mit Batteriebetrieb fortfahren?";
"Enabling Bluetooth…" = "Bluetooth wird aktiviert…";
"Enhance with Datasets" = "Mit Datensätzen erweitern";
"Error" = "Fehler";
"Estimated working set: %@ · Budget: %@" = "Geschätzter Arbeitssatz: %1$@ · Budget: %2$@";
"Experts Per Token" = "Experten pro Token";
"Explore Datasets" = "Entdecken Sie Datensätze";
"Expose any downloaded models or connected remote endpoints from the Stored tab to your paired devices. Select which one should answer conversations when the relay is running." = "Stellen Sie alle heruntergeladenen Modelle oder verbundenen Remote-Endpunkte über die Registerkarte „Gespeichert“ Ihren gekoppelten Geräten zur Verfügung. Wählen Sie aus, wer Gespräche beantworten soll, wenn das Relay läuft.";
"Expose to iOS" = "Für iOS verfügbar machen";
"Explore the latest open-source models optimized for your Mac." = "Entdecken Sie die neuesten Open-Source-Modelle, die für Ihren Mac optimiert sind.";
"Failed to load README" = "README konnte nicht geladen werden";
"Failed: %@" = "Fehlgeschlagen: %@";
"Fastest option on this device: SLM (Leap) models." = "Schnellste Option auf diesem Gerät: SLM-Modelle (Leap).";
"Field requirements will depend on your specific backend deployment." = "Die Anforderungen vor Ort hängen von Ihrer spezifischen Backend-Bereitstellung ab.";
"Files" = "Dateien";
"First, enable fast dataset search" = "Aktivieren Sie zunächst die schnelle Datensatzsuche";
"First-time GGUF load takes longer" = "Das erstmalige Laden von GGUF dauert länger";
"First-time download from HuggingFace" = "Erstmaliger Download von HuggingFace";
"First‑time setup: download the Qwen‑1.7B model and embeddings.\nWi‑Fi recommended." = "Erstmalige Einrichtung: Laden Sie das Qwen-1.7B-Modell und die Einbettungen herunter.\nWLAN empfohlen.";
"For best performance, please plug in your phone until this completes." = "Um eine optimale Leistung zu erzielen, schließen Sie Ihr Telefon bitte an, bis dieser Vorgang abgeschlossen ist.";
"Force Local Network" = "Lokales Netzwerk erzwingen";
"Forces chat traffic through the last LAN host even if Wi‑Fi names don't match yet." = "Erzwingt den Chat-Verkehr über den letzten LAN-Host, auch wenn die WLAN-Namen noch nicht übereinstimmen.";
"Formatted view unavailable" = "Formatierte Ansicht nicht verfügbar";
"Found unsupported: %@ …" = "Nicht unterstützt gefunden: %@ …";
"Frequency penalty: %@" = "Häufigkeitsstrafe: %@";
"GGUF models are the most compatible option. Use the format switch to explore the other builds when you need them." = "GGUF-Modelle sind die kompatibelste Option. Verwenden Sie den Formatschalter, um die anderen Builds bei Bedarf zu erkunden.";
"GGUF works everywhere. MLX targets Apple Silicon speed. SLM focuses on responsiveness on any device." = "GGUF funktioniert überall. MLX zielt auf die Geschwindigkeit von Apple Silicon ab. SLM konzentriert sich auf die Reaktionsfähigkeit auf jedem Gerät.";
"GPU Offload Layers" = "GPU-Offload-Ebenen";
"GPU off-load is not supported for this model." = "GPU-Offload wird für dieses Modell nicht unterstützt.";
"Get Started" = "Legen Sie los";
"Help shape Noema by trying upcoming features and sharing feedback." = "Gestalten Sie Noema mit, indem Sie kommende Funktionen ausprobieren und Feedback teilen.";
"High context lengths use more memory" = "Hohe Kontextlängen verbrauchen mehr Speicher";
"High-quality embedding model for local RAG" = "Hochwertiges Einbettungsmodell für lokales RAG";
"Host ID: %@" = "Host-ID: %@";
"How it works" = "Wie es funktioniert";
"I'm New to Local LLMs, Guide Me" = "Ich bin neu bei lokalen LLMs, leiten Sie mich";
"If enabled, the app will attempt to load models even when they likely exceed your device's memory budget. This can cause the app to terminate." = "Wenn diese Option aktiviert ist, versucht die App, Modelle zu laden, auch wenn diese wahrscheinlich das Speicherbudget Ihres Geräts überschreiten. Dies kann dazu führen, dass die App beendet wird.";
"Import Dataset" = "Datensatz importieren";
"Import PDFs, EPUBs, or text files to build local knowledge bases." = "Importieren Sie PDFs, EPUBs oder Textdateien, um lokale Wissensdatenbanken aufzubauen.";
"Import your own PDFs, EPUBs, or TXT files and keep them local." = "Importieren Sie Ihre eigenen PDFs, EPUBs oder TXT-Dateien und bewahren Sie sie lokal auf.";
"Importing & Scanning..." = "Importieren und Scannen...";
"In progress..." = "Im Gange...";
"Indexing %@" = "Indizierung %@";
"Indexing dataset…" = "Datensatz wird indiziert…";
"Indexing: %@% · %@" = "Indizierung: %1$@%2$ · %3$@";
"Install a local model to make it available at launch." = "Installieren Sie ein lokales Modell, um es beim Start verfügbar zu machen.";
"Install another model with the same architecture and equal or smaller size to enable speculative decoding." = "Installieren Sie ein anderes Modell mit derselben Architektur und gleicher oder kleinerer Größe, um eine spekulative Dekodierung zu ermöglichen.";
"K Cache Quant" = "K Cache-Quant";
"Keep this iPhone or iPad within a few feet of the Mac that is advertising Noema Relay. We'll pull the relay details automatically once connected." = "Halten Sie dieses iPhone oder iPad in einem Umkreis von wenigen Metern um den Mac, auf dem Noema Relay beworben wird. Sobald die Verbindung hergestellt ist, rufen wir die Relay-Details automatisch ab.";
"LAN URL: %@" = "LAN-URL: %@";
"Large Model Downloads" = "Große Modell-Downloads";
"Last Sync" = "Letzte Synchronisierung";
"Last refreshed %@" = "Zuletzt aktualisiert %@";
"Latest benchmark" = "Neuester Benchmark";
"Latest integrated release: %@" = "Neueste integrierte Version: %@";
"Library" = "Bibliothek";
"Light" = "Licht";
"Llama.cpp" = "Call.cpp";
"Load" = "Laden";
"Load a local model before chatting. You can download one from the Explore tab or load a model you've already installed." = "Laden Sie vor dem Chatten ein lokales Modell. Sie können eines über die Registerkarte „Erkunden“ herunterladen oder ein bereits installiertes Modell laden.";
"Loading recommendation…" = "Ladeempfehlung…";
"Loading…" = "Laden…";
"Local Network HTTP server for LAN clients (OpenAI-compatible)" = "Lokaler Netzwerk-HTTP-Server für LAN-Clients (OpenAI-kompatibel)";
"Low = focused. High = varied." = "Niedrig = konzentriert. Hoch = abwechslungsreich.";
"Lower = more results (more noise). Higher = stricter matches." = "Niedriger = mehr Ergebnisse (mehr Rauschen). Höher = strengere Übereinstimmungen.";
"MLX currently manages expert routing automatically; manual selection is not supported." = "MLX verwaltet derzeit das Experten-Routing automatisch; Die manuelle Auswahl wird nicht unterstützt.";
"Many models are several gigabytes in size and require a stable connection and sufficient storage. Downloads can fail or take a long time on slow networks or devices with limited space." = "Viele Modelle sind mehrere Gigabyte groß und benötigen eine stabile Verbindung und ausreichend Speicherplatz. In langsamen Netzwerken oder auf Geräten mit begrenztem Speicherplatz können Downloads fehlschlagen oder lange dauern.";
"Max Chunks: %@" = "Max. Chunks: %@";
"Max recommended context on this device: ~%@ tokens" = "Maximal empfohlener Kontext auf diesem Gerät: ~%@ Token";
"Measure real-world generation speed for this configuration. A short scripted prompt will run locally and report timing and memory usage." = "Messen Sie die reale Generierungsgeschwindigkeit für diese Konfiguration. Eine kurze Skript-Eingabeaufforderung wird lokal ausgeführt und meldet Timing und Speichernutzung.";
"Min-p" = "Min-p";
"Min-p: %@" = "Min-p: %@";
"Minimum cosine similarity a passage must have to be considered relevant. Lower = more passages (higher recall, more noise). Higher = fewer, more precise passages. Try 0.2–0.4 for broad questions; 0.5–0.7 for precise lookups." = "Minimale Kosinusähnlichkeit einer Passage muss als relevant angesehen werden. Niedriger = mehr Passagen (höherer Recall, mehr Rauschen). Höher = weniger, präzisere Passagen. Versuchen Sie es mit 0,2–0,4 für allgemeine Fragen; 0,5–0,7 für präzise Suchvorgänge.";
"MoE layers: %@ / %@" = "MoE-Schichten: %1$@ / %2$@";
"Model Detection Limitations" = "Einschränkungen der Modellerkennung";
"Model Formats" = "Modellformate";
"Models" = "Modelle";
"Models shown here are exposed by the Mac relay. Manage sources in the Relay tab on macOS to share more models." = "Die hier gezeigten Modelle werden vom Mac-Relais bereitgestellt. Verwalten Sie Quellen auf der Registerkarte „Relay“ unter macOS, um weitere Modelle freizugeben.";
"Move your device closer to the Mac running the relay if it doesn't appear right away. Bluetooth discovery usually completes within a few seconds." = "Bewegen Sie Ihr Gerät näher an den Mac, auf dem das Relay ausgeführt wird, wenn es nicht sofort angezeigt wird. Die Bluetooth-Erkennung ist normalerweise innerhalb weniger Sekunden abgeschlossen.";
"Name your dataset" = "Benennen Sie Ihren Datensatz";
"Nearby Relays" = "Relais in der Nähe";
"Nearby iPhone and iPad devices discover your Mac relay instantly and sync pairing codes over the air." = "In der Nähe befindliche iPhone- und iPad-Geräte erkennen Ihr Mac-Relay sofort und synchronisieren Kopplungscodes drahtlos.";
"Need a fresh thread? Tap the plus button for a brand-new conversation." = "Brauchen Sie einen neuen Thread? Tippen Sie auf die Plus-Schaltfläche, um ein brandneues Gespräch zu starten.";
"Nice! You already have the recommended GGUF starter model ready to use." = "Hübsch! Sie haben bereits das empfohlene GGUF-Startermodell einsatzbereit.";
"No compatible files found for retrieval. Supported: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV" = "Es wurden keine kompatiblen Dateien zum Abrufen gefunden. Unterstützt: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV";
"No connection responses recorded yet." = "Es wurden noch keine Verbindungsantworten aufgezeichnet.";
"No datasets available yet. Import or download datasets to build your personal library." = "Noch keine Datensätze verfügbar. Importieren oder laden Sie Datensätze herunter, um Ihre persönliche Bibliothek aufzubauen.";
"No datasets found. Try different keywords." = "Keine Datensätze gefunden. Probieren Sie verschiedene Schlüsselwörter aus.";
"No datasets imported yet." = "Noch keine Datensätze importiert.";
"No datasets yet" = "Noch keine Datensätze";
"No files listed for this dataset." = "Für diesen Datensatz sind keine Dateien aufgeführt.";
"No model >" = "Kein Modell >";
"No model loaded" = "Kein Modell geladen";
"No models available. Add downloads or remote connections in Stored to configure the relay." = "Keine Modelle verfügbar. Fügen Sie Downloads oder Remote-Verbindungen in „Gespeichert“ hinzu, um das Relay zu konfigurieren.";
"No models cached yet. Open the backend to refresh its catalog." = "Noch keine Modelle zwischengespeichert. Öffnen Sie das Backend, um den Katalog zu aktualisieren.";
"No models found for '%@'" = "Keine Modelle für „%@“ gefunden";
"No models loaded right now. We'll spin one up when a request arrives." = "Im Moment sind keine Modelle geladen. Wir werden eines hochfahren, wenn eine Anfrage eingeht.";
"No models match your search." = "Keine Modelle entsprechen Ihrer Suche.";
"No models yet" = "Noch keine Modelle";
"No parameters" = "Keine Parameter";
"No quant files available" = "Keine Quant-Dateien verfügbar";
"No recent devices. We'll list clients the next time they talk to this relay." = "Keine aktuellen Geräte. Wir werden die Kunden auflisten, wenn sie das nächste Mal mit diesem Relay sprechen.";
"No remote endpoints configured yet." = "Noch keine Remote-Endpunkte konfiguriert.";
"No remote endpoints configured." = "Keine Remote-Endpunkte konfiguriert.";
"No ≥Q3 quants are available for this model." = "Für dieses Modell sind keine ≥Q3-Quants verfügbar.";
"Noema" = "November";
"Noema REST API — /api/v0/* for model catalog & operations" = "Noema REST API – /api/v0/* für Modellkatalog und Operationen";
"Noema Relay" = "Noema-Staffel";
"Noema Server" = "Noema-Server";
"Noema attempts to gauge available memory to prevent models from exceeding device limits. These checks may occasionally miss risky situations and allow a model to crash your app, or they may be overly conservative and block a model that could have run fine." = "Noema versucht, den verfügbaren Speicher zu messen, um zu verhindern, dass Modelle die Gerätegrenzen überschreiten. Diese Prüfungen können gelegentlich riskante Situationen übersehen und dazu führen, dass ein Modell Ihre App zum Absturz bringt, oder sie sind möglicherweise zu konservativ und blockieren ein Modell, das hätte einwandfrei laufen können.";
"Noema could not find a projector in the repository. If the model advertises vision, ensure the mmproj file is present in the same folder as the weights." = "Noema konnte im Repository keinen Projektor finden. Wenn das Modell Vision ankündigt, stellen Sie sicher, dass die mmproj-Datei im selben Ordner wie die Gewichte vorhanden ist.";
"Noema has been reset. The embedding model remains installed." = "Noema wurde zurückgesetzt. Das Einbettungsmodell bleibt installiert.";
"Nomic Embed Text v1.5 (Q4_K_M)" = "Nomic Embed Text v1.5 (Q4_K_M)";
"None" = "Keiner";
"Not found" = "Nicht gefunden";
"Not provided" = "Nicht bereitgestellt";
"OK" = "OK";
"Off-Grid" = "Off-Grid";
"Off-grid mode blocks every network call so the app stays self-contained. Good luck exploring Noema!" = "Der Off-Grid-Modus blockiert jeden Netzwerkanruf, sodass die App eigenständig bleibt. Viel Glück beim Erkunden von Noema!";
"Only one expert is available for this model; the active expert count is fixed." = "Für dieses Modell steht nur ein Experte zur Verfügung; Die Anzahl der aktiven Experten ist festgelegt.";
"Open Stored to choose a model to run locally or connect to a remote endpoint." = "Öffnen Sie Stored, um ein Modell auszuwählen, das lokal ausgeführt oder mit einem Remote-Endpunkt verbunden werden soll.";
"Open the sidebar to revisit any previous session without losing your spot." = "Öffnen Sie die Seitenleiste, um eine vorherige Sitzung erneut aufzurufen, ohne Ihren Platz zu verlieren.";
"OpenAI-style API — /v1/chat/completions, /v1/completions, /v1/models" = "API im OpenAI-Stil – /v1/chat/completions, /v1/completions, /v1/models";
"Optimizations in use" = "Optimierungen im Einsatz";
"PDF viewing not supported on this platform" = "Die PDF-Anzeige wird auf dieser Plattform nicht unterstützt";
"Pick a model and add a dataset" = "Wählen Sie ein Modell aus und fügen Sie einen Datensatz hinzu";
"Pick the SLM format when you want ultra-responsive models that run well anywhere." = "Wählen Sie das SLM-Format, wenn Sie äußerst reaktionsschnelle Modelle wünschen, die überall gut funktionieren.";
"Pinned answer" = "Angepinnte Antwort";
"Pinned answer unavailable" = "Angepinnte Antwort nicht verfügbar";
"Preparation" = "Vorbereitung";
"Preparing Embedding Model" = "Einbettungsmodell vorbereiten";
"Preparing benchmark…" = "Benchmark wird vorbereitet…";
"Preparing…" = "Vorbereiten…";
"Presence penalty: %@" = "Anwesenheitsstrafe: %@";
"Projector (mmproj)" = "Projektor (mmproj)";
"Projector downloaded automatically from Hugging Face. Keep this file alongside the weights so vision remains available." = "Der Projektor wurde automatisch von Hugging Face heruntergeladen. Bewahren Sie diese Datei neben den Gewichten auf, damit Sie weiterhin sehen können.";
"Quantize the runtime key cache to save memory. Experimental." = "Quantisieren Sie den Laufzeitschlüsselcache, um Speicher zu sparen. Experimental.";
"Quantize the runtime value cache to save memory when Flash Attention is enabled. Experimental." = "Quantisieren Sie den Laufzeitwertcache, um Speicher zu sparen, wenn Flash Attention aktiviert ist. Experimental.";
"Qwen 3 1.7B GGUF (Q3_K_M) gives you a dependable starting point. Delete it anytime if you need space." = "Qwen 3 1.7B GGUF (Q3_K_M) bietet Ihnen einen zuverlässigen Ausgangspunkt. Löschen Sie es jederzeit, wenn Sie Platz benötigen.";
"RAG embeds normalized paragraphs from your PDFs and EPUBs. On each question, the most relevant chunks are retrieved and added to the prompt. Images are ignored." = "RAG bettet normalisierte Absätze aus Ihren PDFs und EPUBs ein. Bei jeder Frage werden die relevantesten Abschnitte abgerufen und der Eingabeaufforderung hinzugefügt. Bilder werden ignoriert.";
"RAM Safety Checks" = "RAM-Sicherheitsprüfungen";
"RAM information for this device will be added in a future update." = "RAM-Informationen für dieses Gerät werden in einem zukünftigen Update hinzugefügt.";
"REST Endpoints" = "REST-Endpunkte";
"Reachable at" = "Erreichbar unter";
"Ready for Use" = "Einsatzbereit";
"Recent Chats" = "Aktuelle Chats";
"Recommended" = "Empfohlen";
"Recommended Starter Model" = "Empfohlenes Einsteigermodell";
"Relay ID" = "Relais-ID";
"Relay Server Running" = "Relay-Server läuft";
"Relay Sources" = "Relaisquellen";
"Remaining: %@" = "Verbleibend: %@";
"Remember:" = "Erinnern:";
"Remote Backends" = "Remote-Backends";
"Remote endpoint is offline. This model can't be found at this time." = "Remote-Endpunkt ist offline. Dieses Modell kann derzeit nicht gefunden werden.";
"Remote timeout: %@s" = "Remote-Timeout: %@s";
"Repeat last N tokens: %@" = "Letzte N Token wiederholen: %@";
"Repetition penalty: %@" = "Wiederholungsstrafe: %@";
"Request Parameters" = "Anforderungsparameter";
"Responses are generated by the macOS relay server. Configure the provider (LM Studio or Ollama) on the Mac app." = "Antworten werden vom macOS-Relay-Server generiert. Konfigurieren Sie den Anbieter (LM Studio oder Ollama) in der Mac-App.";
"Result" = "Ergebnis";
"Results" = "Ergebnisse";
"Save" = "Speichern";
"Saving…" = "Sparen…";
"Score: %@" = "Ergebnis: %@";
"SearXNG web search is available without limits. There's nothing to purchase—just enable the globe button in chat whenever you need online results." = "Die SearXNG-Websuche ist ohne Einschränkungen verfügbar. Sie müssen nichts kaufen – aktivieren Sie einfach die Globus-Schaltfläche im Chat, wenn Sie Online-Ergebnisse benötigen.";
"SearXNG web search is enabled for this device." = "Die SearXNG-Websuche ist für dieses Gerät aktiviert.";
"Search" = "Suchen";
"Search for any subject you're interested in." = "Suchen Sie nach einem beliebigen Thema, das Sie interessiert.";
"Search requests are proxied through https://search.noemaai.com and are available without quotas." = "Suchanfragen werden über https://search.noemaai.com weitergeleitet und sind ohne Kontingente verfügbar.";
"Seed" = "Samen";
"Selecting more experts keeps additional expert weights resident in RAM and increases memory usage." = "Durch die Auswahl weiterer Experten verbleiben zusätzliche Expertengewichte im RAM und erhöhen die Speichernutzung.";
"Server Settings" = "Servereinstellungen";
"Share Logs" = "Protokolle teilen";
"Sharing relay payload with nearby devices…" = "Weitergabe der Relay-Nutzlast an Geräte in der Nähe …";
"Shows the last server response." = "Zeigt die letzte Serverantwort an.";
"Signal" = "Signal";
"Similarity Threshold" = "Ähnlichkeitsschwelle";
"Simple" = "Einfach";
"Smooth loops and phrase echo by balancing repetition controls." = "Glätten Sie Loops und Phrasen-Echos durch ausgewogene Wiederholungskontrollen.";
"Smooth loops and repeated phrases by tuning repetition controls." = "Glätten Sie Loops und wiederholte Phrasen durch Anpassen der Wiederholungssteuerung.";
"Some models do not provide the system prompts needed for Noema to detect and configure them properly. These models may be unusable until they include appropriate metadata or support." = "Einige Modelle bieten nicht die Systemaufforderungen, die Noema benötigt, um sie richtig zu erkennen und zu konfigurieren. Diese Modelle sind möglicherweise unbrauchbar, bis sie entsprechende Metadaten oder Unterstützung enthalten.";
"Source unavailable. Check storage or network settings." = "Quelle nicht verfügbar. Überprüfen Sie die Speicher- oder Netzwerkeinstellungen.";
"Source: %@" = "Quelle: %@";
"Specify identifiers for models that are not listed by the server. Leave blank to rely on the server's catalog." = "Geben Sie Bezeichner für Modelle an, die nicht vom Server aufgeführt sind. Lassen Sie das Feld leer, um sich auf den Katalog des Servers zu verlassen.";
"Specify your model identifiers, or reload your custom models later." = "Geben Sie Ihre Modellkennungen an oder laden Sie Ihre benutzerdefinierten Modelle später neu.";
"Speed up with a smaller helper model." = "Beschleunigen Sie mit einem kleineren Hilfsmodell.";
"Start by installing one model. Then add a dataset (like an open textbook) so the AI can answer with grounded knowledge." = "Beginnen Sie mit der Installation eines Modells. Fügen Sie dann einen Datensatz hinzu (z. B. ein offenes Lehrbuch), damit die KI mit fundiertem Wissen antworten kann.";
"Start the relay to automatically share the latest payload with nearby devices." = "Starten Sie das Relay, um die neueste Nutzlast automatisch mit Geräten in der Nähe zu teilen.";
"Start with a reliable Qwen 3 1.7B build. It balances capability with small download size." = "Beginnen Sie mit einem zuverlässigen Qwen 3 1.7B-Build. Es vereint Leistungsfähigkeit mit geringer Downloadgröße.";
"Startup defaults now live in Settings → Startup. Favorite models here to keep them handy." = "Die Standardeinstellungen für den Start sind jetzt unter „Einstellungen“ → „Start“ verfügbar. Hier finden Sie Lieblingsmodelle, damit Sie sie immer griffbereit haben.";
"Status" = "Status";
"Stay close to your Mac" = "Bleiben Sie in der Nähe Ihres Mac";
"Stop Using Dataset" = "Beenden Sie die Verwendung des Datensatzes";
"Streaming" = "Streaming";
"Streaming response…" = "Streaming-Antwort…";
"Supported Endpoints" = "Unterstützte Endpunkte";
"Supported formats: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV" = "Unterstützte Formate: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV";
"Swap between the new stacked chat panel and the classic tab bar layout." = "Wechseln Sie zwischen dem neuen gestapelten Chat-Panel und dem klassischen Tab-Leisten-Layout.";
"Swipe left to remove the embedding model from this device." = "Wischen Sie nach links, um das Einbettungsmodell von diesem Gerät zu entfernen.";
"Switch the selector to MLX for Apple Silicon‑optimized builds that excel at speed." = "Schalten Sie den Wahlschalter auf MLX für Apple Silicon-optimierte Builds, die sich durch Geschwindigkeit auszeichnen.";
"Switch to Raw to inspect the original response." = "Wechseln Sie zu Raw, um die ursprüngliche Antwort zu überprüfen.";
"System" = "System";
"Tap to load" = "Zum Laden tippen";
"Temperature" = "Temperatur";
"Testing" = "Testen";
"The app memory usage budget is an estimate based on your device's total RAM and typical iOS memory management. The actual available memory may vary depending on system load, other running apps, and iOS memory pressure. Models that exceed this budget may cause the app to be terminated by iOS." = "Das Budget für die App-Speichernutzung ist eine Schätzung, die auf dem gesamten RAM Ihres Geräts und der typischen iOS-Speicherverwaltung basiert. Der tatsächlich verfügbare Speicher kann je nach Systemauslastung, anderen laufenden Apps und iOS-Speicherauslastung variieren. Modelle, die dieses Budget überschreiten, können dazu führen, dass die App von iOS beendet wird.";
"The embedding model is installed. Delete it to free ~320 MB." = "Das Einbettungsmodell ist installiert. Löschen Sie es, um ca. 320 MB freizugeben.";
"The relay listens to the %@ container for new conversations and responds with your selected provider." = "Das Relay lauscht dem %@-Container auf neue Konversationen und antwortet mit Ihrem ausgewählten Anbieter.";
"The tool returned data that can't be formatted. Switch to Raw to inspect the original response." = "Das Tool hat Daten zurückgegeben, die nicht formatiert werden können. Wechseln Sie zu Raw, um die ursprüngliche Antwort zu überprüfen.";
"These options stay in simple mode for clarity. Let’s cover the essentials." = "Aus Gründen der Übersichtlichkeit bleiben diese Optionen im einfachen Modus. Lassen Sie uns das Wesentliche behandeln.";
"Think of Noema as a simple way to run AI on your device. To get useful answers, you pair a local model with datasets (like open textbooks). We’ll guide you through the first setup." = "Stellen Sie sich Noema als eine einfache Möglichkeit vor, KI auf Ihrem Gerät auszuführen. Um nützliche Antworten zu erhalten, koppeln Sie ein lokales Modell mit Datensätzen (z. B. offenen Lehrbüchern). Wir führen Sie durch die erste Einrichtung.";
"This app bundles llama.cpp; we keep this in sync with upstream b‑releases." = "Diese App bündelt llama.cpp; Wir halten dies mit den Upstream-B-Releases synchron.";
"This backend is unavailable. Remove it or pick another option." = "Dieses Backend ist nicht verfügbar. Entfernen Sie es oder wählen Sie eine andere Option.";
"This chat stays private—responses are generated on your device after you load a model." = "Dieser Chat bleibt privat – Antworten werden auf Ihrem Gerät generiert, nachdem Sie ein Modell geladen haben.";
"This configuration exceeds the current RAM safety guard, so benchmarking is disabled." = "Diese Konfiguration überschreitet den aktuellen RAM-Sicherheitsschutz, daher ist das Benchmarking deaktiviert.";
"This dataset is taking a while to load, still working…" = "Das Laden dieses Datensatzes dauert eine Weile, funktioniert aber noch ...";
"This dataset's files are not currently supported for document retrieval." = "Die Dateien dieses Datensatzes werden derzeit nicht für den Dokumentenabruf unterstützt.";
"This device doesn't support GPU offload." = "Dieses Gerät unterstützt kein GPU-Offload.";
"This device doesn't support GPU offload; GGUF models will run on the CPU and generation speed will be significantly slower." = "Dieses Gerät unterstützt kein GPU-Offload. GGUF-Modelle werden auf der CPU ausgeführt und die Generierungsgeschwindigkeit wird deutlich langsamer sein.";
"This model doesn't support GPU offload and generation speed will be significantly slower. Consider switching to an MLX model." = "Dieses Modell unterstützt kein GPU-Offload und die Generierungsgeschwindigkeit wird deutlich langsamer sein. Erwägen Sie den Wechsel zu einem MLX-Modell.";
"This model doesn't support GPU offload and generation speed will be significantly slower. Fastest option on this device: use an SLM (Leap) model." = "Dieses Modell unterstützt kein GPU-Offload und die Generierungsgeschwindigkeit wird deutlich langsamer sein. Schnellste Option auf diesem Gerät: Verwenden Sie ein SLM-Modell (Leap).";
"This model doesn't support GPU offload and may run slowly. Consider an MLX model." = "Dieses Modell unterstützt kein GPU-Offload und läuft möglicherweise langsam. Betrachten Sie ein MLX-Modell.";
"This model doesn't support GPU offload and may run slowly. Fastest option: use an SLM model." = "Dieses Modell unterstützt kein GPU-Offload und läuft möglicherweise langsam. Schnellste Option: Verwenden Sie ein SLM-Modell.";
"This permanently removes every chat conversation. This action cannot be undone." = "Dadurch wird jede Chat-Konversation dauerhaft entfernt. Diese Aktion kann nicht rückgängig gemacht werden.";
"This textbook appears to be available only as a web page. Noema can't import it as a dataset." = "Dieses Lehrbuch scheint nur als Webseite verfügbar zu sein. Noema kann es nicht als Datensatz importieren.";
"Tool calling isn't perfect. Although Noema implements many methods of detecting and instructing models to use tools, not all LLMs will follow instructions and some might not call them correctly or at all. Tool calling heavily depends on model pre-training and will get better as time passes." = "Der Werkzeugaufruf ist nicht perfekt. Obwohl Noema viele Methoden zum Erkennen und Anweisen von Modellen zur Verwendung von Werkzeugen implementiert, folgen nicht alle LLMs den Anweisungen und einige rufen sie möglicherweise nicht richtig oder überhaupt nicht auf. Der Werkzeugaufruf hängt stark von der Vorschulung des Modells ab und wird mit der Zeit besser.";
"Tools" = "Werkzeuge";
"Top-k: %@" = "Top-k: %@";
"Top-p" = "Top-p";
"Top-p: %@" = "Top-p: %@";
"Try again" = "Versuchen Sie es erneut";
"Try another dataset if these formats aren't available." = "Versuchen Sie es mit einem anderen Datensatz, wenn diese Formate nicht verfügbar sind.";
"Try the Qwen 3 1.7B GGUF (Q3_K_M) build below. It's a good starting point and you can delete it anytime." = "Probieren Sie den folgenden Build Qwen 3 1.7B GGUF (Q3_K_M) aus. Es ist ein guter Ausgangspunkt und Sie können es jederzeit löschen.";
"Unable to load image" = "Bild kann nicht geladen werden";
"Unknown error" = "Unbekannter Fehler";
"Updates every second" = "Aktualisiert jede Sekunde";
"Use" = "Verwenden";
"Use Dataset" = "Verwenden Sie den Datensatz";
"Use this switch to flip between finding models or datasets." = "Verwenden Sie diesen Schalter, um zwischen der Suche nach Modellen oder Datensätzen zu wechseln.";
"Using %@" = "Verwenden von %@";
"Using %@ of %@ budget" = "Verwendung von %1$@ von %2$@ Budget";
"Using more than %@ significantly increases RAM usage." = "Die Verwendung von mehr als %@ erhöht die RAM-Nutzung erheblich.";
"Using server catalog" = "Verwenden des Serverkatalogs";
"V Cache Quant" = "V Cache Quant";
"Vendor recommendation: %@" = "Anbieterempfehlung: %@";
"Version" = "Version";
"Version %@" = "Version %@";
"Version 1.4" = "Version 1.4";
"Vision models require a companion projector (.mmproj). Noema will fetch it automatically the next time you download this model." = "Vision-Modelle erfordern einen Begleitprojektor (.mmproj). Noema ruft es automatisch ab, wenn Sie dieses Modell das nächste Mal herunterladen.";
"Wait for the response in your other chat to finish before sending a new message." = "Warten Sie, bis die Antwort in Ihrem anderen Chat abgeschlossen ist, bevor Sie eine neue Nachricht senden.";
"Waiting for tool response…" = "Warten auf Antwort des Tools…";
"We'll extract text and prepare embeddings. You can also start later from the dataset details." = "Wir extrahieren Text und bereiten Einbettungen vor. Sie können auch später mit den Datensatzdetails beginnen.";
"We'll route new conversations through %@ even if Wi‑Fi names differ. You can switch back by reloading the backend." = "Wir leiten neue Konversationen über %@ weiter, auch wenn sich die WLAN-Namen unterscheiden. Sie können zurückwechseln, indem Sie das Backend neu laden.";
"We'll try remote models in priority order for this long before moving to the next option." = "Wir werden Remote-Modelle so lange in der Reihenfolge ihrer Priorität ausprobieren, bevor wir zur nächsten Option übergehen.";
"We'll try this saved identifier even though it's not in the latest catalog." = "Wir werden diese gespeicherte Kennung ausprobieren, auch wenn sie nicht im neuesten Katalog enthalten ist.";
"Web Search Tool Calls" = "Aufrufe von Web-Suchtools";
"Web Search button" = "Schaltfläche „Websuche“.";
"Web search is included" = "Die Websuche ist enthalten";
"Weights" = "Gewichte";
"Welcome to Noema" = "Willkommen bei Noema";
"Welcome to Noema for Mac" = "Willkommen bei Noema für Mac";
"What is Noema?" = "Was ist Noema?";
"When connecting from another device, point the base URL to your computer (for example http://192.168.0.10:11434) and start Ollama with `OLLAMA_HOST=0.0.0.0` so it accepts remote clients." = "Wenn Sie eine Verbindung von einem anderen Gerät herstellen, verweisen Sie auf die Basis-URL auf Ihren Computer (zum Beispiel http://192.168.0.10:11434) und starten Sie Ollama mit „OLLAMA_HOST=0.0.0.0“, damit es Remote-Clients akzeptiert.";
"When enabled, pressing eject on iOS tells this Mac to unload the active relay model." = "Wenn diese Option aktiviert ist, wird dieser Mac durch Drücken von „Auswerfen“ auf iOS angewiesen, das aktive Relaismodell zu entladen.";
"When enabled, you will be asked to choose parameters every time a model loads." = "Wenn diese Option aktiviert ist, werden Sie jedes Mal, wenn ein Modell geladen wird, aufgefordert, Parameter auszuwählen.";
"Wi-Fi: %@" = "WLAN: %@";
"Working set estimate (%@): %@ @ %@ tokens" = "Schätzung des Arbeitssatzes (%1$@): %2$@ @ %3$@ Token";
"Write prompts, instructions, or notes here. Press return to add new lines." = "Schreiben Sie hier Aufforderungen, Anweisungen oder Notizen. Drücken Sie die Eingabetaste, um neue Zeilen hinzuzufügen.";
"You can keep chatting while indexing finishes" = "Sie können weiter chatten, während die Indizierung abgeschlossen ist";
"You can only favorite up to three models." = "Sie können nur bis zu drei Modelle zu Ihren Favoriten hinzufügen.";
"You can restart this process in the dataset settings any time." = "Sie können diesen Vorgang jederzeit in den Datensatzeinstellungen neu starten.";
"You're in Off-Grid mode. The Explore tab is hidden and all network features are disabled. You can only use downloaded models and datasets." = "Sie befinden sich im Off-Grid-Modus. Die Registerkarte „Erkunden“ ist ausgeblendet und alle Netzwerkfunktionen sind deaktiviert. Sie können nur heruntergeladene Modelle und Datensätze verwenden.";
"Your Datasets" = "Ihre Datensätze";
"Your Models" = "Ihre Modelle";
"Your private AI workspace" = "Ihr privater KI-Arbeitsbereich";
"You’re ready to explore. Download models, add datasets, and start chatting." = "Sie sind bereit für die Erkundung. Laden Sie Modelle herunter, fügen Sie Datensätze hinzu und beginnen Sie mit dem Chatten.";
"minutes" = "Minuten";
"•" = "";
"• Close other applications to free up RAM" = "• Schließen Sie andere Anwendungen, um RAM freizugeben";
"• Embedding happens locally on your device" = "• Die Einbettung erfolgt lokal auf Ihrem Gerät";
"• Larger datasets take exponentially more time" = "• Größere Datensätze benötigen exponentiell mehr Zeit";
"• You can pause and resume downloads if needed" = "• Sie können Downloads bei Bedarf anhalten und fortsetzen";
"…and %@ more parameter%@" = "…und %1$@ weitere Parameter%2$@";
"⚠️ " = "";
"General" = "Allgemein";

"Privacy" = "Datenschutz";

"About" = "Über";

"About & Support" = "Über & Support";

"Network" = "Netzwerk";

"Embedding Model" = "Embedding-Modell";

"Retrieval" = "Abruf";

"Early Testers" = "Frühe Tester";

"Build Info" = "Build-Informationen";

"Settings" = "Einstellungen";

"Language" = "Sprache";
"Startup" = "Start";
"Search models" = "Modelle suchen";
"SLM Models - Liquid AI" = "SLM Models - Liquid AI";
"Import" = "Importieren";
"Import GGUF" = "GGUF importieren";
"Import MLX" = "MLX importieren";
"Import Failed" = "Import fehlgeschlagen";
"Switching between GGUF/MLX modes" = "Zwischen GGUF/MLX-Modi wechseln";
"Switching between GGUF/SLM modes" = "Zwischen GGUF/SLM-Modi wechseln";
"Vision-capable model" = "Vision-fähiges Modell";
"All" = "Alle";
"Text" = "Text";
"Vision" = "Vision";
"Continue" = "Fortfahren";
"Try bullet" = "Versuchen Sie:\n• Andere Schlüsselwörter (z. B. „gemma-3“ statt „gemma 3“)\n• %@\n• Text-/Vision-Filter anpassen\n• Suchfilter prüfen";
"Select one or more .gguf files. For vision models, also select the projector .gguf (files containing ‘mmproj’ or ‘projector’). Files will be copied into your local model library." = "Select one or more .gguf files. For vision models, also select the projector .gguf (files containing ‘mmproj’ or ‘projector’). Files will be copied into your local model library.";
"Select the model folder that contains config.json and the weights (safetensors/npz). The entire folder will be imported into your local model library." = "Select the model folder that contains config.json and the weights (safetensors/npz). The entire folder will be imported into your local model library.";
"K Cache Quantization" = "K-Cache-Quantisierung";
"V Cache Quantization" = "V-Cache-Quantisierung";
"Favorite Limit Reached" = "Favoritenlimit erreicht";
"Overview" = "Übersicht";
"Sampling" = "Sampling";
"Speculative Decoding" = "Spekulatives Decoding";
"Benchmark" = "Benchmark";
"Maintenance" = "Wartung";
"MLX" = "MLX";
"Tokenizer Path (tokenizer.json)" = "Tokenizer-Pfad (tokenizer.json)";
"Back" = "Zurück";
"Favorite Model" = "Bevorzugtes Modell";
"Reset to Default Settings" = "Auf Standardeinstellungen zurücksetzen";
"Delete Model" = "Modell löschen";
"Delete %@?" = "%@ löschen?";
"Not provided by repository" = "Nicht vom Repository bereitgestellt";
"Unknown (not checked yet)" = "Unbekannt (noch nicht geprüft)";
"Keep Model In Memory" = "Modell im Speicher behalten";
"GPU Offload Layers: %@/%@" = "GPU-Offload-Ebenen: %1$@/%2$@";
"CPU Threads: %@" = "CPU-Threads: %@";
"Offload KV Cache to GPU" = "KV-Cache auf GPU auslagern";
"Use mmap()" = "mmap() verwenden";
"Random" = "Zufällig";
"Flash Attention" = "Flash Attention";
"1 expert" = "1 Experte";
"%@ experts" = "%@ Experten";
"Helper Model" = "Hilfsmodell";
"Draft strategy" = "Entwurfsstrategie";
"Run Benchmark" = "Benchmark starten";
"Benchmarking…" = "Benchmark läuft…";
"Leap SLM models manage runtime optimizations automatically." = "Leap-SLM-Modelle verwalten Laufzeitoptimierungen automatisch.";
"This format doesn't expose tunable runtime optimizations." = "Dieses Format bietet keine anpassbaren Laufzeitoptimierungen.";
"Token processing" = "Token-Verarbeitung";
"Token generation" = "Token-Generierung";
"Total time" = "Gesamtzeit";
"First token" = "Erstes Token";
"Peak memory" = "Spitzenspeicher";
"Output tokens" = "Ausgabe-Token";
"End Guide" = "Anleitung beenden";
"Streaming benchmark output…" = "Benchmark-Ausgabe wird gestreamt…";
"Streaming… %@ chunks (~%@ tok est.)" = "Streaming… %1$@ Blöcke (~%2$@ Token geschätzt)";
"Streaming… %d chunks (~%d tok est.)" = "Streaming… %d Blöcke (~%d Token geschätzt)";
"The selected model's weights could not be located." = "Die Gewichte des ausgewählten Modells wurden nicht gefunden.";
"Failed to load model for benchmark: %@" = "Modell für Benchmark konnte nicht geladen werden: %@";
"Benchmark generation failed: %@" = "Benchmark-Generierung fehlgeschlagen: %@";
"K Cache" = "K-Cache";
"V Cache" = "V-Cache";
"KV Offload" = "KV-Offload";
"On" = "Ein";
"Off" = "Aus";
"GPU" = "GPU";
"CPU" = "CPU";
"%.1f tok/s" = "%.1f Tok/s";
"%.1fs" = "%.1fs";
"%.2fs" = "%.2fs";
"Move Up" = "Nach oben verschieben";
"Move Down" = "Nach unten verschieben";
"Remove" = "Entfernen";
"Startup remote options" = "Remote-Startoptionen";
"No models cached yet. Open the backend to refresh its catalog." = "Noch keine Modelle im Cache. Öffne das Backend, um den Katalog zu aktualisieren.";
"We'll try this saved identifier even though it's not in the latest catalog." = "Wir versuchen diesen gespeicherten Bezeichner, auch wenn er nicht im neuesten Katalog ist.";
"This backend is unavailable. Remove it or pick another option." = "Dieses Backend ist nicht verfügbar. Entferne es oder wähle eine andere Option.";
"Backend removed" = "Backend entfernt";
"What is Max Chunks?" = "Was bedeutet Max Chunks?";
"What is Similarity Threshold?" = "Was ist der Ähnlichkeitsschwellenwert?";
"Approx. %@" = "Ca. %@";
"Advanced mode shows developer options and diagnostics." = "Der erweiterte Modus zeigt Entwickleroptionen und Diagnosen.";
"Simple mode hides advanced settings for a cleaner interface." = "Der einfache Modus blendet erweiterte Einstellungen aus für eine übersichtlichere Oberfläche.";
"Hide advanced controls" = "Erweiterte Steuerungen ausblenden";
"Show advanced controls" = "Erweiterte Steuerungen anzeigen";
"Adjust model settings" = "Modelleinstellungen anpassen";
"Model Settings" = "Modelleinstellungen";
"SLM models are not supported on this platform." = "SLM-Modelle werden auf dieser Plattform nicht unterstützt.";
"Model likely exceeds memory budget. Lower context or choose a smaller quant." = "Das Modell überschreitet wahrscheinlich das Speicherbudget. Verringere den Kontext oder wähle eine kleinere Quantisierung.";
"Apple bundle models aren't supported on macOS yet." = "Apple-Bundle-Modelle werden auf macOS noch nicht unterstützt.";
"Estimate: %@\nBudget: %@\nContext length: %@ tokens\n\nThis is an estimate based on your device’s memory budget, context length (KV cache), and typical runtime overheads. Actual usage may vary." = "Schätzung: %@\nBudget: %@\nKontextlänge: %@ Tokens\n\nDies ist eine Schätzung basierend auf dem Speicherbudget deines Geräts, der Kontextlänge (KV-Cache) und typischen Laufzeit-Overheads. Der tatsächliche Verbrauch kann abweichen.";
"Model likely fits in RAM" = "Modell passt voraussichtlich in den RAM";
"Model may not fit in RAM" = "Modell passt möglicherweise nicht in den RAM";
"Fits in RAM (estimated)" = "Passt in den RAM (geschätzt)";
"May not fit (estimated)" = "Passt eventuell nicht (geschätzt)";
"Please provide a backend name." = "Bitte einen Backend-Namen angeben.";
"A backend with this name already exists." = "Ein Backend mit diesem Namen existiert bereits.";
"Backend not found." = "Backend nicht gefunden.";
"This Noema Relay device is already configured." = "Dieses Noema-Relay-Gerät ist bereits konfiguriert.";
"OpenAI API" = "OpenAI API";
"LM Studio" = "LM Studio";
"Ollama" = "Ollama";
"Cloud Relay" = "Cloud Relay";
"Noema Relay" = "Noema Relay";
"Compatible with OpenAI-style /v1 endpoints" = "Kompatibel mit OpenAI-/v1-Endpunkten";
"Connect to LM Studio's REST server" = "Verbinde dich mit dem REST-Server von LM Studio";
"Target an Ollama host for chat and pulls" = "Ollama-Host für Chat und Downloads ansteuern";
"Use Noema's Cloud Relay on macOS" = "Noemas Cloud Relay unter macOS verwenden";
"Pair with your Mac over CloudKit" = "Mit deinem Mac über CloudKit koppeln";
"Please provide the CloudKit container identifier." = "Bitte den CloudKit-Container-Bezeichner angeben.";
"Please provide the host device ID from the Mac relay." = "Bitte die Hostgeräte-ID des Mac-Relays angeben.";
"Missing host device ID for Noema Relay." = "Fehlende Hostgeräte-ID für Noema Relay.";
"Missing CloudKit container identifier." = "CloudKit-Container-Bezeichner fehlt.";
"Relay catalog unavailable." = "Relay-Katalog nicht verfügbar.";
"Relay catalog is still syncing. Open the Mac relay, ensure it is signed into iCloud, then try again in a moment." = "Der Relay-Katalog wird noch synchronisiert. Öffne das Relay auf dem Mac, prüfe die iCloud-Anmeldung und versuche es erneut.";
"Terms of Use" = "Nutzungsbedingungen";
"Privacy Policy" = "Datenschutzerklärung";
"Contact Support" = "Support kontaktieren";
"Write a Review" = "Bewertung schreiben";
"Notes & Issues" = "Hinweise & Probleme";
"Qwen3-1.7B is a compact and efficient model from the Qwen3 family, suitable for on-device usage with strong general capabilities." = "Qwen3-1.7B ist ein kompaktes, effizientes Modell der Qwen3-Familie, geeignet für On-Device-Einsatz mit starken Allround-Fähigkeiten.";
"Gemma 3n E2B is a lightweight instruction-tuned model from Google's Gemma family, optimized for efficient on-device conversations." = "Gemma 3n E2B ist ein leichtes, instruktionfeinabgestimmtes Modell aus Googles Gemma-Familie, optimiert für effiziente lokale Konversationen.";
"Gemma 3n E2B is an instruction-tuned variant of Google's Gemma family built for efficient reasoning on low-resource devices.\nAvailable in GGUF quants (Q3_K_M, Q4_K_M, Q6_K) and an MLX 4-bit build for Apple Silicon.\n" = "Gemma 3n E2B ist eine instruktion‑abgestimmte Variante der Gemma-Familie, entwickelt für effizientes Reasoning auf ressourcenarmen Geräten.\nVerfügbar in GGUF-Quants (Q3_K_M, Q4_K_M, Q6_K) sowie als MLX-4‑Bit-Build für Apple Silicon.\n";
"Phi-4 Mini Reasoning is a lightweight model from the Phi-4 family, tuned for strong reasoning and efficiency across tasks." = "Phi-4 Mini Reasoning ist ein leichtes Modell der Phi-4-Familie, optimiert für starkes Reasoning und Effizienz in vielen Aufgaben.";
"Phi-4 Mini Reasoning — a compact model in Microsoft’s Phi-4 line designed for logical reasoning, problem solving, and instruction-following. \nDistributed in efficient GGUF quants (Q3_K_L, Q4_K_M, Q6_K) and an MLX 4-bit variant for Apple Silicon devices.\n" = "Phi-4 Mini Reasoning – ein kompaktes Modell aus Microsofts Phi-4-Reihe, ausgelegt für logisches Denken, Problemlösung und Befolgen von Anweisungen.\nBereitgestellt in effizienten GGUF-Quants (Q3_K_L, Q4_K_M, Q6_K) sowie einer MLX-4‑Bit-Variante für Apple-Silicon-Geräte.\n";
"Runtime Safety" = "Laufzeitsicherheit";
"Bypass RAM safety check (may cause crashes)" = "RAM-Sicherheitsprüfung umgehen (kann Abstürze verursachen)";
"Estimate for" = "Schätzung für";
"Off-grid Mode" = "Offline-Modus";
"Delete All Chats" = "Alle Chats löschen";
"Reset App Data" = "App-Daten zurücksetzen";
"Max Chunks" = "Max. Chunks";
"Delete Embedding Model" = "Embedding-Modell löschen";
"Override the app language. Defaults to the device language on first launch." = "App-Sprache überschreiben. Standardmäßig wird beim ersten Start die Gerätesprache verwendet.";
"Swap between the new stacked chat panel and the classic tab bar layout." = "Zwischen dem neuen gestapelten Chat-Bereich und der klassischen Tab-Leiste wechseln.";
"Available Quantizations" = "Verfügbare Quantisierungen";
"Sort quantizations" = "Quantisierungen sortieren";
"Quant" = "Quant";
"Size ↑" = "Größe ↑";
"Size ↓" = "Größe ↓";
"Model Library" = "Modellbibliothek";
"Type to filter models…" = "Tippe, um Modelle zu filtern…";
"No models match your search." = "Keine Modelle entsprechen deiner Suche.";
"Browse Explore tab" = "Explore-Tab öffnen";
"Manually choose parameters" = "Parameter manuell auswählen";
"The base URL looks invalid. Please include the host (e.g. http://127.0.0.1:1234)." = "Die Basis-URL scheint ungültig zu sein. Bitte den Host angeben (z. B. http://127.0.0.1:1234).";
"Could not build the remote endpoint URL." = "Remote-Endpunkt-URL konnte nicht erstellt werden.";
"The server returned an unexpected response." = "Der Server hat eine unerwartete Antwort zurückgegeben.";
"Server responded with status code %d." = "Server antwortete mit Statuscode %d.";
"Server responded with status code %d: %@" = "Server antwortete mit Statuscode %1$d: %2$@";
"Failed to decode server response." = "Serverantwort konnte nicht dekodiert werden.";

"Explore" = "Entdecken";
"Search datasets" = "Datensätze durchsuchen";
"Download" = "Herunterladen";
"Offline" = "Offline";
"Tap to load" = "Tippen zum Laden";
"%d models" = "%d Modelle";
"Updated %@" = "Aktualisiert %@";
"No models fetched yet" = "Noch keine Modelle abgerufen";
"Auth" = "Auth";
"Local Network" = "Lokales Netzwerk";
"Direct" = "Direkt";
"LAN" = "LAN";
"LAN · %@" = "LAN · %@";
"Backend" = "Backend";
"Base URL" = "Basis-URL";
"Chat Path" = "Chat-Pfad";
"Models Path" = "Modelle-Pfad";
"Endpoint Type" = "Endpunkttyp";
"Endpoints" = "Endpunkte";
"Authentication" = "Authentifizierung";
"Model Identifiers" = "Modellkennungen";
"Name" = "Name";
"Host device ID" = "Host-Geräte-ID";
"Host Device ID" = "Host-Geräte-ID";
"CloudKit container identifier" = "CloudKit-Container-ID";
"Field requirements will depend on your specific backend deployment." = "Feldanforderungen hängen von deiner Backend-Bereitstellung ab.";
"Uses Noema Relay configuration" = "Verwendet Noema Relay-Konfiguration";
"Chat: %@\nModels: %@" = "Chat: %@\nModelle: %@";
"Download Dataset" = "Datensatz herunterladen";
"No files listed for this dataset." = "Für diesen Datensatz sind keine Dateien aufgeführt.";
"This dataset's files are not currently supported for document retrieval." = "Die Dateien dieses Datensatzes werden derzeit nicht für die Dokumentenabfrage unterstützt.";
"Supported formats: %@" = "Unterstützte Formate: %@";
"Try another dataset if these formats aren't available." = "Probieren Sie einen anderen Datensatz, wenn diese Formate nicht verfügbar sind.";
"Found unsupported: %@ …" = "Nicht unterstützt gefunden: %@ …";
"This textbook appears to be available only as a web page. Noema can't import it as a dataset." = "Dieses Lehrbuch scheint nur als Webseite verfügbar zu sein. Noema kann es nicht als Datensatz importieren.";
"Download complete" = "Download abgeschlossen";
"Downloading…" = "Wird geladen…";
"No compatible files found for retrieval. Supported formats: %@" = "Keine kompatiblen Dateien für die Abfrage gefunden. Unterstützte Formate: %@";
"No internet connection." = "Keine Internetverbindung.";
"Request timed out. Please try again." = "Zeitüberschreitung der Anfrage. Bitte erneut versuchen.";
"Connection was lost. Please try again." = "Verbindung wurde getrennt. Bitte erneut versuchen.";
"Unexpected error: %@" = "Unerwarteter Fehler: %@";

"Downloaded" = "Heruntergeladen";
"Compressed Text" = "Komprimierter Text";
"Small" = "Klein";
"Medium" = "Mittel";
"Large" = "Groß";
"Very Large" = "Sehr groß";
"Extreme" = "Extrem";
"Under 10 MB" = "Unter 10 MB";
"10–50 MB" = "10–50 MB";
"50–200 MB" = "50–200 MB";
"200–500 MB" = "200–500 MB";
"Over 500 MB" = "Über 500 MB";
"Estimated Embedding Time" = "Geschätzte Einbettungszeit";
"Peak RAM Usage" = "Maximale RAM-Nutzung";
"Dataset Size" = "Datensatzgröße";
"Performance Note" = "Hinweis zur Leistung";
"Recommendation" = "Empfehlung";
"Remember:" = "Merke dir:";
"• Close other applications to free up RAM" = "• Schließe andere Anwendungen, um RAM freizugeben";
"• Embedding happens locally on your device" = "• Die Einbettung erfolgt lokal auf deinem Gerät";
"• Larger datasets take exponentially more time" = "• Größere Datensätze benötigen exponentiell mehr Zeit";
"• You can pause and resume downloads if needed" = "• Du kannst Downloads bei Bedarf pausieren und fortsetzen";
"Dataset Requirements" = "Datensatzanforderungen";
"Got it" = "Verstanden";
"Check Requirements" = "Anforderungen prüfen";
"< 1 minute" = "Weniger als 1 Minute";
"%d minutes" = "%d Minuten";
"This dataset should embed quickly with minimal resource usage. Perfect for testing and quick experiments." = "Dieser Datensatz sollte sich schnell mit minimalem Ressourcenbedarf einbetten lassen. Ideal für Tests und schnelle Experimente.";
"This dataset is a reasonable size for most systems. Embedding should complete in a few minutes." = "Dieser Datensatz hat eine vernünftige Größe für die meisten Systeme. Die Einbettung sollte in wenigen Minuten abgeschlossen sein.";
"This is a substantial dataset. Ensure you have adequate RAM and expect embedding to take 10–30 minutes." = "Dies ist ein umfangreicher Datensatz. Stelle ausreichend RAM sicher und rechne mit 10–30 Minuten Einbettungszeit.";
"This is a very large dataset. Embedding may take 30–60 minutes and requires significant RAM." = "Dies ist ein sehr großer Datensatz. Die Einbettung kann 30–60 Minuten dauern und benötigt viel RAM.";
"This is an extremely large dataset. Consider splitting it into smaller parts for better performance." = "Dies ist ein extrem großer Datensatz. Erwäge, ihn für bessere Leistung in kleinere Teile aufzuteilen.";
"Go ahead and download! This size works well on all systems." = "Lade ruhig herunter! Diese Größe funktioniert auf allen Systemen gut.";
"Recommended for most users. Make sure you have at least 4GB of free RAM." = "Für die meisten Nutzer empfohlen. Stelle mindestens 4 GB freien RAM sicher.";
"Recommended only if you have 8GB+ RAM available. Close other applications before embedding." = "Nur empfohlen, wenn 8 GB oder mehr RAM verfügbar sind. Schließe andere Anwendungen vor der Einbettung.";
"Recommended only for systems with 16GB+ RAM. Consider processing during off-hours." = "Nur für Systeme mit 16 GB oder mehr RAM empfohlen. Erwäge die Verarbeitung außerhalb der Arbeitszeit.";
"Not recommended for typical systems. Consider finding a smaller version or subset of this dataset." = "Für typische Systeme nicht empfohlen. Suche nach einer kleineren Version oder Teilmenge dieses Datensatzes.";
"Sample dataset" = "Beispieldatensatz";
"Ready" = "Bereit";
"Open" = "Öffnen";

"Model doesn't support GPU offload" = "Modell unterstützt kein GPU-Offloading";
"Loading model…" = "Modell wird geladen…";
"Select a model to load" = "Wähle ein Modell zum Laden";
"Please wait" = "Bitte warten";
"Models Library" = "Modellbibliothek";
"Sort" = "Sortieren";
"Recency" = "Neueste";
"Size" = "Größe";
"Name" = "Name";
"Load Failed" = "Laden fehlgeschlagen";
"Don't show again" = "Nicht mehr anzeigen";

/* Noema Relay – pairing & dataset helpers */
"Model file missing (.gguf)" = "Modelldatei fehlt (.gguf)";
"Model path missing" = "Modellpfad fehlt";
"Imported Dataset" = "Importierter Datensatz";
"Dataset name" = "Name des Datensatzes";
"Keep this device near the Mac that's running Noema Relay to import its settings." = "Halte dieses Gerät in der Nähe des Macs, auf dem Noema Relay läuft, um dessen Einstellungen zu importieren.";
"Scanning for your Mac relay…" = "Suche nach deinem Mac‑Relay…";
"Ready to scan nearby relays" = "Bereit, nach Relays in der Nähe zu suchen";
"Bluetooth access is required to pair with the Mac relay." = "Bluetooth‑Zugriff ist erforderlich, um eine Verbindung mit dem Mac‑Relay herzustellen.";
"Stop Scanning" = "Suche beenden";
"Start Scan" = "Suche starten";
"Connection verified. Relay details imported from this Mac." = "Verbindung bestätigt. Relaisdetails von diesem Mac importiert.";
"Signal strength unavailable" = "Signalstärke nicht verfügbar";
"Very close" = "Sehr nah";
"Nearby" = "In der Nähe";
"Within one room" = "Im selben Raum";
"Move closer for a stronger signal" = "Gehe näher heran, um ein stärkeres Signal zu erhalten.";
"This Mac" = "Dieser Mac";

/* Accessibility announcements */
"Model loaded." = "Modell geladen.";
"Prompt submitted." = "Prompt gesendet.";
"Generating response…" = "Antwort wird erstellt…";
"Response generated." = "Antwort erstellt.";

/* Tabs & accessibility labels */
"Stored" = "Gespeichert";
"Web Search" = "Websuche";
"Open Stored" = "Gespeichert öffnen";
"Message input" = "Nachrichteneingabe";
"What is Web Search button?" = "Was ist die Websuche-Schaltfläche?";

/* Mac chat quick-load menu */
"Open Model Library" = "Modellbibliothek öffnen";
"Favorites" = "Favoriten";
"Recent" = "Zuletzt verwendet";
