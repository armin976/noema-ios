/* Auto-generated localization file. */
"%@" = "%@";
"%@ %" = "%1$@ %2$";
"%@ %@" = "%1$@ %2$@";
"%@ models" = "%@ modele";
"%@ of %@ budget" = "%1$@ din %2$@ buget";
"%@ tokens" = "%@ jetoane";
"%@ – %@" = "%1$@ – %2$@";
"%@ • %@" = "%1$@ • %2$@";
"%@%" = "%1$@%2$";
"%@% · %@" = "%1$@%2$ · %3$@";
"%@." = "%@.";
"%@:" = "%@:";
"(+ mmproj %@%)" = "(+ mmproj %1$@%2$)";
"... and %@ more" = "... și încă %@";
"320 MB • One-time download" = "320 MB • Descărcare o singură dată";
"320 MB • One‑time download used for local dataset search" = "320 MB • Descărcare unică folosită pentru căutarea setului de date local";
"A larger context keeps more conversation history, but also uses more memory. Adjust it here." = "Un context mai mare păstrează mai mult istoric de conversație, dar folosește și mai multă memorie. Ajustează-l aici.";
"Active" = "Activ";
"Active Model" = "Model activ";
"Active connection via %@" = "Conexiune activă prin %@";
"Active experts per token: %@ of %@" = "Experți activi pe token: %1$@ din %2$@";
"Add a remote backend to configure remote startup fallbacks." = "Adăugați un backend la distanță pentru a configura alternativele de pornire de la distanță.";
"Add one or two datasets (like open textbooks) to keep responses accurate and help the AI cite sources." = "Adăugați unul sau două seturi de date (cum ar fi manualele deschise) pentru a menține răspunsurile exacte și pentru a ajuta AI să citeze sursele.";
"Add remote endpoint" = "Adaugă un endpoint la distanță";
"Adjust appearance, privacy options, and network preferences here." = "Ajustați aspectul, opțiunile de confidențialitate și preferințele de rețea aici.";
"Advanced" = "Avansat";
"Advanced Controls" = "Controale avansate";
"Allows models to use a privacy-preserving web search API when you tap the globe in chat. Default is ON. In Offline Only mode, the button is disabled." = "Permite modelelor să folosească un API de căutare web care păstrează confidențialitatea atunci când atingeți globul în chat. Implicit este ON. În modul Offline Only, butonul este dezactivat.";
"Analyzing context..." = "Se analizează contextul...";
"App Memory Usage (estimated)" = "Utilizarea memoriei aplicației (estimată)";
"App memory usage budget: %@ (conservative)" = "Bugetul de utilizare a memoriei aplicației: %@ (conservator)";
"Approx. Tokens" = "Aproximativ. Jetoane";
"Arm web search when you truly need outside info. It has a small daily limit and most chats don’t require it." = "Armați căutarea pe web atunci când aveți cu adevărat nevoie de informații externe. Are o limită zilnică mică și majoritatea chat-urilor nu o necesită.";
"Ask Noema anything" = "Întrebați-o pe Noema orice";
"Ask…" = "Întrebați…";
"Attach Photos" = "Atașați fotografii";
"Backend not found" = "Backend nu a fost găsit";
"Benchmark running…" = "Benchmark rulare...";
"Benchmarking is not available for this model format." = "Evaluarea comparativă nu este disponibilă pentru acest format de model.";
"Blocks all network traffic, model downloads, and cloud connections so everything stays on‑device." = "Blochează tot traficul de rețea, descărcările de modele și conexiunile la cloud, astfel încât totul să rămână pe dispozitiv.";
"Bluetooth Pairing" = "Asociere Bluetooth";
"Browse community models and curated datasets to expand what Noema can do." = "Răsfoiți modele de comunitate și seturi de date organizate pentru a extinde ceea ce poate face Noema.";
"Browse curated datasets for retrieval" = "Răsfoiți seturi de date selectate pentru a le regăsi";
"CFBundleShortVersionString1.0" = "CFBundleShortVersionString1.0";
"Cancel" = "Anulează";
"Cancel Benchmark" = "Anulează Benchmark";
"Discover Intelligence" = "Descoperă inteligența";
"Catalog" = "Catalog";
"Chat" = "Chat";
"Chat privately with your local models, sync datasets, and manage the relay server in one place." = "Conversați în privat cu modelele dvs. locale, sincronizați seturile de date și gestionați serverul de retransmisie într-un singur loc.";
"Chats" = "Chat-uri";
"Checking…" = "Control…";
"Citation %@" = "Citare %@";
"Cloud Relay Container" = "Container Cloud Relay";
"Cloud Relay via CloudKit (auto-discovery and Bluetooth pairing)" = "Cloud Relay prin CloudKit (descoperire automată și împerechere Bluetooth)";
"CloudKit" = "CloudKit";
"CloudKit bridge active. Local replies are generated on this Mac." = "Puntea CloudKit activă. Răspunsurile locale sunt generate pe acest Mac.";
"Compiling Metal kernels for GGUF models can take up to a minute on first load." = "Compilarea nucleelor ​​metalice pentru modelele GGUF poate dura până la un minut la prima încărcare.";
"Complete the streaming response in the active chat before sending again." = "Completați răspunsul în flux în chatul activ înainte de a trimite din nou.";
"Confirm and Start Embedding" = "Confirmați și începeți încorporarea";
"Connected" = "Conectat";
"Connection Modes" = "Moduri de conectare";
"Connection Status: %@" = "Starea conexiunii: %@";
"Container" = "Container";
"Context Length" = "Lungimea contextului";
"Context Length: 4096 tokens" = "Lungimea contextului: 4096 jetoane";
"Context length is under 5000 tokens. With images and multi-sequence decoding (n_seq_max=16), per-sequence memory can be too small, leading to a crash. Increase context to at least 8192 in Model Settings." = "Lungimea contextului este sub 5000 de jetoane. Cu imagini și decodare cu mai multe secvențe (n_seq_max=16), memoria pe secvență poate fi prea mică, ceea ce duce la o blocare. Măriți contextul la cel puțin 8192 în Setările modelului.";
"Controls how many high‑scoring passages (chunks) can be injected into the prompt. Higher values increase recall but consume more context window and can slow responses. Typical range 3–6." = "Controlează câte pasaje (bucăți) cu scoruri mari pot fi injectate în prompt. Valorile mai mari cresc reamintirea, dar consumă mai multă fereastră de context și pot încetini răspunsurile. Interval tipic 3-6.";
"Couldn't load the recommended model." = "Nu s-a putut încărca modelul recomandat.";
"Couldn’t load the recommended model right now." = "Nu s-a putut încărca modelul recomandat acum.";
"Creativity: %@. Low values focus responses; high values add variety." = "Creativitate: %@. Valorile scăzute focalizează răspunsurile; valorile mari adaugă varietate.";
"Dark" = "Întuneric";
"Dataset" = "Setul de date";
"Dataset indexing in progress..." = "Indexarea setului de date în curs...";
"Dataset ready to use" = "Set de date gata de utilizare";
"Datasets" = "Seturi de date";
"Datasets enrich the model with focused knowledge. Toggle one on to use it in chat." = "Seturile de date îmbogățesc modelul cu cunoștințe concentrate. Activați una pentru a o folosi în chat.";
"Default selection (~%@) balances RAM usage against model quality." = "Selecția implicită (~%@) echilibrează utilizarea RAM cu calitatea modelului.";
"Delete" = "Şterge";
"Delete Dataset" = "Ștergeți setul de date";
"Deletes all chats, downloaded models, and datasets, and restores settings to defaults. The embedding model stays installed." = "Șterge toate chaturile, modelele descărcate și seturile de date și restabilește setările la valorile implicite. Modelul de încorporare rămâne instalat.";
"Device" = "Dispozitiv";
"Digest:" = "Digera:";
"Done" = "Făcut";
"Done!" = "Făcut!";
"Download Now" = "Descărcați acum";
"Download a model from Explore or add a remote endpoint to get started." = "Descărcați un model din Explore sau adăugați un punct final la distanță pentru a începe.";
"Download a small embedding model so Noema can index and search your datasets" = "Descărcați un model mic de încorporare, astfel încât Noema să vă poată indexa și căuta seturile de date";
"Downloaded datasets need on-device embedding. Give it a few minutes after download finishes." = "Seturile de date descărcate necesită încorporare pe dispozitiv. Acordați-i câteva minute după ce descărcarea se termină.";
"Downloaded models and datasets live here so you can manage them offline." = "Modelele și seturile de date descărcate live aici, astfel încât să le puteți gestiona offline.";
"Downloading…" = "Se descarcă...";
"Draft tokens: %@" = "Jetoane de schiță: %@";
"Draft window: %@" = "Schiță de fereastră: %@";
"EPUB viewing not supported on this platform" = "Vizualizarea EPUB nu este acceptată pe această platformă";
"Embedding" = "Încorporarea";
"Embedding Model Ready" = "Model de încorporare gata";
"Embedding is resource intensive. For best performance, plug in your phone. Do you want to proceed on battery?" = "Încorporarea necesită resurse intensive. Pentru cea mai bună performanță, conectați-vă telefonul. Doriți să continuați cu bateria?";
"Enabling Bluetooth…" = "Se activează Bluetooth...";
"Enhance with Datasets" = "Îmbunătățiți cu seturi de date";
"Error" = "Eroare";
"Estimated working set: %@ · Budget: %@" = "Set de lucru estimat: %1$@ · Buget: %2$@";
"Experts Per Token" = "Experți pe token";
"Explore Datasets" = "Explorați seturile de date";
"Expose any downloaded models or connected remote endpoints from the Stored tab to your paired devices. Select which one should answer conversations when the relay is running." = "Expuneți toate modelele descărcate sau punctele finale conectate la distanță din fila Stocat pe dispozitivele dvs. asociate. Selectați care dintre ele ar trebui să răspundă la conversații când releul funcționează.";
"Expose to iOS" = "Expune la iOS";
"Explore the latest open-source models optimized for your Mac." = "Explorează cele mai noi modele open-source optimizate pentru Mac-ul tău.";
"Failed to load README" = "Nu s-a putut încărca README";
"Failed: %@" = "Eșuat: %@";
"Fastest option on this device: SLM (Leap) models." = "Cea mai rapidă opțiune de pe acest dispozitiv: modelele SLM (Leap).";
"Field requirements will depend on your specific backend deployment." = "Cerințele de câmp vor depinde de implementarea backend-ului dvs. specifică.";
"Files" = "Fișiere";
"First, enable fast dataset search" = "În primul rând, activați căutarea rapidă a setului de date";
"First-time GGUF load takes longer" = "Încărcarea GGUF pentru prima dată durează mai mult";
"First-time download from HuggingFace" = "Descărcare pentru prima dată de pe HuggingFace";
"First‑time setup: download the Qwen‑1.7B model and embeddings.\nWi‑Fi recommended." = "Configurare pentru prima dată: descărcați modelul Qwen‑1.7B și înglobările.\nWi-Fi recomandat.";
"For best performance, please plug in your phone until this completes." = "Pentru o performanță optimă, conectați telefonul până la finalizare.";
"Force Local Network" = "Forțare rețea locală";
"Forces chat traffic through the last LAN host even if Wi‑Fi names don't match yet." = "Forțează traficul de chat prin ultima gazdă LAN, chiar dacă numele Wi-Fi nu se potrivesc încă.";
"Formatted view unavailable" = "Vizualizarea formatată nu este disponibilă";
"Found unsupported: %@ …" = "S-a găsit neacceptat: %@…";
"Frequency penalty: %@" = "Penalizare de frecvență: %@";
"GGUF models are the most compatible option. Use the format switch to explore the other builds when you need them." = "Modelele GGUF sunt cea mai compatibilă opțiune. Utilizați comutatorul de format pentru a explora celelalte versiuni atunci când aveți nevoie de ele.";
"GGUF works everywhere. MLX targets Apple Silicon speed. SLM focuses on responsiveness on any device." = "GGUF funcționează peste tot. MLX vizează viteza Apple Silicon. SLM se concentrează pe capacitatea de răspuns pe orice dispozitiv.";
"GPU Offload Layers" = "Straturi de descărcare GPU";
"GPU off-load is not supported for this model." = "Descărcarea GPU nu este acceptată pentru acest model.";
"Get Started" = "Începeți";
"Help shape Noema by trying upcoming features and sharing feedback." = "Ajutați-l să modeleze Noema încercând funcțiile viitoare și partajând feedback.";
"High context lengths use more memory" = "Lungimi mari de context folosesc mai multă memorie";
"High-quality embedding model for local RAG" = "Model de încorporare de înaltă calitate pentru RAG local";
"Host ID: %@" = "ID gazdă: %@";
"How it works" = "Cum funcționează";
"I'm New to Local LLMs, Guide Me" = "Sunt nou în domeniul LLM local, ghidați-mă";
"If enabled, the app will attempt to load models even when they likely exceed your device's memory budget. This can cause the app to terminate." = "Dacă este activată, aplicația va încerca să încarce modele chiar și atunci când probabil depășesc bugetul de memorie al dispozitivului. Acest lucru poate duce la închiderea aplicației.";
"Import Dataset" = "Importați set de date";
"Import PDFs, EPUBs, or text files to build local knowledge bases." = "Importați fișiere PDF, EPUB sau fișiere text pentru a construi baze de cunoștințe locale.";
"Import your own PDFs, EPUBs, or TXT files and keep them local." = "Importați-vă propriile fișiere PDF, EPUB sau TXT și păstrați-le locale.";
"Importing & Scanning..." = "Se importă și se scanează...";
"In progress..." = "În curs...";
"Indexing %@" = "Se indexează %@";
"Indexing dataset…" = "Se indexează setul de date...";
"Indexing: %@% · %@" = "Indexare: %1$@%2$ · %3$@";
"Install a local model to make it available at launch." = "Instalați un model local pentru a-l face disponibil la lansare.";
"Install another model with the same architecture and equal or smaller size to enable speculative decoding." = "Instalați un alt model cu aceeași arhitectură și dimensiune egală sau mai mică pentru a permite decodificarea speculativă.";
"K Cache Quant" = "K Cant. cache";
"Keep this iPhone or iPad within a few feet of the Mac that is advertising Noema Relay. We'll pull the relay details automatically once connected." = "Păstrați acest iPhone sau iPad la câțiva metri de Mac-ul care face reclamă Noema Relay. Vom extrage automat detaliile releului după conectare.";
"LAN URL: %@" = "URL LAN: %@";
"Large Model Downloads" = "Descărcări mari de modele";
"Last Sync" = "Ultima sincronizare";
"Last refreshed %@" = "Ultima actualizare %@";
"Latest benchmark" = "Cel mai recent benchmark";
"Latest integrated release: %@" = "Cea mai recentă versiune integrată: %@";
"Library" = "Bibliotecă";
"Light" = "Aprinde";
"Llama.cpp" = "Apelați.cpp";
"Load" = "Încarcă";
"Load a local model before chatting. You can download one from the Explore tab or load a model you've already installed." = "Încărcați un model local înainte de a discuta. Puteți descărca unul din fila Explorare sau puteți încărca un model pe care l-ați instalat deja.";
"Loading recommendation…" = "Se încarcă recomandarea…";
"Loading…" = "Încărcare…";
"Local Network HTTP server for LAN clients (OpenAI-compatible)" = "Server HTTP de rețea locală pentru clienții LAN (compatibil cu OpenAI)";
"Low = focused. High = varied." = "Scăzut = concentrat. Ridicat = variat.";
"Lower = more results (more noise). Higher = stricter matches." = "Mai scăzut = mai multe rezultate (mai mult zgomot). Mai mare = potriviri mai stricte.";
"MLX currently manages expert routing automatically; manual selection is not supported." = "MLX gestionează în prezent rutarea expertă în mod automat; selecția manuală nu este acceptată.";
"Many models are several gigabytes in size and require a stable connection and sufficient storage. Downloads can fail or take a long time on slow networks or devices with limited space." = "Multe modele au o dimensiune de câțiva gigaocteți și necesită o conexiune stabilă și spațiu de stocare suficient. Descărcările pot eșua sau pot dura mult timp pe rețele lente sau dispozitive cu spațiu limitat.";
"Max Chunks: %@" = "Bucăți maxime: %@";
"Max recommended context on this device: ~%@ tokens" = "Context maxim recomandat pe acest dispozitiv: ~%@ jetoane";
"Measure real-world generation speed for this configuration. A short scripted prompt will run locally and report timing and memory usage." = "Măsurați viteza de generare în lumea reală pentru această configurație. Un scurt prompt scriptat va rula local și va raporta timpul și utilizarea memoriei.";
"Min-p" = "Min-p";
"Min-p: %@" = "Min-p: %@";
"Minimum cosine similarity a passage must have to be considered relevant. Lower = more passages (higher recall, more noise). Higher = fewer, more precise passages. Try 0.2–0.4 for broad questions; 0.5–0.7 for precise lookups." = "Asemănarea minimă a cosinusului trebuie să aibă un pasaj pentru a fi considerată relevantă. Mai jos = mai multe pasaje (rechemare mai mare, mai mult zgomot). Mai mare = mai puține pasaje, mai precise. Încercați 0,2–0,4 pentru întrebări ample; 0,5–0,7 pentru căutări precise.";
"MoE layers: %@ / %@" = "Straturi MoE: %1$@ / %2$@";
"Model Detection Limitations" = "Limitări de detectare a modelului";
"Model Formats" = "Formate de model";
"Models" = "Modele";
"Models shown here are exposed by the Mac relay. Manage sources in the Relay tab on macOS to share more models." = "Modelele prezentate aici sunt expuse de releul Mac. Gestionați sursele în fila Releu pe macOS pentru a partaja mai multe modele.";
"Move your device closer to the Mac running the relay if it doesn't appear right away. Bluetooth discovery usually completes within a few seconds." = "Mutați-vă dispozitivul mai aproape de Mac-ul care rulează releul dacă acesta nu apare imediat. Descoperirea Bluetooth se finalizează de obicei în câteva secunde.";
"Name your dataset" = "Denumiți-vă setul de date";
"Nearby Relays" = "Relee din apropiere";
"Nearby iPhone and iPad devices discover your Mac relay instantly and sync pairing codes over the air." = "Dispozitivele iPhone și iPad din apropiere descoperă Mac-ul dvs. retransmite instantaneu și sincronizează codurile de asociere prin aer.";
"Need a fresh thread? Tap the plus button for a brand-new conversation." = "Ai nevoie de un fir nou? Atingeți butonul plus pentru o conversație nou-nouță.";
"Nice! You already have the recommended GGUF starter model ready to use." = "Frumos! Aveți deja gata de utilizare modelul de pornire GGUF recomandat.";
"No compatible files found for retrieval. Supported: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV" = "Nu s-au găsit fișiere compatibile pentru recuperare. Acceptat: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV";
"No connection responses recorded yet." = "Nu s-au înregistrat încă răspunsuri la conexiune.";
"No datasets available yet. Import or download datasets to build your personal library." = "Nu există încă set de date disponibile. Importați sau descărcați seturi de date pentru a vă construi biblioteca personală.";
"No datasets found. Try different keywords." = "Nu au fost găsite seturi de date. Încercați diferite cuvinte cheie.";
"No datasets imported yet." = "Niciun set de date importat încă.";
"No datasets yet" = "Niciun set de date încă";
"No files listed for this dataset." = "Nu există fișiere listate pentru acest set de date.";
"No model >" = "Nici un model >";
"No model loaded" = "Niciun model încărcat";
"No models available. Add downloads or remote connections in Stored to configure the relay." = "Nu există modele disponibile. Adăugați descărcări sau conexiuni la distanță în Stored pentru a configura releul.";
"No models cached yet. Open the backend to refresh its catalog." = "Nu există încă modele în cache. Deschideți backend-ul pentru a-și reîmprospăta catalogul.";
"No models found for '%@'" = "Nu s-au găsit modele pentru „%@”";
"No models loaded right now. We'll spin one up when a request arrives." = "Niciun model încărcat în acest moment. Vom roti unul când sosește o solicitare.";
"No models match your search." = "Niciun model nu corespunde căutării dvs.";
"No models yet" = "Încă nu există modele";
"No parameters" = "Fără parametri";
"No quant files available" = "Nu există fișiere cuant disponibile";
"No recent devices. We'll list clients the next time they talk to this relay." = "Nu există dispozitive recente. Vom enumera clienții data viitoare când vor vorbi cu acest releu.";
"No remote endpoints configured yet." = "Nu au fost încă configurate puncte finale la distanță.";
"No remote endpoints configured." = "Nu au fost configurate puncte finale la distanță.";
"No ≥Q3 quants are available for this model." = "Nu sunt disponibile cantități ≥Q3 pentru acest model.";
"Noema" = "noiembrie";
"Noema REST API — /api/v0/* for model catalog & operations" = "Noema REST API — /api/v0/* pentru catalogul de modele și operațiuni";
"Noema Relay" = "Noema Stafeu";
"Noema Server" = "Noema Server";
"Noema attempts to gauge available memory to prevent models from exceeding device limits. These checks may occasionally miss risky situations and allow a model to crash your app, or they may be overly conservative and block a model that could have run fine." = "Noema încearcă să evalueze memoria disponibilă pentru a preveni modelele să depășească limitele dispozitivului. Aceste verificări pot rata ocazional situații riscante și pot permite unui model să vă blocheze aplicația sau pot fi prea conservatoare și pot bloca un model care ar fi putut funcționa bine.";
"Noema could not find a projector in the repository. If the model advertises vision, ensure the mmproj file is present in the same folder as the weights." = "Noema nu a putut găsi un proiector în depozit. Dacă modelul promovează viziunea, asigurați-vă că fișierul mmproj este prezent în același folder cu greutățile.";
"Noema has been reset. The embedding model remains installed." = "Noema a fost resetată. Modelul de încorporare rămâne instalat.";
"Nomic Embed Text v1.5 (Q4_K_M)" = "Nomic Embed Text v1.5 (Q4_K_M)";
"None" = "Nici unul";
"Not found" = "Nu a fost găsit";
"Not provided" = "Nu este furnizat";
"OK" = "Bine";
"Off-Grid" = "În afara rețelei";
"Off-grid mode blocks every network call so the app stays self-contained. Good luck exploring Noema!" = "Modul off-grid blochează fiecare apel de rețea, astfel încât aplicația să rămână autonomă. Succes la explorarea Noema!";
"Only one expert is available for this model; the active expert count is fixed." = "Un singur expert este disponibil pentru acest model; numărul de experți activi este fix.";
"Open Stored to choose a model to run locally or connect to a remote endpoint." = "Deschideți Stocat pentru a alege un model de rulat local sau pentru a vă conecta la un punct final la distanță.";
"Open the sidebar to revisit any previous session without losing your spot." = "Deschideți bara laterală pentru a revedea orice sesiune anterioară fără a vă pierde locul.";
"OpenAI-style API — /v1/chat/completions, /v1/completions, /v1/models" = "API în stil OpenAI — /v1/chat/completions, /v1/completions, /v1/models";
"Optimizations in use" = "Optimizări în utilizare";
"PDF viewing not supported on this platform" = "Vizualizarea PDF nu este acceptată pe această platformă";
"Pick a model and add a dataset" = "Alegeți un model și adăugați un set de date";
"Pick the SLM format when you want ultra-responsive models that run well anywhere." = "Alegeți formatul SLM atunci când doriți modele ultra-responsive care rulează bine oriunde.";
"Pinned answer" = "Răspuns fixat";
"Pinned answer unavailable" = "Răspunsul fixat nu este disponibil";
"Preparation" = "Pregătirea";
"Preparing Embedding Model" = "Pregătirea modelului de încorporare";
"Preparing benchmark…" = "Se pregătește un benchmark...";
"Preparing…" = "Se pregătesc…";
"Presence penalty: %@" = "Penalizare de prezență: %@";
"Projector (mmproj)" = "Proiector (mmproj)";
"Projector downloaded automatically from Hugging Face. Keep this file alongside the weights so vision remains available." = "Proiector descărcat automat din Hugging Face. Păstrați acest fișier alături de greutăți, astfel încât vederea să rămână disponibilă.";
"Quantize the runtime key cache to save memory. Experimental." = "Cuantificați memoria cache a cheilor de rulare pentru a economisi memorie. Experimental.";
"Quantize the runtime value cache to save memory when Flash Attention is enabled. Experimental." = "Cuantificați memoria cache a valorii de rulare pentru a economisi memorie când este activată atenția Flash. Experimental.";
"Qwen 3 1.7B GGUF (Q3_K_M) gives you a dependable starting point. Delete it anytime if you need space." = "Qwen 3 1.7B GGUF (Q3_K_M) vă oferă un punct de pornire de încredere. Ștergeți-l oricând dacă aveți nevoie de spațiu.";
"RAG embeds normalized paragraphs from your PDFs and EPUBs. On each question, the most relevant chunks are retrieved and added to the prompt. Images are ignored." = "RAG încorporează paragrafe normalizate din PDF-urile și EPUB-urile dvs. La fiecare întrebare, cele mai relevante bucăți sunt preluate și adăugate la prompt. Imaginile sunt ignorate.";
"RAM Safety Checks" = "Verificări de siguranță RAM";
"RAM information for this device will be added in a future update." = "Informațiile RAM pentru acest dispozitiv vor fi adăugate într-o actualizare viitoare.";
"REST Endpoints" = "Puncte finale REST";
"Reachable at" = "Accesibil la";
"Ready for Use" = "Gata de utilizare";
"Recent Chats" = "Chat-uri recente";
"Recommended" = "Recomandat";
"Recommended Starter Model" = "Model de pornire recomandat";
"Relay ID" = "ID-ul releului";
"Relay Server Running" = "Serverul de retransmisie rulează";
"Relay Sources" = "Surse de releu";
"Remaining: %@" = "Rămâne: %@";
"Remember:" = "Amintiți-vă:";
"Remote Backends" = "Backend-uri la distanță";
"Remote endpoint is offline. This model can't be found at this time." = "Punctul final la distanță este offline. Acest model nu poate fi găsit în acest moment.";
"Remote timeout: %@s" = "Timeout de la distanță: %@s";
"Repeat last N tokens: %@" = "Repetați ultimele N jetoane: %@";
"Repetition penalty: %@" = "Penalizare pentru repetare: %@";
"Request Parameters" = "Parametri de solicitare";
"Responses are generated by the macOS relay server. Configure the provider (LM Studio or Ollama) on the Mac app." = "Răspunsurile sunt generate de serverul de releu macOS. Configurați furnizorul (LM Studio sau Ollama) în aplicația pentru Mac.";
"Result" = "Rezultat";
"Results" = "Rezultate";
"Save" = "Salvează";
"Saving…" = "Economisire…";
"Score: %@" = "Scor: %@";
"SearXNG web search is available without limits. There's nothing to purchase—just enable the globe button in chat whenever you need online results." = "Căutarea web SearXNG este disponibilă fără limite. Nu există nimic de cumpărat – doar activați butonul glob în chat ori de câte ori aveți nevoie de rezultate online.";
"SearXNG web search is enabled for this device." = "Căutarea web SearXNG este activată pentru acest dispozitiv.";
"Search" = "Căutare";
"Search for any subject you're interested in." = "Căutați orice subiect care vă interesează.";
"Search requests are proxied through https://search.noemaai.com and are available without quotas." = "Solicitările de căutare sunt trimise prin proxy prin https://search.noemaai.com și sunt disponibile fără cote.";
"Seed" = "Sămânță";
"Selecting more experts keeps additional expert weights resident in RAM and increases memory usage." = "Selectarea mai multor experți păstrează ponderi suplimentare ale experților rezidenți în RAM și crește utilizarea memoriei.";
"Server Settings" = "Setări server";
"Share Logs" = "Partajați jurnalele";
"Sharing relay payload with nearby devices…" = "Se partajează sarcina utilă de releu cu dispozitivele din apropiere...";
"Shows the last server response." = "Afișează ultimul răspuns al serverului.";
"Signal" = "Semnal";
"Similarity Threshold" = "Pragul de similitudine";
"Simple" = "Simplu";
"Smooth loops and phrase echo by balancing repetition controls." = "Buclele netede și ecoul frazei prin echilibrarea controalelor de repetiție.";
"Smooth loops and repeated phrases by tuning repetition controls." = "Buclele netede și frazele repetate prin reglarea comenzilor de repetiție.";
"Some models do not provide the system prompts needed for Noema to detect and configure them properly. These models may be unusable until they include appropriate metadata or support." = "Unele modele nu oferă solicitările de sistem necesare pentru ca Noema să le detecteze și să le configureze corect. Aceste modele pot fi inutilizabile până când includ metadate sau suport adecvat.";
"Source unavailable. Check storage or network settings." = "Sursa indisponibilă. Verificați setările de stocare sau de rețea.";
"Source: %@" = "Sursa: %@";
"Specify identifiers for models that are not listed by the server. Leave blank to rely on the server's catalog." = "Specificați identificatori pentru modelele care nu sunt listate de server. Lăsați necompletat pentru a vă baza pe catalogul serverului.";
"Specify your model identifiers, or reload your custom models later." = "Specificați identificatorii de model sau reîncărcați modelele personalizate mai târziu.";
"Speed up with a smaller helper model." = "Accelerează cu un model de ajutor mai mic.";
"Start by installing one model. Then add a dataset (like an open textbook) so the AI can answer with grounded knowledge." = "Începeți prin a instala un model. Apoi adăugați un set de date (cum ar fi un manual deschis), astfel încât AI să poată răspunde cu cunoștințe fundamentate.";
"Start the relay to automatically share the latest payload with nearby devices." = "Porniți releul pentru a partaja automat cea mai recentă sarcină utilă cu dispozitivele din apropiere.";
"Start with a reliable Qwen 3 1.7B build. It balances capability with small download size." = "Începeți cu o versiune de încredere Qwen 3 1.7B. Echilibrează capacitatea cu dimensiunea mică de descărcare.";
"Startup defaults now live in Settings → Startup. Favorite models here to keep them handy." = "Setările implicite de pornire sunt acum disponibile în Setări → Pornire. Modelele preferate aici pentru a le ține la îndemână.";
"Status" = "Stare";
"Stay close to your Mac" = "Rămâi aproape de Mac-ul tău";
"Stop Using Dataset" = "Nu mai utilizați setul de date";
"Streaming" = "Streaming";
"Streaming response…" = "Răspunsul în flux...";
"Supported Endpoints" = "Puncte finale acceptate";
"Supported formats: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV" = "Formate acceptate: PDF, EPUB, TXT, MD, JSON, JSONL, CSV, TSV";
"Swap between the new stacked chat panel and the classic tab bar layout." = "Schimbați între noul panou de chat stivuit și aspectul clasic al barei de file.";
"Swipe left to remove the embedding model from this device." = "Glisați spre stânga pentru a elimina modelul de încorporare de pe acest dispozitiv.";
"Switch the selector to MLX for Apple Silicon‑optimized builds that excel at speed." = "Comutați selectorul la MLX pentru versiunile optimizate pentru Apple Silicon care excelează în viteză.";
"Switch to Raw to inspect the original response." = "Comutați la Raw pentru a inspecta răspunsul inițial.";
"System" = "Sistem";
"Tap to load" = "Atingeți pentru a încărca";
"Temperature" = "Temperatură";
"Testing" = "Testare";
"The app memory usage budget is an estimate based on your device's total RAM and typical iOS memory management. The actual available memory may vary depending on system load, other running apps, and iOS memory pressure. Models that exceed this budget may cause the app to be terminated by iOS." = "Bugetul de utilizare a memoriei aplicației este o estimare bazată pe memoria RAM totală a dispozitivului și gestionarea tipică a memoriei iOS. Memoria disponibilă reală poate varia în funcție de încărcarea sistemului, de alte aplicații care rulează și de presiunea memoriei iOS. Modelele care depășesc acest buget pot determina oprirea aplicației de către iOS.";
"The embedding model is installed. Delete it to free ~320 MB." = "Modelul de încorporare este instalat. Ștergeți-l pentru a elibera ~320 MB.";
"The relay listens to the %@ container for new conversations and responds with your selected provider." = "Releul ascultă containerul %@ pentru conversații noi și răspunde cu furnizorul selectat.";
"The tool returned data that can't be formatted. Switch to Raw to inspect the original response." = "Instrumentul a returnat date care nu pot fi formatate. Comutați la Raw pentru a inspecta răspunsul inițial.";
"These options stay in simple mode for clarity. Let’s cover the essentials." = "Aceste opțiuni rămân în modul simplu pentru claritate. Să acoperim elementele esențiale.";
"Think of Noema as a simple way to run AI on your device. To get useful answers, you pair a local model with datasets (like open textbooks). We’ll guide you through the first setup." = "Gândiți-vă la Noema ca la o modalitate simplă de a rula AI pe dispozitivul dvs. Pentru a obține răspunsuri utile, asociați un model local cu seturi de date (cum ar fi manualele deschise). Vă vom ghida prin prima configurare.";
"This app bundles llama.cpp; we keep this in sync with upstream b‑releases." = "Această aplicație include llama.cpp; menținem acest lucru sincronizat cu lansările b din amonte.";
"This backend is unavailable. Remove it or pick another option." = "Acest backend este indisponibil. Eliminați-l sau alegeți o altă opțiune.";
"This chat stays private—responses are generated on your device after you load a model." = "Acest chat rămâne privat – răspunsurile sunt generate pe dispozitiv după ce încărcați un model.";
"This configuration exceeds the current RAM safety guard, so benchmarking is disabled." = "Această configurație depășește gardul de siguranță actual al memoriei RAM, așa că benchmarking-ul este dezactivat.";
"This dataset is taking a while to load, still working…" = "Încărcarea acestui set de date durează, încă funcționează...";
"This dataset's files are not currently supported for document retrieval." = "Fișierele acestui set de date nu sunt acceptate în prezent pentru recuperarea documentelor.";
"This device doesn't support GPU offload." = "Acest dispozitiv nu acceptă descărcarea GPU.";
"This device doesn't support GPU offload; GGUF models will run on the CPU and generation speed will be significantly slower." = "Acest dispozitiv nu acceptă descărcarea GPU; Modelele GGUF vor rula pe procesor, iar viteza de generare va fi semnificativ mai mică.";
"This model doesn't support GPU offload and generation speed will be significantly slower. Consider switching to an MLX model." = "Acest model nu acceptă descărcarea GPU, iar viteza de generare va fi semnificativ mai mică. Luați în considerare trecerea la un model MLX.";
"This model doesn't support GPU offload and generation speed will be significantly slower. Fastest option on this device: use an SLM (Leap) model." = "Acest model nu acceptă descărcarea GPU, iar viteza de generare va fi semnificativ mai mică. Cea mai rapidă opțiune de pe acest dispozitiv: utilizați un model SLM (Leap).";
"This model doesn't support GPU offload and may run slowly. Consider an MLX model." = "Acest model nu acceptă descărcarea GPU și poate rula lent. Luați în considerare un model MLX.";
"This model doesn't support GPU offload and may run slowly. Fastest option: use an SLM model." = "Acest model nu acceptă descărcarea GPU și poate rula lent. Cea mai rapidă opțiune: utilizați un model SLM.";
"This permanently removes every chat conversation. This action cannot be undone." = "Acest lucru elimină definitiv fiecare conversație prin chat. Această acțiune nu poate fi anulată.";
"This textbook appears to be available only as a web page. Noema can't import it as a dataset." = "Acest manual pare să fie disponibil doar ca pagină web. Noema nu îl poate importa ca set de date.";
"Tool calling isn't perfect. Although Noema implements many methods of detecting and instructing models to use tools, not all LLMs will follow instructions and some might not call them correctly or at all. Tool calling heavily depends on model pre-training and will get better as time passes." = "Apelarea instrumentului nu este perfectă. Deși Noema implementează multe metode de detectare și instruire a modelelor să utilizeze instrumente, nu toți LLM-urile vor urma instrucțiunile și este posibil ca unii să nu le numească corect sau deloc. Apelarea instrumentelor depinde în mare măsură de pregătirea prealabilă a modelului și se va îmbunătăți pe măsură ce trece timpul.";
"Tools" = "Instrumente";
"Top-k: %@" = "Top-k: %@";
"Top-p" = "Sus-p";
"Top-p: %@" = "Top-p: %@";
"Try again" = "Încearcă din nou";
"Try another dataset if these formats aren't available." = "Încercați un alt set de date dacă aceste formate nu sunt disponibile.";
"Try the Qwen 3 1.7B GGUF (Q3_K_M) build below. It's a good starting point and you can delete it anytime." = "Încercați versiunea Qwen 3 1.7B GGUF (Q3_K_M) de mai jos. Este un bun punct de plecare și îl puteți șterge oricând.";
"Unable to load image" = "Nu se poate încărca imaginea";
"Unknown error" = "Eroare necunoscută";
"Updates every second" = "Actualizări în fiecare secundă";
"Use" = "Utilizare";
"Use Dataset" = "Utilizați setul de date";
"Use this switch to flip between finding models or datasets." = "Utilizați acest comutator pentru a comuta între modele sau seturi de date.";
"Using %@" = "Folosind %@";
"Using %@ of %@ budget" = "Se utilizează %1$@ din %2$@ buget";
"Using more than %@ significantly increases RAM usage." = "Utilizarea mai mult de %@ crește semnificativ utilizarea RAM.";
"Using server catalog" = "Folosind catalogul serverului";
"V Cache Quant" = "V Cache Quant";
"Vendor recommendation: %@" = "Recomandarea furnizorului: %@";
"Version" = "Versiune";
"Version %@" = "Versiunea %@";
"Version 1.4" = "Versiunea 1.4";
"Vision models require a companion projector (.mmproj). Noema will fetch it automatically the next time you download this model." = "Modelele Vision necesită un proiector însoțitor (.mmproj). Noema îl va prelua automat data viitoare când descărcați acest model.";
"Wait for the response in your other chat to finish before sending a new message." = "Așteptați ca răspunsul din celălalt chat să se termine înainte de a trimite un mesaj nou.";
"Waiting for tool response…" = "Se așteaptă răspunsul instrumentului...";
"We'll extract text and prepare embeddings. You can also start later from the dataset details." = "Vom extrage text și vom pregăti înglobări. De asemenea, puteți începe mai târziu de la detaliile setului de date.";
"We'll route new conversations through %@ even if Wi‑Fi names differ. You can switch back by reloading the backend." = "Vom direcționa conversațiile noi prin %@ chiar dacă numele Wi-Fi diferă. Puteți comuta înapoi reîncărcând backend-ul.";
"We'll try remote models in priority order for this long before moving to the next option." = "Vom încerca modele de la distanță în ordine de prioritate pentru aceasta mult înainte de a trece la următoarea opțiune.";
"We'll try this saved identifier even though it's not in the latest catalog." = "Vom încerca acest identificator salvat, chiar dacă nu se află în cel mai recent catalog.";
"Web Search Tool Calls" = "Apeluri pentru instrumentul de căutare web";
"Web Search button" = "butonul Căutare Web";
"Web search is included" = "Căutarea pe web este inclusă";
"Weights" = "Greutăți";
"Welcome to Noema" = "Bun venit la Noema";
"Welcome to Noema for Mac" = "Bun venit la Noema pentru Mac";
"What is Noema?" = "Ce este Noema?";
"When connecting from another device, point the base URL to your computer (for example http://192.168.0.10:11434) and start Ollama with `OLLAMA_HOST=0.0.0.0` so it accepts remote clients." = "Când vă conectați de pe alt dispozitiv, îndreptați adresa URL de bază către computer (de exemplu http://192.168.0.10:11434) și porniți Ollama cu `OLLAMA_HOST=0.0.0.0`, astfel încât să accepte clienți la distanță.";
"When enabled, pressing eject on iOS tells this Mac to unload the active relay model." = "Când este activată, apăsarea de eject pe iOS îi spune acestui Mac să descarce modelul de releu activ.";
"When enabled, you will be asked to choose parameters every time a model loads." = "Când este activat, vi se va cere să alegeți parametrii de fiecare dată când se încarcă un model.";
"Wi-Fi: %@" = "WiFi: %@";
"Working set estimate (%@): %@ @ %@ tokens" = "Estimare set de lucru (%1$@): %2$@ @ %3$@ jetoane";
"Write prompts, instructions, or notes here. Press return to add new lines." = "Scrieți solicitări, instrucțiuni sau note aici. Apăsați Revenire pentru a adăuga linii noi.";
"You can keep chatting while indexing finishes" = "Puteți continua să discutați în timp ce indexarea se termină";
"You can only favorite up to three models." = "Puteți favoriza doar până la trei modele.";
"You can restart this process in the dataset settings any time." = "Puteți reporni oricând acest proces din setările setului de date.";
"You're in Off-Grid mode. The Explore tab is hidden and all network features are disabled. You can only use downloaded models and datasets." = "Sunteți în modul Off-Grid. Fila Explorare este ascunsă și toate funcțiile de rețea sunt dezactivate. Puteți utiliza numai modele și seturi de date descărcate.";
"Your Datasets" = "Seturile dvs. de date";
"Your Models" = "Modelele dvs";
"Your private AI workspace" = "Spațiul tău de lucru AI privat";
"You’re ready to explore. Download models, add datasets, and start chatting." = "Ești gata să explorezi. Descărcați modele, adăugați seturi de date și începeți să discutați.";
"minutes" = "minute";
"•" = "";
"• Close other applications to free up RAM" = "• Închideți alte aplicații pentru a elibera RAM";
"• Embedding happens locally on your device" = "• Încorporarea are loc local pe dispozitivul dvs";
"• Larger datasets take exponentially more time" = "• Seturile de date mai mari necesită exponențial mai mult timp";
"• You can pause and resume downloads if needed" = "• Puteți întrerupe și relua descărcările dacă este necesar";
"…and %@ more parameter%@" = "…și încă %1$@ parametru%2$@";
"⚠️ " = "";
"General" = "General";

"Privacy" = "Confidențialitate";

"About" = "Despre";

"About & Support" = "Despre și suport";

"Network" = "Rețea";

"Embedding Model" = "Model de embedding";

"Retrieval" = "Regăsire";

"Early Testers" = "Testeri timpurii";

"Build Info" = "Informații build";

"Settings" = "Setări";

"Language" = "Limbă";
"Startup" = "Pornire";
"Search models" = "Căutați modele";
"SLM Models - Liquid AI" = "SLM Models - Liquid AI";
"Import" = "Importă";
"Import GGUF" = "Importă GGUF";
"Import MLX" = "Importă MLX";
"Import Failed" = "Import nereușit";
"Switching between GGUF/MLX modes" = "Comutați între modurile GGUF/MLX";
"Switching between GGUF/SLM modes" = "Comutați între modurile GGUF/SLM";
"Vision-capable model" = "Model compatibil vizual";
"All" = "Toate";
"Text" = "Text";
"Vision" = "Viziune";
"Continue" = "Continuă";
"Try bullet" = "Încercați:\n• Alte cuvinte cheie (de ex. „gemma-3” în loc de „gemma 3”) \n• %@\n• Ajustați filtrul text/viziune\n• Verificați filtrele de căutare";
"Select one or more .gguf files. For vision models, also select the projector .gguf (files containing ‘mmproj’ or ‘projector’). Files will be copied into your local model library." = "Select one or more .gguf files. For vision models, also select the projector .gguf (files containing ‘mmproj’ or ‘projector’). Files will be copied into your local model library.";
"Select the model folder that contains config.json and the weights (safetensors/npz). The entire folder will be imported into your local model library." = "Select the model folder that contains config.json and the weights (safetensors/npz). The entire folder will be imported into your local model library.";
"K Cache Quantization" = "Cuantificare cache K";
"V Cache Quantization" = "Cuantificare cache V";
"Favorite Limit Reached" = "Limită de favorite atinsă";
"Overview" = "Prezentare generală";
"Sampling" = "Sampling";
"Speculative Decoding" = "Decodare speculativă";
"Benchmark" = "Benchmark";
"Maintenance" = "Mentenanță";
"MLX" = "MLX";
"Tokenizer Path (tokenizer.json)" = "Cale tokenizer (tokenizer.json)";
"Back" = "Înapoi";
"Favorite Model" = "Model favorit";
"Reset to Default Settings" = "Resetează la setările implicite";
"Delete Model" = "Șterge modelul";
"Delete %@?" = "Ștergeți %@?";
"Not provided by repository" = "Neasigurat de depozit";
"Unknown (not checked yet)" = "Necunoscut (neverificat încă)";
"Keep Model In Memory" = "Păstrează modelul în memorie";
"GPU Offload Layers: %@/%@" = "Straturi offload GPU: %1$@/%2$@";
"CPU Threads: %@" = "Thread-uri CPU: %@";
"Offload KV Cache to GPU" = "Offload cache KV pe GPU";
"Use mmap()" = "Folosește mmap()";
"Random" = "Aleatoriu";
"Flash Attention" = "Flash Attention";
"1 expert" = "1 expert";
"%@ experts" = "%@ experți";
"Helper Model" = "Model auxiliar";
"Draft strategy" = "Strategie de draft";
"Run Benchmark" = "Rulează benchmark";
"Benchmarking…" = "Benchmarking…";
"Leap SLM models manage runtime optimizations automatically." = "Modelele Leap SLM gestionează automat optimizările de rulare.";
"This format doesn't expose tunable runtime optimizations." = "Acest format nu oferă optimizări runtime configurabile.";
"Token processing" = "Procesare tokenuri";
"Token generation" = "Generare tokenuri";
"Total time" = "Timp total";
"First token" = "Primul token";
"Peak memory" = "Memorie maximă";
"Output tokens" = "Tokenuri rezultate";
"End Guide" = "Încheie ghidul";
"Streaming benchmark output…" = "Se transmite ieșirea benchmark-ului…";
"Streaming… %@ chunks (~%@ tok est.)" = "Streaming… %1$@ fragmente (~%2$@ tok estimați)";
"Streaming… %d chunks (~%d tok est.)" = "Streaming… %d fragmente (~%d tok estimați)";
"The selected model's weights could not be located." = "Greutățile modelului selectat nu au putut fi găsite.";
"Failed to load model for benchmark: %@" = "Încărcarea modelului pentru benchmark a eșuat: %@";
"Benchmark generation failed: %@" = "Generarea benchmark-ului a eșuat: %@";
"K Cache" = "Cache K";
"V Cache" = "Cache V";
"KV Offload" = "Offload KV";
"On" = "Activat";
"Off" = "Dezactivat";
"GPU" = "GPU";
"CPU" = "CPU";
"%.1f tok/s" = "%.1f tok/s";
"%.1fs" = "%.1fs";
"%.2fs" = "%.2fs";
"Memory Budget" = "Buget de memorie";
"Startup Defaults" = "Setări implicite la pornire";
"Runtime Safety" = "Siguranță la rulare";
"Working set estimate (%@): %@ @ %d tokens" = "Estimare set de lucru (%@): %@ @ %d jetoane";
"RAM information for this device will be added in a future update." = "Informațiile RAM pentru acest dispozitiv vor fi adăugate într-o actualizare viitoare.";
"Estimate for" = "Estimează pentru";
"Bypass RAM safety check (may cause crashes)" = "Ocolește verificarea de siguranță RAM (poate cauza blocări)";
"Off-grid Mode" = "Mod off-grid";
"Local default" = "Implicit local";
"Add remote default" = "Adaugă implicit la distanță";
"When both are available" = "Când ambele sunt disponibile";
"Remote timeout: %ds" = "Timeout remote: %ds";
"We'll try remote models in priority order for this long before moving to the next option." = "Vom încerca modelele la distanță în ordinea priorității pentru acest timp înainte de a trece la următoarea opțiune.";
"Appearance" = "Aspect";
"Override the app language. Defaults to the device language on first launch." = "Suprascrie limba aplicației. Implicit folosește limba dispozitivului la prima lansare.";
"Reopen Onboarding" = "Redeschide onboarding-ul";
"Join Early Testers" = "Alătură-te Early Testers";
"Contact Support" = "Contactează suportul";
"Write a Review" = "Scrie o recenzie";
"Notes & Issues" = "Note și probleme";
"Delete All Chats" = "Șterge toate conversațiile";
"Reset App Data" = "Resetează datele aplicației";
"This permanently removes every chat conversation. This action cannot be undone." = "Aceasta șterge definitiv toate conversațiile. Acțiunea nu poate fi anulată.";
"Chat History Deleted" = "Istoricul conversațiilor a fost șters";
"App Data Reset" = "Datele aplicației resetate";
"Noema has been reset. The embedding model remains installed." = "Noema a fost resetată. Modelul de embedding rămâne instalat.";
"Failed to Delete Embedding Model" = "Nu s-a putut șterge modelul de embedding";
"About RAM Usage" = "Despre utilizarea RAM";
"The app memory usage budget is an estimate based on your device's total RAM and typical iOS memory management. The actual available memory may vary depending on system load, other running apps, and iOS memory pressure. Models that exceed this budget may cause the app to be terminated by iOS." = "Bugetul de utilizare a memoriei este o estimare bazată pe RAM-ul dispozitivului și pe gestionarea tipică a memoriei. Memoria disponibilă poate varia în funcție de încărcarea sistemului. Modelele care depășesc acest buget pot determina închiderea aplicației.";
"Max Chunks" = "Fragmente maxime";
"Similarity Threshold" = "Prag de similitudine";
"Delete Embedding Model" = "Șterge modelul de embedding";
"The embedding model is installed. Delete it to free ~320 MB." = "Modelul de embedding este instalat. Șterge-l pentru a elibera ~320 MB.";
"Swipe left to remove the embedding model from this device." = "Glisează spre stânga pentru a elimina modelul de embedding de pe acest dispozitiv.";
"Verifying…" = "Se verifică…";
"Installing…" = "Se instalează…";
"Download Embedding Model" = "Descarcă modelul de embedding";
"Custom Backend" = "Backend personalizat";
"Backend" = "Backend";
"Endpoint Type" = "Tip endpoint";
"Endpoints" = "Endpoint-uri";
"Authentication" = "Autentificare";
"Model Identifiers" = "Identificatori model";
"CloudKit container identifier" = "Identificator container CloudKit";
"Host device ID" = "ID dispozitiv gazdă";
"Base URL" = "URL de bază";
"Auth header (optional)" = "Antet Auth (opțional)";
"Model identifier" = "Identificator model";
"Add Identifier" = "Adaugă identificator";
"Remove identifier" = "Elimină identificator";
"Specify your model identifiers, or reload your custom models later." = "Specifică identificatorii modelului sau reîncarcă modelele personalizate mai târziu.";
"When connecting from another device, point the base URL to your computer (for example http://192.168.0.10:11434) and start Ollama with `OLLAMA_HOST=0.0.0.0` so it accepts remote clients." = "Când te conectezi de pe un alt dispozitiv, setează URL-ul de bază către calculatorul tău (de exemplu http://192.168.0.10:11434) și pornește Ollama cu `OLLAMA_HOST=0.0.0.0` pentru a accepta clienți la distanță.";
"Connections to localhost may not work from other devices. Replace it with your machine's LAN IP address to allow remote access." = "Conexiunile la localhost pot să nu funcționeze de pe alte dispozitive. Înlocuiește-l cu adresa IP LAN a calculatorului pentru a permite accesul de la distanță.";
"Launch Ollama with `OLLAMA_HOST=0.0.0.0` so it can accept remote clients." = "Pornește Ollama cu `OLLAMA_HOST=0.0.0.0` pentru a accepta clienți la distanță.";
"Model doesn't support GPU offload" = "Modelul nu suportă offload pe GPU";
"This model doesn't support GPU offload and may run slowly. Consider an MLX model." = "Acest model nu suportă offload pe GPU și poate rula lent. Ia în calcul un model MLX.";
"This model doesn't support GPU offload and may run slowly. Fastest option: use an SLM model." = "Acest model nu suportă offload pe GPU și poate rula lent. Opțiunea cea mai rapidă: folosește un model SLM.";
"Load Failed" = "Încărcarea a eșuat";
"Don't show again" = "Nu mai afișa";
"Select a model to load" = "Selectează un model pentru încărcare";
"Loading model…" = "Se încarcă modelul…";
"Please wait" = "Așteaptă";
"Models Library" = "Biblioteca de modele";
"Streaming" = "Streaming";
"Type to filter models…" = "Tastează pentru a filtra modelele…";
"Sort" = "Sortează";
"Recency" = "Recență";

/* Noema Relay – pairing & dataset helpers */
"Model file missing (.gguf)" = "Fișierul model lipsește (.gguf)";
"Model path missing" = "Calea modelului lipsește";
"Imported Dataset" = "Set de date importat";
"Dataset name" = "Numele setului de date";
"Keep this device near the Mac that's running Noema Relay to import its settings." = "Ține acest dispozitiv aproape de Mac‑ul pe care rulează Noema Relay pentru a‑i importa setările.";
"Scanning for your Mac relay…" = "Se caută releul tău Mac…";
"Ready to scan nearby relays" = "Gata de scanare a releelor din apropiere";
"Bluetooth access is required to pair with the Mac relay." = "Este necesar acces la Bluetooth pentru a te împerechea cu releul de pe Mac.";
"Stop Scanning" = "Oprește scanarea";
"Start Scan" = "Pornește scanarea";
"Connection verified. Relay details imported from this Mac." = "Conexiune verificată. Detaliile releului au fost importate de pe acest Mac.";
"Signal strength unavailable" = "Intensitatea semnalului indisponibilă";
"Very close" = "Foarte aproape";
"Nearby" = "În apropiere";
"Within one room" = "În aceeași cameră";
"Move closer for a stronger signal" = "Apropie‑te pentru un semnal mai puternic.";
"This Mac" = "Acest Mac";

/* Accessibility announcements */
"Model loaded." = "Model încărcat.";
"Prompt submitted." = "Prompt trimis.";
"Generating response…" = "Se generează răspunsul…";
"Response generated." = "Răspuns generat.";

/* Tabs & accessibility labels */
"Stored" = "Stocat";
"Web Search" = "Căutare web";
"Open Stored" = "Deschideți Stocat";
"Message input" = "Introducere mesaj";
"What is Web Search button?" = "Ce este butonul de căutare web?";
"Model Library" = "Biblioteca de modele";
"No models match your search." = "Niciun model nu corespunde căutării.";
"Browse Explore tab" = "Deschide fila Explorează";
"Manually choose parameters" = "Alege manual parametrii";
"Available Quantizations" = "Cuantizări disponibile";
"Sort quantizations" = "Sortează cuantizările";
"Quant" = "Cuant";
"Size ↑" = "Dimensiune ↑";
"Size ↓" = "Dimensiune ↓";
"Ready" = "Gata";
"Open" = "Deschide";
"Retry download" = "Reîncearcă descărcarea";
"Vision-capable" = "Compatibil cu viziune";
"Mixture-of-Experts" = "Mixture-of-Experts";
"Resume" = "Reia";
"Discover and download local models" = "Descoperă și descarcă modele locale";
"Browse curated datasets for retrieval" = "Răsfoiește seturi de date curatoriate pentru regăsire";
"Section" = "Secțiune";
"Filter" = "Filtrează";
"Downloaded" = "Descărcat";
"Size" = "Dimensiune";
"Compressed Text" = "Text comprimat";
"Small" = "Mic";
"Medium" = "Mediu";
"Large" = "Mare";
"Very Large" = "Foarte mare";
"Extreme" = "Extrem";
"Under 10 MB" = "Sub 10 MB";
"10–50 MB" = "10–50 MB";
"50–200 MB" = "50–200 MB";
"200–500 MB" = "200–500 MB";
"Over 500 MB" = "Peste 500 MB";
"Estimated Embedding Time" = "Timp estimat de embedding";
"Peak RAM Usage" = "Consum maxim de RAM";
"Dataset Size" = "Dimensiunea setului de date";
"Performance Note" = "Notă de performanță";
"Recommendation" = "Recomandare";
"Remember:" = "Reține:";
"• Close other applications to free up RAM" = "• Închide alte aplicații pentru a elibera RAM";
"• Embedding happens locally on your device" = "• Embedding-ul se face local pe dispozitivul tău";
"• Larger datasets take exponentially more time" = "• Seturile de date mai mari durează mult mai mult";
"• You can pause and resume downloads if needed" = "• Poți pune descărcările pe pauză și le poți relua la nevoie";
"Dataset Requirements" = "Cerințe pentru setul de date";
"Got it" = "Am înțeles";
"Check Requirements" = "Verifică cerințele";
"< 1 minute" = "< 1 minut";
"%d minutes" = "%d minute";
"This dataset should embed quickly with minimal resource usage. Perfect for testing and quick experiments." = "Acest set de date ar trebui să fie integrat rapid cu resurse minime. Perfect pentru teste și experimente rapide.";
"This dataset is a reasonable size for most systems. Embedding should complete in a few minutes." = "Acest set are o dimensiune potrivită pentru majoritatea sistemelor. Integrarea ar trebui să se termine în câteva minute.";
"This is a substantial dataset. Ensure you have adequate RAM and expect embedding to take 10–30 minutes." = "Acesta este un set de date substanțial. Asigură-te că ai suficientă RAM și așteaptă-te la 10–30 de minute de procesare.";
"This is a very large dataset. Embedding may take 30–60 minutes and requires significant RAM." = "Acesta este un set de date foarte mare. Integrarea poate dura 30–60 de minute și necesită multă RAM.";
"This is an extremely large dataset. Consider splitting it into smaller parts for better performance." = "Acesta este un set de date extrem de mare. Ia în considerare împărțirea lui în părți mai mici pentru performanță mai bună.";
"Go ahead and download! This size works well on all systems." = "Poți descărca fără griji! Această dimensiune merge bine pe toate sistemele.";
"Recommended for most users. Make sure you have at least 4GB of free RAM." = "Recomandat pentru majoritatea utilizatorilor. Asigură-te că ai cel puțin 4GB de RAM liber.";
"Recommended only if you have 8GB+ RAM available. Close other applications before embedding." = "Recomandat doar dacă ai peste 8GB RAM disponibil. Închide alte aplicații înainte de integrare.";
"Recommended only for systems with 16GB+ RAM. Consider processing during off-hours." = "Recomandat doar pentru sisteme cu cel puțin 16GB RAM. Ia în calcul procesarea în afara orelor de lucru.";
"Not recommended for typical systems. Consider finding a smaller version or subset of this dataset." = "Nu este recomandat pentru sistemele obișnuite. Caută o versiune mai mică sau un subset al acestui set de date.";
"Sample dataset" = "Set de date exemplu";
"Could not connect to Ollama at localhost. When connecting from another device, replace \"localhost\" with your computer's IP address or hostname and start Ollama with `OLLAMA_HOST=0.0.0.0` so it can accept remote connections." = "Nu s-a putut conecta la Ollama pe localhost. Pentru conectare de pe alt dispozitiv, înlocuiește \"localhost\" cu adresa IP sau numele gazdei și pornește Ollama cu `OLLAMA_HOST=0.0.0.0` pentru a accepta conexiuni.";
"Could not connect to the Ollama server. Make sure Ollama is running on %@ and is configured to accept connections from this device (for example by launching it with `OLLAMA_HOST=0.0.0.0`)." = "Nu s-a putut conecta la serverul Ollama. Asigură-te că Ollama rulează pe %@ și este configurat să accepte conexiuni de pe acest dispozitiv (de exemplu pornindu-l cu `OLLAMA_HOST=0.0.0.0`).";
"Move Up" = "Mută în sus";
"Move Down" = "Mută în jos";
"Remove" = "Elimină";
"Startup remote options" = "Opțiuni remote la pornire";
"No models cached yet. Open the backend to refresh its catalog." = "Nu există încă modele în cache. Deschide backend-ul pentru a-i reîmprospăta catalogul.";
"We'll try this saved identifier even though it's not in the latest catalog." = "Vom încerca acest identificator salvat chiar dacă nu se află în cel mai recent catalog.";
"This backend is unavailable. Remove it or pick another option." = "Acest backend nu este disponibil. Elimină-l sau alege altă opțiune.";
"Backend removed" = "Backend eliminat";
"What is Max Chunks?" = "Ce înseamnă numărul maxim de fragmente?";
"What is Similarity Threshold?" = "Ce este pragul de similaritate?";
"Approx. %@" = "Aprox. %@";
"Advanced mode shows developer options and diagnostics." = "Modul avansat afișează opțiuni de dezvoltator și diagnostic.";
"Simple mode hides advanced settings for a cleaner interface." = "Modul simplu ascunde setările avansate pentru o interfață mai curată.";
"Hide advanced controls" = "Ascunde controalele avansate";
"Show advanced controls" = "Afișează controalele avansate";
"Adjust model settings" = "Ajustează setările modelului";
"Model Settings" = "Setări model";
"SLM models are not supported on this platform." = "Modelele SLM nu sunt acceptate pe această platformă.";
"Model likely exceeds memory budget. Lower context or choose a smaller quant." = "Modelul probabil depășește bugetul de memorie. Redu contextul sau alege un cuant mai mic.";
"Apple bundle models aren't supported on macOS yet." = "Modelele Apple bundle nu sunt încă acceptate pe macOS.";
"Estimate: %@\nBudget: %@\nContext length: %@ tokens\n\nThis is an estimate based on your device’s memory budget, context length (KV cache), and typical runtime overheads. Actual usage may vary." = "Estimare: %@\nBuget: %@\nLungime context: %@ token-uri\n\nAceasta este o estimare bazată pe bugetul de memorie al dispozitivului, lungimea contextului (cache KV) și costuri tipice de execuție. Valorile reale pot varia.";
"Model likely fits in RAM" = "Modelul probabil încape în RAM";
"Model may not fit in RAM" = "Modelul s-ar putea să nu încapă în RAM";
"Fits in RAM (estimated)" = "Încape în RAM (estimat)";
"May not fit (estimated)" = "S-ar putea să nu încapă (estimat)";
"Please provide a backend name." = "Te rugăm să oferi un nume pentru backend.";
"A backend with this name already exists." = "Există deja un backend cu acest nume.";
"Backend not found." = "Backend negăsit.";
"This Noema Relay device is already configured." = "Acest dispozitiv Noema Relay este deja configurat.";
"OpenAI API" = "OpenAI API";
"LM Studio" = "LM Studio";
"Ollama" = "Ollama";
"Cloud Relay" = "Cloud Relay";
"Noema Relay" = "Noema Relay";
"Compatible with OpenAI-style /v1 endpoints" = "Compatibil cu endpoint-uri /v1 în stil OpenAI";
"Connect to LM Studio's REST server" = "Conectează-te la serverul REST LM Studio";
"Target an Ollama host for chat and pulls" = "Țintește un host Ollama pentru chat și descărcări";
"Use Noema's Cloud Relay on macOS" = "Folosește Cloud Relay al Noema pe macOS";
"Pair with your Mac over CloudKit" = "Asociază-te cu Mac-ul prin CloudKit";
"Please provide the CloudKit container identifier." = "Introdu ID-ul containerului CloudKit.";
"Please provide the host device ID from the Mac relay." = "Introdu ID-ul dispozitivului gazdă din releul Mac.";
"Missing host device ID for Noema Relay." = "Lipsește ID-ul dispozitivului gazdă pentru Noema Relay.";
"Missing CloudKit container identifier." = "Lipsește identificatorul containerului CloudKit.";
"Relay catalog unavailable." = "Catalogul releului nu este disponibil.";
"Relay catalog is still syncing. Open the Mac relay, ensure it is signed into iCloud, then try again in a moment." = "Catalogul releului încă se sincronizează. Deschide releul pe Mac, asigură-te că este conectat la iCloud, apoi încearcă din nou.";
"Terms of Use" = "Termeni de utilizare";
"Privacy Policy" = "Politica de confidențialitate";
"Contact Support" = "Contactează suportul";
"Write a Review" = "Scrie o recenzie";
"Notes & Issues" = "Note și probleme";
"Qwen3-1.7B is a compact and efficient model from the Qwen3 family, suitable for on-device usage with strong general capabilities." = "Qwen3-1.7B este un model compact și eficient din familia Qwen3, potrivit pentru utilizare pe dispozitiv cu capabilități generale solide.";
"Gemma 3n E2B is a lightweight instruction-tuned model from Google's Gemma family, optimized for efficient on-device conversations." = "Gemma 3n E2B este un model ușor, ajustat pentru instrucțiuni, din familia Gemma de la Google, optimizat pentru conversații eficiente pe dispozitive locale.";
"Gemma 3n E2B is an instruction-tuned variant of Google's Gemma family built for efficient reasoning on low-resource devices.\nAvailable in GGUF quants (Q3_K_M, Q4_K_M, Q6_K) and an MLX 4-bit build for Apple Silicon.\n" = "Gemma 3n E2B este o variantă instrucțională din familia Gemma, construită pentru raționament eficient pe dispozitive cu resurse reduse.\nDisponibil în cuantizări GGUF (Q3_K_M, Q4_K_M, Q6_K) și într-o versiune MLX 4-bit pentru Apple Silicon.\n";
"Phi-4 Mini Reasoning is a lightweight model from the Phi-4 family, tuned for strong reasoning and efficiency across tasks." = "Phi-4 Mini Reasoning este un model ușor din familia Phi-4, optimizat pentru raționament și eficiență în diverse sarcini.";
"Phi-4 Mini Reasoning — a compact model in Microsoft’s Phi-4 line designed for logical reasoning, problem solving, and instruction-following. \nDistributed in efficient GGUF quants (Q3_K_L, Q4_K_M, Q6_K) and an MLX 4-bit variant for Apple Silicon devices.\n" = "Phi-4 Mini Reasoning — un model compact din seria Phi-4 a Microsoft, conceput pentru raționament logic, rezolvare de probleme și urmarea instrucțiunilor.\nDistribuit în cuantizări GGUF eficiente (Q3_K_L, Q4_K_M, Q6_K) și într-o variantă MLX 4-bit pentru dispozitive Apple Silicon.\n";
"Available Quantizations" = "Cuantizări disponibile";
"Sort quantizations" = "Sortează cuantizările";
"Quant" = "Cuant";
"Size ↑" = "Dimensiune ↑";
"Size ↓" = "Dimensiune ↓";
"Model Library" = "Biblioteca de modele";
"Type to filter models…" = "Tastează pentru a filtra modelele…";
"No models match your search." = "Niciun model nu corespunde căutării tale.";
"Browse Explore tab" = "Deschide fila Explore";
"Manually choose parameters" = "Alege parametrii manual";
"The base URL looks invalid. Please include the host (e.g. http://127.0.0.1:1234)." = "URL-ul de bază pare nevalid. Include gazda (de ex. http://127.0.0.1:1234).";
"Could not build the remote endpoint URL." = "Nu s-a putut construi URL-ul endpoint-ului la distanță.";
"The server returned an unexpected response." = "Serverul a returnat un răspuns neașteptat.";
"Server responded with status code %d." = "Serverul a răspuns cu codul de stare %d.";
"Server responded with status code %d: %@" = "Serverul a răspuns cu codul %1$d: %2$@";
"Failed to decode server response." = "Nu s-a putut decoda răspunsul serverului.";

"Explore" = "Explorează";
"Search datasets" = "Caută seturi de date";
"Download" = "Descarcă";
"Offline" = "Deconectat";
"Tap to load" = "Atinge pentru a încărca";
"%d models" = "%d modele";
"Updated %@" = "Actualizat %@";
"No models fetched yet" = "Niciun model preluat încă";
"Auth" = "Autentificare";
"Local Network" = "Rețea locală";
"Direct" = "Direct";
"LAN" = "LAN";
"LAN · %@" = "LAN · %@";
"Backend" = "Backend";
"Base URL" = "URL de bază";
"Chat Path" = "Cale chat";
"Models Path" = "Cale modele";
"Endpoint Type" = "Tip endpoint";
"Endpoints" = "Endpoint-uri";
"Authentication" = "Autentificare";
"Model Identifiers" = "Identificatori model";
"Name" = "Nume";
"Host device ID" = "ID dispozitiv gazdă";
"Host Device ID" = "ID dispozitiv gazdă";
"CloudKit container identifier" = "Identificator container CloudKit";
"Field requirements will depend on your specific backend deployment." = "Cerințele câmpurilor depind de implementarea backend.";
"Uses Noema Relay configuration" = "Folosește configurația Noema Relay";
"Chat: %@\nModels: %@" = "Chat: %@\nModele: %@";

"Download Dataset" = "Descarcă setul de date";
"No files listed for this dataset." = "Nu există fișiere listate pentru acest set de date.";
"This dataset's files are not currently supported for document retrieval." = "Fișierele acestui set de date nu sunt acceptate momentan pentru regăsirea documentelor.";
"Supported formats: %@" = "Formate acceptate: %@";
"Try another dataset if these formats aren't available." = "Încercați un alt set de date dacă aceste formate nu sunt disponibile.";
"Found unsupported: %@ …" = "Formate neacceptate găsite: %@ …";
"This textbook appears to be available only as a web page. Noema can't import it as a dataset." = "Acest manual pare să fie disponibil doar ca pagină web. Noema nu îl poate importa ca set de date.";
"Download complete" = "Descărcare finalizată";
"Downloading…" = "Se descarcă…";
"No compatible files found for retrieval. Supported formats: %@" = "Nu am găsit fișiere compatibile pentru regăsire. Formate acceptate: %@";
"No internet connection." = "Nu există conexiune la internet.";
"Request timed out. Please try again." = "Solicitarea a expirat. Vă rugăm să încercați din nou.";
"Connection was lost. Please try again." = "Conexiunea s-a pierdut. Vă rugăm să încercați din nou.";
"Unexpected error: %@" = "Eroare neașteptată: %@";

/* Mac chat quick-load menu */
"Open Model Library" = "Deschide biblioteca de modele";
"Favorites" = "Favorite";
"Recent" = "Recente";

"Name" = "Nume";
